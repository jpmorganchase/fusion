{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#pyfusion","title":"PyFusion","text":"<p>PyFusion is the Python SDK for the Fusion platform API. </p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pyfusion\n</code></pre> <p>Fusion by J.P. Morgan is a cloud-native data platform for institutional investors, providing end-to-end data management, analytics, and reporting solutions across the investment lifecycle. The platform allows clients to seamlessly integrate and combine data from multiple sources into a single data model that delivers the benefits and scale and reduces costs, along with the ability to more easily unlock timely analysis and insights. Fusion's open data architecture supports flexible distribution, including partnerships with cloud and data providers, all managed by J.P. Morgan data experts. </p> <p>For more information, please visit fusion.jpmorgan.com</p> <p>For the SDK documentation, please visit page</p>"},{"location":"api/","title":"Modules","text":"<p>Main Fusion module.</p> <p>Synchronisation between the local filesystem and Fusion.</p> <p>Parameters:</p> Name Type Description Default <code>fs_fusion</code> <code>filesystem</code> <p>Fusion filesystem.</p> required <code>fs_local</code> <code>filesystem</code> <p>Local filesystem.</p> required <code>products</code> <code>list</code> <p>List of products.</p> <code>None</code> <code>datasets</code> <code>list</code> <p>List of datasets.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>Fusion catalog.</p> <code>None</code> <code>direction</code> <code>str</code> <p>Direction of synchronisation: upload/download.</p> <code>'upload'</code> <code>flatten</code> <code>bool</code> <p>Flatten the folder structure.</p> <code>False</code> <code>dataset_format</code> <code>str</code> <p>Dataset format for upload/download.</p> <code>None</code> <code>n_par</code> <code>int</code> <p>Specify how many distributions to download in parallel. Defaults to all.</p> <code>None</code> <code>show_progress</code> <code>bool</code> <p>Display a progress bar during data download Defaults to True.</p> <code>True</code> <code>local_path</code> <code>str</code> <p>path to files in the local filesystem, e.g., \"s3a://my_bucket/\"</p> <code>''</code> <code>log_level</code> <code>int</code> <p>Logging level. Error level by default.</p> <code>ERROR</code> <code>log_path</code> <code>str</code> <p>The folder path where the log is stored. Defaults to \".\".</p> <code>'.'</code> Source code in <code>py_src/fusion/fs_sync.py</code> <pre><code>def fsync(  # noqa: PLR0912, PLR0913, PLR0915\n    fs_fusion: fsspec.filesystem,\n    fs_local: fsspec.filesystem,\n    products: Optional[list[str]] = None,\n    datasets: Optional[list[str]] = None,\n    catalog: Optional[str] = None,\n    direction: str = \"upload\",\n    flatten: bool = False,\n    dataset_format: Optional[str] = None,\n    n_par: Optional[int] = None,\n    show_progress: bool = True,\n    local_path: str = \"\",\n    log_level: int = logging.ERROR,\n    log_path: str = \".\",\n) -&gt; None:\n    \"\"\"Synchronisation between the local filesystem and Fusion.\n\n    Args:\n        fs_fusion (fsspec.filesystem): Fusion filesystem.\n        fs_local (fsspec.filesystem): Local filesystem.\n        products (list): List of products.\n        datasets (list): List of datasets.\n        catalog (str): Fusion catalog.\n        direction (str): Direction of synchronisation: upload/download.\n        flatten (bool): Flatten the folder structure.\n        dataset_format (str): Dataset format for upload/download.\n        n_par (int, optional): Specify how many distributions to download in parallel. Defaults to all.\n        show_progress (bool): Display a progress bar during data download Defaults to True.\n        local_path (str): path to files in the local filesystem, e.g., \"s3a://my_bucket/\"\n        log_level (int): Logging level. Error level by default.\n        log_path (str): The folder path where the log is stored. Defaults to \".\".\n\n    Returns:\n\n    \"\"\"\n\n    logging.addLevelName(VERBOSE_LVL, \"VERBOSE\")\n    logger.setLevel(log_level)\n    if not logger.handlers:\n        logger.addHandler(logging.NullHandler())\n\n    formatter = logging.Formatter(\n        \"%(asctime)s.%(msecs)03d %(name)s:%(levelname)s %(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n    )\n\n    if not any(isinstance(h, logging.FileHandler) for h in logger.handlers):\n        file_handler = logging.FileHandler(filename=\"{}/{}\".format(log_path, \"fusion_fsync.log\"))\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n    if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):\n        stdout_handler = logging.StreamHandler(sys.stdout)\n        stdout_handler.setFormatter(formatter)\n        logger.addHandler(stdout_handler)\n\n    if len(logger.handlers) &gt; 1:\n        logger.handlers = [h for h in logger.handlers if not isinstance(h, logging.NullHandler)]\n\n    catalog = catalog if catalog else \"common\"\n    datasets = datasets if datasets else []\n    products = products if products else []\n\n    assert len(products) &gt; 0 or len(datasets) &gt; 0, \"At least one list products or datasets should be non-empty.\"\n    assert direction in [\n        \"upload\",\n        \"download\",\n    ], \"The direction must be either upload or download.\"\n\n    if len(local_path) &gt; 0 and local_path[-1] != \"/\":\n        local_path += \"/\"\n\n    for product in products:\n        res = json.loads(fs_fusion.cat(f\"{catalog}/products/{product}\").decode())\n        datasets += [r[\"identifier\"] for r in res[\"resources\"]]\n\n    assert len(datasets) &gt; 0, \"The supplied products did not contain any datasets.\"\n\n    local_state = pd.DataFrame()\n    fusion_state = pd.DataFrame()\n    while True:\n        try:\n            local_state_temp = _get_local_state(\n                fs_local,\n                fs_fusion,\n                datasets,\n                catalog,\n                dataset_format,\n                local_state,\n                local_path,\n            )\n            fusion_state_temp = _get_fusion_df(fs_fusion, datasets, catalog, flatten, dataset_format)\n            if not local_state_temp.equals(local_state) or not fusion_state_temp.equals(fusion_state):\n                res = _synchronize(\n                    fs_fusion,\n                    fs_local,\n                    local_state_temp,\n                    fusion_state_temp,\n                    direction,\n                    n_par,\n                    show_progress,\n                    local_path,\n                )\n                if len(res) == 0 or all(i[0] for i in res):\n                    local_state = local_state_temp\n                    fusion_state = fusion_state_temp\n\n                if not all(r[0] for r in res):\n                    failed_res = [r for r in res if not r[0]]\n                    msg = f\"Not all {direction}s were successfully completed. The following failed:\\n{failed_res}\"\n                    errs = [r for r in res if not r[2]]\n                    logger.warning(msg)\n                    logger.warning(errs)\n                    warnings.warn(msg, stacklevel=2)\n\n            else:\n                logger.info(\"All synced, sleeping\")\n                time.sleep(10)\n\n        except KeyboardInterrupt:  # noqa: PERF203\n            if input(\"Type exit to exit: \") != \"exit\":\n                continue\n            break\n\n        except Exception as _:\n            logger.error(\"Exception thrown\", exc_info=True)\n            continue\n</code></pre> <p>Fusion Product class and functions.</p> <p>Fusion Dataset class and functions.</p> <p>Fusion Product class and functions.</p>"},{"location":"api/#fusion.fusion.Fusion","title":"<code>Fusion</code>","text":"<p>Core Fusion class for API access.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>class Fusion:\n    \"\"\"Core Fusion class for API access.\"\"\"\n\n    @staticmethod\n    def _call_for_dataframe(url: str, session: requests.Session) -&gt; pd.DataFrame:\n        \"\"\"Private function that calls an API endpoint and returns the data as a pandas dataframe.\n\n        Args:\n            url (Union[FusionCredentials, Union[str, dict]): URL for an API endpoint with valid parameters.\n            session (requests.Session): Specify a proxy if required to access the authentication server. Defaults to {}.\n\n        Returns:\n            pandas.DataFrame: a dataframe containing the requested data.\n        \"\"\"\n        response = session.get(url)\n        response.raise_for_status()\n        table = response.json()[\"resources\"]\n        ret_df = pd.DataFrame(table).reset_index(drop=True)\n        return ret_df\n\n    @staticmethod\n    def _call_for_bytes_object(url: str, session: requests.Session) -&gt; BytesIO:\n        \"\"\"Private function that calls an API endpoint and returns the data as a bytes object in memory.\n\n        Args:\n            url (Union[FusionCredentials, Union[str, dict]): URL for an API endpoint with valid parameters.\n            session (requests.Session): Specify a proxy if required to access the authentication server. Defaults to {}.\n\n        Returns:\n            io.BytesIO: in memory file content\n        \"\"\"\n\n        response = session.get(url)\n        response.raise_for_status()\n\n        return BytesIO(response.content)\n\n    def __init__(\n        self,\n        credentials: str | FusionCredentials = \"config/client_credentials.json\",\n        root_url: str = \"https://fusion.jpmorgan.com/api/v1/\",\n        download_folder: str = \"downloads\",\n        log_level: int = logging.ERROR,\n        fs: fsspec.filesystem = None,\n        log_path: str = \".\",\n        enable_logging: bool = True,\n    ) -&gt; None:\n        \"\"\"Constructor to instantiate a new Fusion object.\n\n        Args:\n            credentials (Union[str, FusionCredentials]): A path to a credentials file or a fully populated\n            FusionCredentials object. Defaults to 'config/client_credentials.json'.\n            root_url (_type_, optional): The API root URL.\n                Defaults to \"https://fusion.jpmorgan.com/api/v1/\".\n            download_folder (str, optional): The folder path where downloaded data files\n                are saved. Defaults to \"downloads\".\n            log_level (int, optional): Set the logging level. Defaults to logging.ERROR.\n            fs (fsspec.filesystem): filesystem.\n            log_path (str, optional): The folder path where the log is stored.\n            enable_logging (bool, optional): If True, enables logging to a file in addition to stdout.\n                If False, logging is only directed to stdout. Defaults to True.\n        \"\"\"\n        self._default_catalog = \"common\"\n\n        self.root_url = root_url\n        self.download_folder = download_folder\n        Path(download_folder).mkdir(parents=True, exist_ok=True)\n\n        logging.addLevelName(VERBOSE_LVL, \"VERBOSE\")\n        logger.setLevel(log_level)\n        if not logger.handlers:\n            logger.addHandler(logging.NullHandler())\n\n        formatter = logging.Formatter(\n            \"%(asctime)s.%(msecs)03d %(name)s:%(levelname)s %(message)s\",\n            datefmt=\"%Y-%m-%d %H:%M:%S\",\n        )\n\n        if enable_logging and not any(isinstance(h, logging.FileHandler) for h in logger.handlers):\n            file_handler = logging.FileHandler(filename=f\"{log_path}/fusion_sdk.log\")\n            file_handler.setFormatter(formatter)\n            logger.addHandler(file_handler)\n\n        if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):\n            stdout_handler = logging.StreamHandler(sys.stdout)\n            stdout_handler.setFormatter(formatter)\n            logger.addHandler(stdout_handler)\n\n        if len(logger.handlers) &gt; 1:\n            logger.handlers = [h for h in logger.handlers if not isinstance(h, logging.NullHandler)]\n\n        if isinstance(credentials, FusionCredentials):\n            self.credentials = credentials\n        elif isinstance(credentials, str):\n            try:\n                self.credentials = FusionCredentials.from_file(Path(credentials))\n            except CredentialError as e:\n                if hasattr(e, \"status_code\"):\n                    message = \"Failed to load credentials. Please check the credentials file.\"\n                    raise APIResponseError(e, message=message) from e\n                else:\n                    raise e\n        else:\n            raise ValueError(\"credentials must be a path to a credentials file or FusionCredentials object\")\n\n        self.session = get_session(self.credentials, self.root_url)\n        self.fs = fs if fs else get_default_fs()\n        self.events: pd.DataFrame | None = None\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Object representation to list all available methods.\"\"\"\n        return \"Fusion object \\nAvailable methods:\\n\" + tabulate(\n            pd.DataFrame(  # type: ignore\n                [\n                    [\n                        method_name\n                        for method_name in dir(Fusion)\n                        if callable(getattr(Fusion, method_name)) and not method_name.startswith(\"_\")\n                    ]\n                    + [p for p in dir(Fusion) if isinstance(getattr(Fusion, p), property)],\n                    [\n                        getattr(Fusion, method_name).__doc__.split(\"\\n\")[0]\n                        for method_name in dir(Fusion)\n                        if callable(getattr(Fusion, method_name)) and not method_name.startswith(\"_\")\n                    ]\n                    + [\n                        getattr(Fusion, p).__doc__.split(\"\\n\")[0]\n                        for p in dir(Fusion)\n                        if isinstance(getattr(Fusion, p), property)\n                    ],\n                ]\n            ).T.set_index(0),\n            tablefmt=\"psql\",\n        )\n\n\n    @property\n    def default_catalog(self) -&gt; str:\n        \"\"\"Returns the default catalog.\n\n        Returns:\n            None\n        \"\"\"\n        return self._default_catalog\n\n    @default_catalog.setter\n    def default_catalog(self, catalog: str) -&gt; None:\n        \"\"\"Allow the default catalog, which is \"common\" to be overridden.\n\n        Args:\n            catalog (str): The catalog to use as the default\n\n        Returns:\n            None\n        \"\"\"\n        self._default_catalog = catalog\n\n    def _use_catalog(self, catalog: str | None) -&gt; str:\n        \"\"\"Determine which catalog to use in an API call.\n\n        Args:\n            catalog (str): The catalog value passed as an argument to an API function wrapper.\n\n        Returns:\n            str: The catalog to use\n        \"\"\"\n        if catalog is None:\n            return self.default_catalog\n\n        return catalog\n\n    def get_fusion_filesystem(self, **kwargs: Any) -&gt; FusionHTTPFileSystem:\n        \"\"\"Retrieve Fusion file system instance.\n\n        Note: This function always returns a reference to the exact same FFS instance since\n        an FFS instance is based off the FusionCredentials object.\n\n        Returns: Fusion Filesystem\n\n        \"\"\"\n        as_async = kwargs.get(\"asynchronous\", False)\n        return FusionHTTPFileSystem(\n            asynchronous=as_async, client_kwargs={\"root_url\": self.root_url, \"credentials\": self.credentials}\n        )\n\n    def _get_new_root_url(self) -&gt; str:\n        \"\"\"\n        Returns a modified version of the root URL to support the new API format.\n\n        This method temporarily strips trailing segments such as \"/api/v1/\" or \"/v1/\"\n        from the original `root_url` to align with an updated API base path format.\n\n        Returns:\n            str: The adjusted root URL without trailing version segments.\n\n        Deprecated:\n            This method is temporary and will be removed once all components have migrated\n            to the new API structure. Use `root_url` and apply formatting externally\n            as needed.\n        \"\"\"\n        new_root_url = self.root_url\n\n        if new_root_url:\n            if new_root_url.endswith(\"/api/v1/\"):\n                new_root_url = new_root_url[:-8]  # remove \"/api/v1/\"\n            elif new_root_url.endswith(\"/v1/\"):\n                new_root_url = new_root_url[:-4]  # remove \"/v1/\"\n\n        return new_root_url\n\n    def list_catalogs(self, output: bool = False) -&gt; pd.DataFrame:\n        \"\"\"Lists the catalogs available to the API account.\n\n        Args:\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n\n        Returns:\n            class:`pandas.DataFrame`: A dataframe with a row for each catalog\n        \"\"\"\n        url = f\"{self.root_url}catalogs/\"\n        cat_df = Fusion._call_for_dataframe(url, self.session)\n\n        if output:\n            pass\n\n        return cat_df\n\n    def catalog_resources(self, catalog: str | None = None, output: bool = False) -&gt; pd.DataFrame:\n        \"\"\"List the resources contained within the catalog, for example products and datasets.\n\n        Args:\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n\n        Returns:\n           class:`pandas.DataFrame`: A dataframe with a row for each resource within the catalog\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}\"\n        cat_df = Fusion._call_for_dataframe(url, self.session)\n\n        if output:\n            pass\n        return cat_df\n\n    def list_products(\n        self,\n        contains: str | list[str] | None = None,\n        id_contains: bool = False,\n        catalog: str | None = None,\n        output: bool = False,\n        max_results: int = -1,\n        display_all_columns: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Get the products contained in a catalog. A product is a grouping of datasets.\n\n        Args:\n            contains (Union[str, list], optional): A string or a list of strings that are product\n                identifiers to filter the products list. If a list is provided then it will return\n                products whose identifier matches any of the strings. Defaults to None.\n            id_contains (bool): Filter datasets only where the string(s) are contained in the identifier,\n                ignoring description.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n            max_results (int, optional): Limit the number of rows returned in the dataframe.\n                Defaults to -1 which returns all results.\n            display_all_columns (bool, optional): If True displays all columns returned by the API,\n                otherwise only the key columns are displayed\n\n        Returns:\n            class:`pandas.DataFrame`: a dataframe with a row for each product\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/products\"\n        full_prod_df: pd.DataFrame = Fusion._call_for_dataframe(url, self.session)\n\n        if contains:\n            if isinstance(contains, list):\n                contains = \"|\".join(f\"{s}\" for s in contains)\n            if id_contains:\n                filtered_df = full_prod_df[full_prod_df[\"identifier\"].str.contains(contains, case=False)]\n            else:\n                filtered_df = full_prod_df[\n                    full_prod_df[\"identifier\"].str.contains(contains, case=False)\n                    | full_prod_df[\"description\"].str.contains(contains, case=False)\n                ]\n        else:\n            filtered_df = full_prod_df\n\n        filtered_df[\"category\"] = filtered_df.category.str.join(\", \")\n        filtered_df[\"region\"] = filtered_df.region.str.join(\", \")\n        if not display_all_columns:\n            filtered_df = filtered_df[\n                filtered_df.columns.intersection(\n                    [\n                        \"identifier\",\n                        \"title\",\n                        \"region\",\n                        \"category\",\n                        \"status\",\n                        \"description\",\n                    ]\n                )\n            ]\n\n        if max_results &gt; -1: \n            filtered_df = filtered_df[0:max_results]\n\n        if output:\n            pass\n\n        return filtered_df\n\n    def list_datasets(  # noqa: PLR0912, PLR0913\n        self,\n        contains: str | list[str] | None = None,\n        id_contains: bool = False,\n        product: str | list[str] | None = None,\n        catalog: str | None = None,\n        output: bool = False,\n        max_results: int = -1,\n        display_all_columns: bool = False,\n        status: str | None = None,\n        dataset_type: str | None = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Get the datasets contained in a catalog.\n\n        Args:\n            contains (Union[str, list], optional): A string or a list of strings that are dataset\n                identifiers to filter the datasets list. If a list is provided then it will return\n                datasets whose identifier matches any of the strings. If a single dataset identifier is provided and\n                there is an exact match, only that dataset will be returned. Defaults to None.\n            id_contains (bool): Filter datasets only where the string(s) are contained in the identifier,\n                ignoring description.\n            product (Union[str, list], optional): A string or a list of strings that are product\n                identifiers to filter the datasets list. Defaults to None.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n            max_results (int, optional): Limit the number of rows returned in the dataframe.\n                Defaults to -1 which returns all results.\n            display_all_columns (bool, optional): If True displays all columns returned by the API,\n                otherwise only the key columns are displayed\n            status (str, optional): filter the datasets by status, default is to show all results.\n            dataset_type (str, optional): filter the datasets by type, default is to show all results.\n\n        Returns:\n            class:`pandas.DataFrame`: a dataframe with a row for each dataset.\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        # try for exact match\n        if contains and isinstance(contains, str):\n            url = f\"{self.root_url}catalogs/{catalog}/datasets/{contains}\"\n            resp = self.session.get(url)\n            status_success = 200\n            if resp.status_code == status_success:\n                resp_json = resp.json()\n                if not display_all_columns:\n                    cols = [\n                        \"identifier\",\n                        \"title\",\n                        \"containerType\",\n                        \"region\",\n                        \"category\",\n                        \"coverageStartDate\",\n                        \"coverageEndDate\",\n                        \"description\",\n                        \"status\",\n                        \"type\",\n                    ]\n                    data = {col: resp_json.get(col, None) for col in cols}\n                    return pd.DataFrame([data])\n                else:\n                    return pd.json_normalize(resp_json)\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets\"\n        ds_df = Fusion._call_for_dataframe(url, self.session)\n\n        if contains:\n            if isinstance(contains, list):\n                contains = \"|\".join(f\"{s}\" for s in contains)\n            if id_contains:\n                ds_df = ds_df[ds_df[\"identifier\"].str.contains(contains, case=False)]\n            else:\n                ds_df = ds_df[\n                    ds_df[\"identifier\"].str.contains(contains, case=False)\n                    | ds_df[\"description\"].str.contains(contains, case=False)\n                ]\n\n        if product:\n            url = f\"{self.root_url}catalogs/{catalog}/productDatasets\"\n            prd_df = Fusion._call_for_dataframe(url, self.session)\n            prd_df = (\n                prd_df[prd_df[\"product\"] == product]\n                if isinstance(product, str)\n                else prd_df[prd_df[\"product\"].isin(product)]\n            )\n            ds_df = ds_df[ds_df[\"identifier\"].str.lower().isin(prd_df[\"dataset\"].str.lower())].reset_index(drop=True)\n\n        if max_results &gt; -1:\n            ds_df = ds_df[0:max_results]\n\n        ds_df[\"category\"] = ds_df.category.str.join(\", \")\n        ds_df[\"region\"] = ds_df.region.str.join(\", \")\n        if not display_all_columns:\n            cols = [\n                \"identifier\",\n                \"title\",\n                \"containerType\",\n                \"region\",\n                \"category\",\n                \"coverageStartDate\",\n                \"coverageEndDate\",\n                \"description\",\n                \"status\",\n                \"type\",\n            ]\n            cols = [c for c in cols if c in ds_df.columns]\n            ds_df = ds_df[cols]\n\n        if status is not None:\n            ds_df = ds_df[ds_df[\"status\"] == status]\n\n        if dataset_type is not None:\n            ds_df = ds_df[ds_df[\"type\"] == dataset_type]\n\n        if output:\n            pass\n\n        return ds_df\n\n\n    def list_reports(\n        self,\n        report_id: str | None = None,\n        output: bool = False,\n        display_all_columns: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Retrieve a single report or all reports from the Fusion system.\"\"\"\n        key_columns = [\n            \"id\", \"name\", \"alternateId\", \"tierType\", \"frequency\",\n            \"category\", \"subCategory\", \"reportOwner\", \"lob\", \"description\"\n        ]\n\n        if report_id:\n            url = f\"{self._get_new_root_url()}/api/corelineage-service/v1/reports/{report_id}\"\n            resp = self.session.get(url)\n            if resp.status_code == HTTPStatus.OK:\n                rep_df = pd.json_normalize(resp.json())\n                if not display_all_columns:\n                    rep_df = rep_df[[c for c in key_columns if c in rep_df.columns]]\n                if output:\n                    pass\n                return rep_df\n            else:\n                resp.raise_for_status()\n        else:\n            url = f\"{self._get_new_root_url()}/api/corelineage-service/v1/reports/list\"\n            resp = self.session.post(url)\n            if resp.status_code == HTTPStatus.OK:\n                data = resp.json()\n                rep_df = pd.json_normalize(data.get(\"content\", data))\n                if not display_all_columns:\n                    rep_df = rep_df[[c for c in key_columns if c in rep_df.columns]]\n                if output:\n                    pass\n                return rep_df\n            else:\n                resp.raise_for_status()\n        return pd.DataFrame(columns=key_columns)\n\n\n    def list_report_attributes(\n        self,\n        report_id: str,\n        output: bool = False,\n        display_all_columns: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Retrieve the attributes (report elements) of a specific report.\"\"\"\n        url = f\"{self._get_new_root_url()}/api/corelineage-service/v1/reports/{report_id}/reportElements\"\n        resp = self.session.get(url)\n\n        if resp.status_code == HTTPStatus.OK:\n            rep_df = pd.json_normalize(resp.json())\n            if not display_all_columns:\n                key_columns = [\n                    \"id\", \"path\", \"status\", \"dataType\", \"isMandatory\",\n                    \"description\", \"createdBy\", \"name\"\n                ]\n                rep_df = rep_df[[c for c in key_columns if c in rep_df.columns]]\n            if output:\n                pass\n            return rep_df\n        else:\n            resp.raise_for_status()\n        return pd.DataFrame(columns=[\"id\", \"path\", \"status\", \"dataType\", \"isMandatory\", \n                                     \"description\", \"createdBy\", \"name\"])\n\n\n    def dataset_resources(self, dataset: str, catalog: str | None = None, output: bool = False) -&gt; pd.DataFrame:\n        \"\"\"List the resources available for a dataset, currently this will always be a datasetseries.\n\n        Args:\n            dataset (str): A dataset identifier\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n\n        Returns:\n            class:`pandas.DataFrame`: A dataframe with a row for each resource\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}\"\n        ds_res_df = Fusion._call_for_dataframe(url, self.session)\n\n        if output:\n            pass\n\n        return ds_res_df\n\n    def list_dataset_attributes(\n        self,\n        dataset: str,\n        catalog: str | None = None,\n        output: bool = False,\n        display_all_columns: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Returns the list of attributes that are in the dataset.\n\n        Args:\n            dataset (str): A dataset identifier\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n            display_all_columns (bool, optional): If True displays all columns returned by the API,\n                otherwise only the key columns are displayed\n\n        Returns:\n            class:`pandas.DataFrame`: A dataframe with a row for each attribute\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/attributes\"\n        ds_attr_df = Fusion._call_for_dataframe(url, self.session)\n\n        if \"index\" in ds_attr_df.columns:\n            ds_attr_df = ds_attr_df.sort_values(by=\"index\").reset_index(drop=True)\n\n        if not display_all_columns:\n            ds_attr_df = ds_attr_df[\n                ds_attr_df.columns.intersection(\n                    [\n                        \"identifier\",\n                        \"title\",\n                        \"dataType\",\n                        \"isDatasetKey\",\n                        \"description\",\n                        \"source\",\n                    ]\n                )\n            ]\n\n        if output:\n            pass\n\n        return ds_attr_df\n\n    def list_datasetmembers(\n        self,\n        dataset: str,\n        catalog: str | None = None,\n        output: bool = False,\n        max_results: int = -1,\n    ) -&gt; pd.DataFrame:\n        \"\"\"List the available members in the dataset series.\n\n        Args:\n            dataset (str): A dataset identifier\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n            max_results (int, optional): Limit the number of rows returned in the dataframe.\n                Defaults to -1 which returns all results.\n\n        Returns:\n            class:`pandas.DataFrame`: a dataframe with a row for each dataset member.\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries\"\n        ds_members_df = Fusion._call_for_dataframe(url, self.session)\n\n        if max_results &gt; -1:\n            ds_members_df = ds_members_df[0:max_results]\n\n        if output:\n            pass\n\n        return ds_members_df\n\n    def datasetmember_resources(\n        self,\n        dataset: str,\n        series: str,\n        catalog: str | None = None,\n        output: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"List the available resources for a datasetseries member.\n\n        Args:\n            dataset (str): A dataset identifier\n            series (str): The datasetseries identifier\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n\n        Returns:\n            class:`pandas.DataFrame`: A dataframe with a row for each datasetseries member resource.\n                Currently, this will always be distributions.\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries/{series}\"\n        ds_mem_res_df = Fusion._call_for_dataframe(url, self.session)\n\n        if output:\n            pass\n\n        return ds_mem_res_df\n\n    def list_distributions(\n        self,\n        dataset: str,\n        series: str,\n        catalog: str | None = None,\n        output: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"List the available distributions (downloadable instances of the dataset with a format type).\n\n        Args:\n            dataset (str): A dataset identifier\n            series (str): The datasetseries identifier\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n\n        Returns:\n            class:`pandas.DataFrame`: A dataframe with a row for each distribution.\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries/{series}/distributions\"\n        distros_df = Fusion._call_for_dataframe(url, self.session)\n\n        if output:\n            pass\n\n        return distros_df\n\n    def _resolve_distro_tuples(\n        self,\n        dataset: str,\n        dt_str: str = \"latest\",\n        dataset_format: str = \"parquet\",\n        catalog: str | None = None,\n    ) -&gt; list[tuple[str, str, str, str]]:\n        \"\"\"Resolve distribution tuples given specification params.\n\n        A private utility function to generate a list of distribution tuples.\n        Each tuple is a distribution, identified by catalog, dataset id,\n        datasetseries member id, and the file format.\n\n        Args:\n            dataset (str): A dataset identifier\n            dt_str (str, optional): Either a single date or a range identified by a start or end date,\n                or both separated with a \":\". Defaults to 'latest' which will return the most recent\n                instance of the dataset.\n            dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n\n        Returns:\n            list: a list of tuples, one for each distribution\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        datasetseries_list = self.list_datasetmembers(dataset, catalog)\n        if len(datasetseries_list) == 0:\n            raise AssertionError(f\"There are no dataset members for dataset {dataset} in catalog {catalog}\")\n\n        if datasetseries_list.empty:\n            raise APIResponseError(  # pragma: no cover\n                ValueError(\n                    f\"No data available for dataset {dataset}. \"\n                    f\"Check that a valid dataset identifier and date/date range has been set.\"\n                ),\n                status_code=404,\n            )\n\n        if dt_str == \"latest\":\n            dt_str = (\n                datasetseries_list[\n                    datasetseries_list[\"createdDate\"] == datasetseries_list[\"createdDate\"].to_numpy().max()\n                ]\n                .sort_values(by=\"identifier\")\n                .iloc[-1][\"identifier\"]\n            )\n            datasetseries_list = datasetseries_list[datasetseries_list[\"identifier\"] == dt_str]\n        else:\n            parsed_dates = normalise_dt_param_str(dt_str)\n            if len(parsed_dates) == 1:\n                parsed_dates = (parsed_dates[0], parsed_dates[0])\n\n            if parsed_dates[0]:\n                datasetseries_list = datasetseries_list[\n                    pd.Series([pd.to_datetime(i, errors=\"coerce\") for i in datasetseries_list[\"identifier\"]])\n                    &gt;= pd.to_datetime(parsed_dates[0])\n                ].reset_index()\n\n            if parsed_dates[1]:\n                datasetseries_list = datasetseries_list[\n                    pd.Series([pd.to_datetime(i, errors=\"coerce\") for i in datasetseries_list[\"identifier\"]])\n                    &lt;= pd.to_datetime(parsed_dates[1])\n                ].reset_index()\n\n        if len(datasetseries_list) == 0:\n            raise APIResponseError(  # pragma: no cover\n                ValueError(\n                    f\"No data available for dataset {dataset} in catalog {catalog}.\\n\"\n                    f\"Check that a valid dataset identifier and date/date range has been set.\"\n                ),\n                status_code=404,\n            )\n\n        required_series = list(datasetseries_list[\"@id\"])\n        tups = [(catalog, dataset, series, dataset_format) for series in required_series]\n\n        return tups\n\n    def download(  # noqa: PLR0912, PLR0913\n        self,\n        dataset: str,\n        dt_str: str = \"latest\",\n        dataset_format: str | None = \"parquet\",\n        catalog: str | None = None,\n        n_par: int | None = None,\n        show_progress: bool = True,\n        force_download: bool = False,\n        download_folder: str | None = None,\n        return_paths: bool = False,\n        partitioning: str | None = None,\n        preserve_original_name: bool = False,\n    ) -&gt; list[tuple[bool, str, str | None]] | None:\n        \"\"\"Downloads the requested distributions of a dataset to disk.\n\n        Args:\n            dataset (str): A dataset identifier\n            dt_str (str, optional): Either a single date or a range identified by a start or end date,\n                or both separated with a \":\". Defaults to 'latest' which will return the most recent\n                instance of the dataset. If more than one series member exists on the latest date, the\n                series member identifiers will be sorted alphabetically and the last one will be downloaded.\n            dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n                If set to None, the function will download if only one format is available, else it will raise an error.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            n_par (int, optional): Specify how many distributions to download in parallel.\n                Defaults to all cpus available.\n            show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n            force_download (bool, optional): If True then will always download a file even\n                if it is already on disk. Defaults to True.\n            download_folder (str, optional): The path, absolute or relative, where downloaded files are saved.\n                Defaults to download_folder as set in __init__\n            return_paths (bool, optional): Return paths and success statuses of the downloaded files.\n            partitioning (str, optional): Partitioning specification.\n            preserve_original_name (bool, optional): Preserve the original name of the file. Defaults to False.\n\n        Returns:\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        # check access to the dataset\n        dataset_resp = self.session.get(f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}\")\n        requests_raise_for_status(dataset_resp)\n\n        access_status = dataset_resp.json().get(\"status\")\n        if access_status != \"Subscribed\":\n            raise APIResponseError(\n                ValueError(f\"You are not subscribed to {dataset} in catalog {catalog}. Please request access.\"),\n                status_code=401,\n            )\n\n        valid_date_range = re.compile(r\"^(\\d{4}\\d{2}\\d{2})$|^((\\d{4}\\d{2}\\d{2})?([:])(\\d{4}\\d{2}\\d{2})?)$\")\n\n        # check that format is valid and if none, check if there is only one format available\n        available_formats = list(self.list_datasetmembers_distributions(dataset, catalog)[\"format\"].unique())\n        if dataset_format and dataset_format not in available_formats:\n            raise FileFormatError(\n                f\"Dataset format {dataset_format} is not available for {dataset} in catalog {catalog}. \"\n                f\"Available formats are {available_formats}.\"\n            )\n        if dataset_format is None:\n            if len(available_formats) == 1:\n                dataset_format = available_formats[0]\n            else:\n                raise FileFormatError(\n                    f\"Multiple formats found for {dataset} in catalog {catalog}. Dataset format is required to\"\n                    f\"download. Available formats are {available_formats}.\"\n                )\n\n        if valid_date_range.match(dt_str) or dt_str == \"latest\":\n            required_series = self._resolve_distro_tuples(dataset, dt_str, dataset_format, catalog)\n        else:\n            # sample data is limited to csv\n            if dt_str == \"sample\":\n                dataset_format = self.list_distributions(dataset, dt_str, catalog)[\"identifier\"].iloc[0]\n            required_series = [(catalog, dataset, dt_str, dataset_format)] # type: ignore[list-item]\n\n        if dataset_format not in RECOGNIZED_FORMATS + [\"raw\"]:\n            raise FileFormatError(f\"Dataset format {dataset_format} is not supported.\")\n\n        if not download_folder:\n            download_folder = self.download_folder\n\n        download_folders = [download_folder] * len(required_series)\n\n        if partitioning == \"hive\":\n            members = [series[2].strip(\"/\") for series in required_series]\n            download_folders = [\n                f\"{download_folders[i]}/{series[0]}/{series[1]}/{members[i]}\"\n                for i, series in enumerate(required_series)\n            ]\n\n        for d in download_folders:\n            if not self.fs.exists(d):\n                self.fs.mkdir(d, create_parents=True)\n\n        n_par = cpu_count(n_par)\n        download_spec = [\n            {\n                \"lfs\": self.fs,\n                \"rpath\": distribution_to_url(\n                    self.root_url,\n                    series[1],\n                    series[2],\n                    series[3],\n                    series[0],\n                    is_download=True,\n                ),\n                \"lpath\": distribution_to_filename(\n                    download_folders[i],\n                    series[1],\n                    series[2],\n                    series[3],\n                    series[0],\n                    partitioning=partitioning,\n                ),\n                \"overwrite\": force_download,\n                \"preserve_original_name\": preserve_original_name,\n            }\n            for i, series in enumerate(required_series)\n        ]\n\n        logger.log(\n            VERBOSE_LVL,\n            f\"Beginning {len(download_spec)} downloads in batches of {n_par}\",\n        )\n        if show_progress:\n            with Progress() as p:\n                task = p.add_task(\"Downloading\", total=len(download_spec))\n                res = []\n                for spec in download_spec:\n                    r = self.get_fusion_filesystem().download(**spec)\n                    res.append(r)\n                    p.update(task, advance=1)\n        else:\n            res = [self.get_fusion_filesystem().download(**spec) for spec in download_spec]\n\n        if (len(res) &gt; 0) and (not all(r[0] for r in res)):\n            for r in res:\n                if not r[0]:\n                    warnings.warn(f\"The download of {r[1]} was not successful\", stacklevel=2)\n        return res if return_paths else None\n\n    async def _async_stream_file(self, url: str, chunk_size: int = 100) -&gt; AsyncGenerator[bytes, None]:\n        \"\"\"Return async stream of a file fro mthe given url.\n\n        Args:\n            url (str): File url. Appends Fusion.root_url if http prefix not present.\n            chunk_size (int, optional): Size for each chunk in async stream. Defaults to 100.\n\n        Returns:\n            AsyncGenerator[bytes, None]: Async generator object.\n\n        Yields:\n            Iterator[AsyncGenerator[bytes, None]]: Next set of bytes read from the file at given url.\n        \"\"\"\n        dup_credentials = copy.deepcopy(self.credentials)\n        async_fs = FusionHTTPFileSystem(\n            client_kwargs={\"root_url\": self.root_url, \"credentials\": dup_credentials}, asynchronous=True\n        )\n        session = await async_fs.set_session()\n        async with session:\n            async for chunk in async_fs._stream_file(url, chunk_size):\n                yield chunk\n\n    async def _async_get_file(self, url: str, chunk_size: int = 1000) -&gt; bytes:\n        \"\"\"Return a file from url as a bytes object, asynchronously.\n\n        Under the hood, opens up an async stream downloading file in chunk_size bytes per chunk.\n        Larger chunk sizes results in shorter execution time for this function.\n\n        Args:\n            url (str): File url. Appends Fusion.root_url if http prefix not present.\n            chunk_size (int, optional): Size of chunks to get from async stream. Defaults to 1000.\n\n        Returns:\n            bytes: File from url as a bytes object.\n        \"\"\"\n        async_generator = self._async_stream_file(url, chunk_size)\n        bytes_list: list[bytes] = [chunk async for chunk in async_generator]\n        final_bytes: bytes = b\"\".join(bytes_list)\n        return final_bytes\n\n    def to_df(  # noqa: PLR0913\n        self,\n        dataset: str,\n        dt_str: str = \"latest\",\n        dataset_format: str = \"parquet\",\n        catalog: str | None = None,\n        n_par: int | None = None,\n        show_progress: bool = True,\n        columns: list[str] | None = None,\n        filters: PyArrowFilterT | None = None,\n        force_download: bool = False,\n        download_folder: str | None = None,\n        dataframe_type: str = \"pandas\",\n        **kwargs: Any,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Gets distributions for a specified date or date range and returns the data as a dataframe.\n\n        Args:\n            dataset (str): A dataset identifier\n            dt_str (str, optional): Either a single date or a range identified by a start or end date,\n                or both separated with a \":\". Defaults to 'latest' which will return the most recent\n                instance of the dataset.\n            dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            n_par (int, optional): Specify how many distributions to download in parallel.\n                Defaults to all cpus available.\n            show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n            columns (List, optional): A list of columns to return from a parquet file. Defaults to None\n            filters (List, optional): List[Tuple] or List[List[Tuple]] or None (default)\n                Rows which do not match the filter predicate will be removed from scanned data.\n                Partition keys embedded in a nested directory structure will be exploited to avoid\n                loading files at all if they contain no matching rows. If use_legacy_dataset is True,\n                filters can only reference partition keys and only a hive-style directory structure\n                is supported. When setting use_legacy_dataset to False, also within-file level filtering\n                and different partitioning schemes are supported.\n                More on https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html\n            force_download (bool, optional): If True then will always download a file even\n                if it is already on disk. Defaults to False.\n            download_folder (str, optional): The path, absolute or relative, where downloaded files are saved.\n                Defaults to download_folder as set in __init__\n            dataframe_type (str, optional): Type\n        Returns:\n            class:`pandas.DataFrame`: a dataframe containing the requested data.\n                If multiple dataset instances are retrieved then these are concatenated first.\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        # sample data is limited to csv\n        if dt_str == \"sample\":\n            dataset_format = \"csv\"\n\n        if not download_folder:\n            download_folder = self.download_folder\n\n        download_res = self.download(\n            dataset,\n            dt_str,\n            dataset_format,\n            catalog,\n            n_par,\n            show_progress,\n            force_download,\n            download_folder,\n            return_paths=True,\n        )\n\n        if not download_res:\n            raise ValueError(\"Must specify 'return_paths=True' in download call to use this function\")\n\n        if not all(res[0] for res in download_res):\n            failed_res = [res for res in download_res if not res[0]]\n            raise Exception(\n                f\"Not all downloads were successfully completed. \"\n                f\"Re-run to collect missing files. The following failed:\\n{failed_res}\"\n            )\n\n        files = [res[1] for res in download_res]\n\n        pd_read_fn_map = {\n            \"csv\": read_csv,\n            \"parquet\": read_parquet,\n            \"parq\": read_parquet,\n            \"json\": read_json,\n            \"raw\": read_csv,\n        }\n\n        pd_read_default_kwargs: dict[str, dict[str, object]] = {\n            \"csv\": {\n                \"columns\": columns,\n                \"filters\": filters,\n                \"fs\": self.fs,\n                \"dataframe_type\": dataframe_type,\n            },\n            \"parquet\": {\n                \"columns\": columns,\n                \"filters\": filters,\n                \"fs\": self.fs,\n                \"dataframe_type\": dataframe_type,\n            },\n            \"json\": {\n                \"columns\": columns,\n                \"filters\": filters,\n                \"fs\": self.fs,\n                \"dataframe_type\": dataframe_type,\n            },\n            \"raw\": {\n                \"columns\": columns,\n                \"filters\": filters,\n                \"fs\": self.fs,\n                \"dataframe_type\": dataframe_type,\n            },\n        }\n\n        pd_read_default_kwargs[\"parq\"] = pd_read_default_kwargs[\"parquet\"]\n\n        pd_reader = pd_read_fn_map.get(dataset_format)\n        pd_read_kwargs = pd_read_default_kwargs.get(dataset_format, {})\n        if not pd_reader:\n            raise Exception(f\"No pandas function to read file in format {dataset_format}\")\n\n        pd_read_kwargs.update(kwargs)\n\n        if len(files) == 0:\n            raise APIResponseError(\n                Exception(\n                    f\"No series members for dataset: {dataset} in date or date range: {dt_str} \"\n                    f\"and format: {dataset_format}\"\n                ),\n                status_code=404,\n            )\n        if dataset_format in [\"parquet\", \"parq\"]:\n            data_df = pd_reader(files, **pd_read_kwargs)  # type: ignore\n        elif dataset_format == \"raw\":\n            dataframes = (\n                pd.concat(\n                    [pd_reader(ZipFile(f).open(p), **pd_read_kwargs) for p in ZipFile(f).namelist()],  # type: ignore  # noqa: SIM115\n                    ignore_index=True,\n                )\n                for f in files\n            )\n            data_df = pd.concat(dataframes, ignore_index=True)\n        else:\n            dataframes = (pd_reader(f, **pd_read_kwargs) for f in files)  # type: ignore\n            if dataframe_type == \"pandas\":\n                data_df = pd.concat(dataframes, ignore_index=True)\n            if dataframe_type == \"polars\":\n                import polars as pl\n\n                data_df = pl.concat(dataframes, how=\"diagonal\") # type: ignore\n\n        return data_df\n\n    def to_bytes(\n        self,\n        dataset: str,\n        series_member: str,\n        dataset_format: str = \"parquet\",\n        catalog: str | None = None,\n    ) -&gt; BytesIO:\n        \"\"\"Returns an instance of dataset (the distribution) as a bytes object.\n\n        Args:\n            dataset (str): A dataset identifier\n            series_member (str,): A dataset series member identifier\n            dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        \"\"\"\n\n        catalog = self._use_catalog(catalog)\n\n        url = distribution_to_url(\n            self.root_url,\n            dataset,\n            series_member,\n            dataset_format,\n            catalog,\n        )\n\n        return Fusion._call_for_bytes_object(url, self.session)\n\n    def to_table(  # noqa: PLR0913\n        self,\n        dataset: str,\n        dt_str: str = \"latest\",\n        dataset_format: str = \"parquet\",\n        catalog: str | None = None,\n        n_par: int | None = None,\n        show_progress: bool = True,\n        columns: list[str] | None = None,\n        filters: PyArrowFilterT | None = None,\n        force_download: bool = False,\n        download_folder: str | None = None,\n        **kwargs: Any,\n    ) -&gt; pa.Table:\n        \"\"\"Gets distributions for a specified date or date range and returns the data as an arrow table.\n\n        Args:\n            dataset (str): A dataset identifier\n            dt_str (str, optional): Either a single date or a range identified by a start or end date,\n                or both separated with a \":\". Defaults to 'latest' which will return the most recent\n                instance of the dataset.\n            dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            n_par (int, optional): Specify how many distributions to download in parallel.\n                Defaults to all cpus available.\n            show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n            columns (List, optional): A list of columns to return from a parquet file. Defaults to None\n            filters (List, optional): List[Tuple] or List[List[Tuple]] or None (default)\n                Rows which do not match the filter predicate will be removed from scanned data.\n                Partition keys embedded in a nested directory structure will be exploited to avoid\n                loading files at all if they contain no matching rows. If use_legacy_dataset is True,\n                filters can only reference partition keys and only a hive-style directory structure\n                is supported. When setting use_legacy_dataset to False, also within-file level filtering\n                and different partitioning schemes are supported.\n                More on https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html\n            force_download (bool, optional): If True then will always download a file even\n                if it is already on disk. Defaults to False.\n            download_folder (str, optional): The path, absolute or relative, where downloaded files are saved.\n                Defaults to download_folder as set in __init__\n        Returns:\n            class:`pyarrow.Table`: a dataframe containing the requested data.\n                If multiple dataset instances are retrieved then these are concatenated first.\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n        n_par = cpu_count(n_par)\n        if not download_folder:\n            download_folder = self.download_folder\n        download_res = self.download(\n            dataset,\n            dt_str,\n            dataset_format,\n            catalog,\n            n_par,\n            show_progress,\n            force_download,\n            download_folder,\n            return_paths=True,\n        )\n\n        if not download_res:\n            raise ValueError(\"Must specify 'return_paths=True' in download call to use this function\")\n\n        if not all(res[0] for res in download_res):\n            failed_res = [res for res in download_res if not res[0]]\n            raise RuntimeError(\n                f\"Not all downloads were successfully completed. \"\n                f\"Re-run to collect missing files. The following failed:\\n{failed_res}\"\n            )\n\n        files = [res[1] for res in download_res]\n\n        read_fn_map = {\n            \"csv\": csv_to_table,\n            \"parquet\": parquet_to_table,\n            \"parq\": parquet_to_table,\n            \"json\": json_to_table,\n            \"raw\": csv_to_table,\n        }\n\n        read_default_kwargs: dict[str, dict[str, object]] = {\n            \"csv\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n            \"parquet\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n            \"json\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n            \"raw\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n        }\n\n        read_default_kwargs[\"parq\"] = read_default_kwargs[\"parquet\"]\n\n        reader = read_fn_map.get(dataset_format)\n        read_kwargs = read_default_kwargs.get(dataset_format, {})\n        if not reader:\n            raise AssertionError(f\"No function to read file in format {dataset_format}\")\n\n        read_kwargs.update(kwargs)\n\n        if len(files) == 0:\n            raise APIResponseError(\n                Exception(\n                    f\"No series members for dataset: {dataset} in date or date range: {dt_str} \"\n                    f\"and format: {dataset_format}\"\n                ),\n                status_code=404,\n            )\n        if dataset_format in [\"parquet\", \"parq\"]:\n            tbl = reader(files, **read_kwargs)  # type: ignore\n        else:\n            tbl = (reader(f, **read_kwargs) for f in files)  # type: ignore\n            tbl = pa.concat_tables(tbl)\n\n        return tbl\n\n    def upload(  # noqa: PLR0912, PLR0913, PLR0915\n        self,\n        path: str,\n        dataset: str | None = None,\n        dt_str: str = \"latest\",\n        catalog: str | None = None,\n        n_par: int | None = None,\n        show_progress: bool = True,\n        return_paths: bool = False,\n        multipart: bool = True,\n        chunk_size: int = 5 * 2**20,\n        from_date: str | None = None,\n        to_date: str | None = None,\n        preserve_original_name: bool | None = False,\n        additional_headers: dict[str, str] | None = None,\n    ) -&gt; list[tuple[bool, str, str | None]] | None:\n        \"\"\"Uploads the requested files/files to Fusion.\n\n        Args:\n            path (str): path to a file or a folder with sub folders and files\n            dataset (str, optional): Dataset identifier to which the files will be uploaded.\n                                    If not provided the dataset will be implied from file's name.\n                                    This is mandatory when uploading a directory.\n            dt_str (str, optional): A file name. Can be any string but is usually a date.\n                                    Defaults to 'latest' which will return the most recent.\n                                    Relevant for a single file upload only. If not provided the dataset will\n                                    be implied from file's name. dt_str will be ignored when uploading \n                                    a directory.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            n_par (int, optional): Specify how many distributions to upload in parallel.\n                Defaults to all cpus available.\n            show_progress (bool, optional): Display a progress bar during data upload Defaults to True.\n            return_paths (bool, optional): Return paths and success statuses of the uploaded files.\n            multipart (bool, optional): Is multipart upload. Defaults to True.\n            chunk_size (int, optional): Maximum chunk size.\n            from_date (str, optional): start of the data date range contained in the distribution,\n                defaults to upoad date\n            to_date (str, optional): end of the data date range contained in the distribution,\n                defaults to upload date.\n            preserve_original_name (bool, optional): Preserve the original name of the file. Defaults to False.\n                Original name not preserved when uploading a directory.\n\n        Returns:\n\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        if not self.fs.exists(path):\n            raise RuntimeError(\"The provided path does not exist\")\n\n        fs_fusion = self.get_fusion_filesystem()\n        if self.fs.info(path)[\"type\"] == \"directory\":\n            validate_file_formats(self.fs, path)\n            if dt_str and dt_str != \"latest\":\n                logger.warning(\"`dt_str` is not considered when uploading a directory. \"\n                                \"File names in the directory are used as series members instead.\")\n\n            file_path_lst = [f for f in self.fs.find(path) if self.fs.info(f)[\"type\"] == \"file\"]\n\n            base_path = Path(path).resolve()\n            # Construct unique file names by flattening the relative path from the base directory.\n            # For example, if the base directory is 'data_folder' and a file is at 'data_folder/sub1/file.txt',\n            # the resulting name will be 'data_folder__sub1__file.txt'.\n            # This ensures that files in different subdirectories with the same base name do not conflict\n            # and helps preserve the folder structure in the filename.  \n            file_name = [\n                base_path.name + \"__\" + \"__\".join(Path(f).resolve().relative_to(base_path).parts)\n                for f in file_path_lst\n            ]\n\n            if catalog and dataset:\n                # Construct URL mappings using the constructed file names as the series member\n                local_url_eqiv = [\n                    file_name_to_url(fname, dataset, catalog, is_download=False)\n                    for fname in file_name\n                ]\n            else:\n                # No catalog/dataset: validate file names and infer raw\n                local_file_validation = validate_file_names(file_path_lst)\n                file_path_lst = [f for flag, f in zip(local_file_validation, file_path_lst) if flag]\n                file_name = [f.split(\"/\")[-1] for f in file_path_lst]\n                is_raw_lst = is_dataset_raw(file_path_lst, fs_fusion)\n                local_url_eqiv = [path_to_url(i, r) for i, r in zip(file_path_lst, is_raw_lst)]\n        else:\n            file_path_lst = [path]\n            if not catalog or not dataset:\n                local_file_validation = validate_file_names(file_path_lst)\n                file_path_lst = [f for flag, f in zip(local_file_validation, file_path_lst) if flag]\n                is_raw_lst = is_dataset_raw(file_path_lst, fs_fusion)\n                local_url_eqiv = [path_to_url(i, r) for i, r in zip(file_path_lst, is_raw_lst)]\n                if preserve_original_name:\n                    raise ValueError(\"preserve_original_name can only be used when catalog and dataset are provided.\")\n            else:\n                # Normalize the dt_str\n                date_identifier = re.compile(r\"^(\\d{4})(\\d{2})(\\d{2})$\")\n                if dt_str == \"latest\":\n                    dt_str = pd.Timestamp(\"today\").date().strftime(\"%Y%m%d\")\n                elif date_identifier.match(dt_str):\n                    dt_str = pd.Timestamp(dt_str).date().strftime(\"%Y%m%d\")\n\n                file_format = path.split(\".\")[-1]\n                file_name = [path.split(\"/\")[-1]]\n                file_format = \"raw\" if file_format not in RECOGNIZED_FORMATS else file_format\n\n                local_url_eqiv = [\n                    \"/\".join(distribution_to_url(\"\", dataset, dt_str, file_format, catalog, False).split(\"/\")[1:])\n                ]\n\n        if self.fs.info(path)[\"type\"] == \"directory\" or preserve_original_name:\n            data_map_df = pd.DataFrame([file_path_lst, local_url_eqiv, file_name]).T\n            data_map_df.columns = pd.Index([\"path\", \"url\", \"file_name\"])\n        else:\n            data_map_df = pd.DataFrame([file_path_lst, local_url_eqiv]).T\n            data_map_df.columns = pd.Index([\"path\", \"url\"])\n\n        n_par = cpu_count(n_par)\n        res = upload_files(\n            fs_fusion,\n            self.fs,\n            data_map_df,\n            multipart=multipart,\n            chunk_size=chunk_size,\n            show_progress=show_progress,\n            from_date=from_date,\n            to_date=to_date,\n            additional_headers=additional_headers,\n        )\n\n        if not all(r[0] for r in res):\n            failed_res = [r for r in res if not r[0]]\n            msg = f\"Not all uploads were successfully completed. The following failed:\\n{failed_res}\"\n            logger.warning(msg)\n            warnings.warn(msg, stacklevel=2)\n\n        return res if return_paths else None\n\n    def from_bytes(  # noqa: PLR0913\n        self,\n        data: BytesIO,\n        dataset: str,\n        series_member: str = \"latest\",\n        catalog: str | None = None,\n        distribution: str = \"parquet\",\n        show_progress: bool = True,\n        multipart: bool = True,\n        return_paths: bool = False,\n        chunk_size: int = 5 * 2**20,\n        from_date: str | None = None,\n        to_date: str | None = None,\n        file_name: str | None = None,\n        **kwargs: Any,  # noqa: ARG002\n    ) -&gt; list[tuple[bool, str, str | None]] | None:\n        \"\"\"Uploads data from an object in memory.\n\n        Args:\n            data (str): an object in memory to upload\n            dataset (str): Dataset name to which the bytes will be uploaded.\n            series_member (str, optional): A single date or label. Defaults to 'latest' which will return\n                the most recent.\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            distribution (str, optional): A distribution type, e.g. a file format or raw\n            show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n            multipart (bool, optional): Is multipart upload.\n            return_paths (bool, optional): Return paths and success statuses of the downloaded files.\n            chunk_size (int, optional): Maximum chunk size.\n            from_date (str, optional): start of the data date range contained in the distribution,\n                defaults to upload date\n            to_date (str, optional): end of the data date range contained in the distribution, defaults to upload date.\n            file_name (str, optional): file name to be used for the uploaded file. Defaults to Fusion standard naming.\n\n        Returns:\n            Optional[list[tuple[bool, str, Optional[str]]]: a list of tuples, one for each distribution\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        fs_fusion = self.get_fusion_filesystem()\n        if distribution not in RECOGNIZED_FORMATS + [\"raw\"]:\n            raise ValueError(f\"Dataset format {distribution} is not supported\")\n\n        is_raw = js.loads(fs_fusion.cat(f\"{catalog}/datasets/{dataset}\"))[\"isRawData\"]\n        local_url_eqiv = path_to_url(f\"{dataset}__{catalog}__{series_member}.{distribution}\", is_raw)\n\n        data_map_df = pd.DataFrame([\"\", local_url_eqiv, file_name]).T\n        data_map_df.columns = [\"path\", \"url\", \"file_name\"]  # type: ignore[assignment]\n\n        res = upload_files(\n            fs_fusion,\n            data,\n            data_map_df,\n            multipart=multipart,\n            chunk_size=chunk_size,\n            show_progress=show_progress,\n            from_date=from_date,\n            to_date=to_date,\n        )\n\n        if not all(r[0] for r in res):\n            failed_res = [r for r in res if not r[0]]\n            msg = f\"Not all uploads were successfully completed. The following failed:\\n{failed_res}\"\n            logger.warning(msg)\n            warnings.warn(msg, stacklevel=2)\n\n        return res if return_paths else None\n\n    def listen_to_events(\n        self,\n        last_event_id: str | None = None,\n        catalog: str | None = None,\n        url: str | None = None,\n    ) -&gt; None:\n        \"\"\"Run server sent event listener in the background. Retrieve results by running get_events.\n\n        Args:\n            last_event_id (str): Last event ID (exclusive).\n            catalog (str): catalog.\n            url (str): subscription url. Defaults to client's root url.\n        Returns:\n            None\n        \"\"\"\n\n        catalog = self._use_catalog(catalog)\n        url = self.root_url if url is None else url\n\n        import asyncio\n        import json\n        import threading\n\n        from aiohttp_sse_client import client as sse_client\n\n        from .utils import get_client\n\n        kwargs: dict[str, Any] = {}\n        if last_event_id:\n            kwargs = {\"headers\": {\"Last-Event-ID\": last_event_id}}\n\n        async def async_events() -&gt; None:\n            \"\"\"Events sync function.\n\n            Returns:\n                None\n            \"\"\"\n            timeout = 1e100\n            session = await get_client(self.credentials, timeout=timeout)\n            async with sse_client.EventSource(\n                f\"{url}catalogs/{catalog}/notifications/subscribe\",\n                session=session,\n                **kwargs,\n            ) as messages:\n                lst = []\n                try:\n                    async for msg in messages:\n                        event = json.loads(msg.data)\n                        # Preserve the original metaData column\n                        original_meta_data = event.get(\"metaData\", {})\n\n                        # Flatten the metaData dictionary into the event dictionary\n                        if isinstance(original_meta_data, dict):\n                            event.update(original_meta_data)\n                        lst.append(event)\n                        if self.events is None:\n                            self.events = pd.DataFrame()\n                        else:\n                            self.events = pd.concat([self.events, pd.DataFrame(lst)], ignore_index=True)\n                            self.events = self.events.drop_duplicates(\n                                subset=[\"id\", \"type\", \"timestamp\"], ignore_index=True\n                            )\n                except TimeoutError as ex:\n                    raise ex from None\n                except BaseException:\n                    raise\n\n        _ = self.catalog_resources()  # refresh token\n        if \"headers\" in kwargs:\n            kwargs[\"headers\"].update({\"authorization\": f\"bearer {self.credentials.bearer_token}\"})\n        else:\n            kwargs[\"headers\"] = {\n                \"authorization\": f\"bearer {self.credentials.bearer_token}\",\n            }\n        if \"http\" in self.credentials.proxies:\n            kwargs[\"proxy\"] = self.credentials.proxies[\"http\"]\n        elif \"https\" in self.credentials.proxies:\n            kwargs[\"proxy\"] = self.credentials.proxies[\"https\"]\n        th = threading.Thread(target=asyncio.run, args=(async_events(),), daemon=True)\n        th.start()\n\n    def get_events(\n        self,\n        last_event_id: str | None = None,\n        catalog: str | None = None,\n        in_background: bool = True,\n        url: str | None = None,\n    ) -&gt; None | pd.DataFrame:\n        \"\"\"Run server sent event listener and print out the new events. Keyboard terminate to stop.\n\n        Args:\n            last_event_id (str): id of the last event.\n            catalog (str): catalog.\n            in_background (bool): execute event monitoring in the background (default = True).\n            url (str): subscription url. Defaults to client's root url.\n        Returns:\n            Union[None, class:`pandas.DataFrame`]: If in_background is True then the function returns no output.\n                If in_background is set to False then pandas DataFrame is output upon keyboard termination.\n        \"\"\"\n\n        catalog = self._use_catalog(catalog)\n        url = self.root_url if url is None else url\n\n        if not in_background:\n            from sseclient import SSEClient\n\n            _ = self.catalog_resources()  # refresh token\n            interrupted = False\n            messages = SSEClient(\n                session=self.session,\n                url=f\"{url}catalogs/{catalog}/notifications/subscribe\",\n                last_id=last_event_id,\n                headers={\n                    \"authorization\": f\"bearer {self.credentials.bearer_token}\",\n                },\n            )\n            lst = []\n            try:\n                for msg in messages:\n                    event = js.loads(msg.data)\n                    # Preserve the original metaData column\n                    original_meta_data = event.get(\"metaData\", {})\n\n                    # Flatten the metaData dictionary into the event dictionary\n                    if isinstance(original_meta_data, dict):\n                        event.update(original_meta_data)\n\n                    if event[\"type\"] != \"HeartBeatNotification\":\n                        lst.append(event)\n            except KeyboardInterrupt:\n                interrupted = True\n            except Exception as e:\n                raise e\n            finally:\n                result = pd.DataFrame(lst) if interrupted or lst else None\n            return result\n        else:\n            return self.events\n\n    def list_dataset_lineage(\n        self,\n        dataset_id: str,\n        catalog: str | None = None,\n        output: bool = False,\n        max_results: int = -1,\n    ) -&gt; pd.DataFrame:\n        \"\"\"List the upstream and downstream lineage of the dataset.\n\n        Args:\n            dataset (str): A dataset identifier\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n            max_results (int, optional): Limit the number of rows returned in the dataframe.\n                Defaults to -1 which returns all results.\n\n        Returns:\n            class:`pandas.DataFrame`: A dataframe with a row for each resource\n\n        Raises:\n            HTTPError: If the dataset is not found in the catalog.\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url_dataset = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset_id}\"\n        resp_dataset = self.session.get(url_dataset)\n        resp_dataset.raise_for_status()\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset_id}/lineage\"\n        resp = self.session.get(url)\n        data = resp.json()\n        relations_data = data[\"relations\"]\n\n        restricted_datasets = [\n            dataset_metadata[\"identifier\"]\n            for dataset_metadata in data[\"datasets\"]\n            if dataset_metadata.get(\"status\", None) == \"Restricted\"\n        ]\n\n        data_dict = {}\n\n        for entry in relations_data:\n            source_dataset_id = entry[\"source\"][\"dataset\"]\n            source_catalog = entry[\"source\"][\"catalog\"]\n            destination_dataset_id = entry[\"destination\"][\"dataset\"]\n            destination_catalog = entry[\"destination\"][\"catalog\"]\n\n            if destination_dataset_id == dataset_id:\n                for dataset in data[\"datasets\"]:\n                    if dataset[\"identifier\"] == source_dataset_id and dataset.get(\"status\", None) != \"Restricted\":\n                        source_dataset_title = dataset[\"title\"]\n                    elif dataset[\"identifier\"] == source_dataset_id and dataset.get(\"status\", None) == \"Restricted\":\n                        source_dataset_title = \"Access Restricted\"\n                data_dict[source_dataset_id] = (\n                    \"source\",\n                    source_catalog,\n                    source_dataset_title,\n                )\n\n            if source_dataset_id == dataset_id:\n                for dataset in data[\"datasets\"]:\n                    if dataset[\"identifier\"] == destination_dataset_id and dataset.get(\"status\", None) != \"Restricted\":\n                        destination_dataset_title = dataset[\"title\"]\n                    elif (\n                        dataset[\"identifier\"] == destination_dataset_id and dataset.get(\"status\", None) == \"Restricted\"\n                    ):\n                        destination_dataset_title = \"Access Restricted\"\n                data_dict[destination_dataset_id] = (\n                    \"produced\",\n                    destination_catalog,\n                    destination_dataset_title,\n                )\n\n        output_data = {\n            \"type\": [v[0] for v in data_dict.values()],\n            \"dataset_identifier\": list(data_dict.keys()),\n            \"title\": [v[2] for v in data_dict.values()],\n            \"catalog\": [v[1] for v in data_dict.values()],\n        }\n\n        lineage_df = pd.DataFrame(output_data)\n        lineage_df.loc[\n            lineage_df[\"dataset_identifier\"].isin(restricted_datasets),\n            [\"dataset_identifier\", \"catalog\", \"title\"],\n        ] = \"Access Restricted\"\n\n        if max_results &gt; -1:\n            lineage_df = lineage_df[0:max_results]\n\n        if output:\n            pass\n\n        return lineage_df\n\n    def create_dataset_lineage(\n        self,\n        base_dataset: str,\n        source_dataset_catalog_mapping: pd.DataFrame | list[dict[str, str]],\n        catalog: str | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Upload lineage to a dataset.\n\n        Args:\n            base_dataset (str): A dataset identifier to which you want to add lineage.\n            source_dataset_catalog_mapping (Union[pd.DataFrame, list[dict[str]]]): Mapping for the dataset\n                identifier(s) and catalog(s) from which to add lineage.\n            catalog (Optional[str], optional): Catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Raises:\n            ValueError: If source_dataset_catalog_mapping is not a pandas DataFrame or a list of dictionaries\n            HTTPError: If the request is unsuccessful.\n\n        Examples:\n            Creating lineage from a pandas DataFrame.\n            &gt;&gt;&gt; data = [{\"dataset\": \"a\", \"catalog\": \"a\"}, {\"dataset\": \"b\", \"catalog\": \"b\"}]\n            &gt;&gt;&gt; df = pd.DataFrame(data)\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.create_dataset_lineage(base_dataset=\"c\", source_dataset_catalog_mapping=df, catalog=\"c\")\n\n            Creating lineage from a list of dictionaries.\n            &gt;&gt;&gt; data = [{\"dataset\": \"a\", \"catalog\": \"a\"}, {\"dataset\": \"b\", \"catalog\": \"b\"}]\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.create_dataset_lineage(base_dataset=\"c\", source_dataset_catalog_mapping=data, catalog=\"c\")\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        if isinstance(source_dataset_catalog_mapping, pd.DataFrame):\n            dataset_mapping_list = [\n                {\"dataset\": row[\"dataset\"], \"catalog\": row[\"catalog\"]}\n                for _, row in source_dataset_catalog_mapping.iterrows()\n            ]\n        elif isinstance(source_dataset_catalog_mapping, list):\n            dataset_mapping_list = source_dataset_catalog_mapping\n        else:\n            raise ValueError(\"source_dataset_catalog_mapping must be a pandas DataFrame or a list of dictionaries.\")\n        data = {\"source\": dataset_mapping_list}\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{base_dataset}/lineage\"\n\n        resp = self.session.post(url, json=data)\n\n        resp.raise_for_status()\n\n        return resp if return_resp_obj else None\n\n    def list_product_dataset_mapping(\n        self,\n        dataset: str | list[str] | None = None,\n        product: str | list[str] | None = None,\n        catalog: str | None = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"get the product to dataset linking contained in  a catalog. A product is a grouping of datasets.\n\n        Args:\n            dataset (str | list[str] | None, optional): A string or list of strings that are dataset\n            identifiers to filter the output. If a list is provided then it will return\n            datasets whose identifier matches any of the strings. Defaults to None.\n            product (str | list[str] | None, optional): A string or list of strings that are product\n            identifiers to filter the output. If a list is provided then it will return\n            products whose identifier matches any of the strings. Defaults to None.\n            catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n\n        Returns:\n            pd.DataFrame: a dataframe with a row  for each dataset to product mapping.\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n        url = f\"{self.root_url}catalogs/{catalog}/productDatasets\"\n        mapping_df = pd.DataFrame(self._call_for_dataframe(url, self.session))\n\n        if dataset:\n            if isinstance(dataset, list):\n                contains = \"|\".join(f\"{s}\" for s in dataset)\n                mapping_df = mapping_df[mapping_df[\"dataset\"].str.contains(contains, case=False)]\n            if isinstance(dataset, str):\n                mapping_df = mapping_df[mapping_df[\"dataset\"].str.contains(dataset, case=False)]\n        if product:\n            if isinstance(product, list):\n                contains = \"|\".join(f\"{s}\" for s in product)\n                mapping_df = mapping_df[mapping_df[\"product\"].str.contains(contains, case=False)]\n            if isinstance(product, str):\n                mapping_df = mapping_df[mapping_df[\"product\"].str.contains(product, case=False)]\n        return mapping_df\n\n    def product(  # noqa: PLR0913\n        self,\n        identifier: str,\n        title: str = \"\",\n        category: str | list[str] | None = None,\n        short_abstract: str = \"\",\n        description: str = \"\",\n        is_active: bool = True,\n        is_restricted: bool | None = None,\n        maintainer: str | list[str] | None = None,\n        region: str | list[str] = \"Global\",\n        publisher: str = \"J.P. Morgan\",\n        sub_category: str | list[str] | None = None,\n        tag: str | list[str] | None = None,\n        delivery_channel: str | list[str] = \"API\",\n        theme: str | None = None,\n        release_date: str | None = None,\n        language: str = \"English\",\n        status: str = \"Available\",\n        image: str = \"\",\n        logo: str = \"\",\n        dataset: str | list[str] | None = None,\n        **kwargs: Any,\n    ) -&gt; Product:\n        \"\"\"Instantiate a Product object with this client for metadata creation.\n\n        Args:\n            identifier (str): Product identifier.\n            title (str, optional): Product title. If not provided, defaults to identifier.\n            category (str | list[str] | None, optional): Category. Defaults to None.\n            short_abstract (str, optional): Short description. Defaults to \"\".\n            description (str, optional): Description. If not provided, defaults to identifier.\n            is_active (bool, optional): Boolean for Active status. Defaults to True.\n            is_restricted (bool | None, optional): Flag for restricted products. Defaults to None.\n            maintainer (str | list[str] | None, optional): Product maintainer. Defaults to None.\n            region (str | list[str] | None, optional): Product region. Defaults to None.\n            publisher (str | None, optional): Name of vendor that publishes the data. Defaults to None.\n            sub_category (str | list[str] | None, optional): Product sub-category. Defaults to None.\n            tag (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n            delivery_channel (str | list[str], optional): Product delivery channel. Defaults to \"API\".\n            theme (str | None, optional): Product theme. Defaults to None.\n            release_date (str | None, optional): Product release date. Defaults to None.\n            language (str, optional): Product language. Defaults to \"English\".\n            status (str, optional): Product status. Defaults to \"Available\".\n            image (str, optional): Product image. Defaults to \"\".\n            logo (str, optional): Product logo. Defaults to \"\".\n            dataset (str | list[str] | None, optional): Product datasets. Defaults to None.\n\n        Returns:\n            Product: Fusion Product class instance.\n\n        Examples:\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.product(identifier=\"PRODUCT_1\", title=\"Product\")\n\n        Note:\n            See the product module for more information on functionalities of product objects.\n\n        \"\"\"\n        product_obj = Product(\n            identifier=identifier,\n            title=title,\n            category=category,\n            short_abstract=short_abstract,\n            description=description,\n            is_active=is_active,\n            is_restricted=is_restricted,\n            maintainer=maintainer,\n            region=region,\n            publisher=publisher,\n            sub_category=sub_category,\n            tag=tag,\n            delivery_channel=delivery_channel,\n            theme=theme,\n            release_date=release_date,\n            language=language,\n            status=status,\n            image=image,\n            logo=logo,\n            dataset=dataset,\n            **kwargs,\n        )\n        product_obj.client = self\n        return product_obj\n\n    def dataset(  # noqa: PLR0913\n        self,\n        identifier: str,\n        title: str = \"\",\n        category: str | list[str] | None = None,\n        description: str = \"\",\n        frequency: str = \"Once\",\n        is_internal_only_dataset: bool = False,\n        is_third_party_data: bool = True,\n        is_restricted: bool | None = None,\n        is_raw_data: bool = True,\n        maintainer: str | None = \"J.P. Morgan Fusion\",\n        source: str | list[str] | None = None,\n        region: str | list[str] | None = None,\n        publisher: str = \"J.P. Morgan\",\n        product: str | list[str] | None = None,\n        sub_category: str | list[str] | None = None,\n        tags: str | list[str] | None = None,\n        created_date: str | None = None,\n        modified_date: str | None = None,\n        delivery_channel: str | list[str] = \"API\",\n        language: str = \"English\",\n        status: str = \"Available\",\n        type_: str | None = \"Source\",\n        container_type: str | None = \"Snapshot-Full\",\n        snowflake: str | None = None,\n        complexity: str | None = None,\n        is_immutable: bool | None = None,\n        is_mnpi: bool | None = None,\n        is_pci: bool | None = None,\n        is_pii: bool | None = None,\n        is_client: bool | None = None,\n        is_public: bool | None = None,\n        is_internal: bool | None = None,\n        is_confidential: bool | None = None,\n        is_highly_confidential: bool | None = None,\n        is_active: bool | None = None,\n        owners: list[str] | None = None,\n        application_id: str | dict[str, str] | None = None,\n        **kwargs: Any,\n    ) -&gt; Dataset:\n        \"\"\"Instantiate a Dataset object with this client for metadata creation.\n\n        Args:\n            identifier (str): Dataset identifier.\n            title (str, optional): Dataset title. If not provided, defaults to identifier.\n            category (str | list[str] | None, optional): A category or list of categories for the dataset.\n            Defaults to None.\n            description (str, optional): Dataset description. If not provided, defaults to identifier.\n            frequency (str, optional): The frequency of the dataset. Defaults to \"Once\".\n            is_internal_only_dataset (bool, optional): Flag for internal datasets. Defaults to False.\n            is_third_party_data (bool, optional): Flag for third party data. Defaults to True.\n            is_restricted (bool | None, optional): Flag for restricted datasets. Defaults to None.\n            is_raw_data (bool, optional): Flag for raw datasets. Defaults to True.\n            maintainer (str | None, optional): Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".\n            source (str | list[str] | None, optional): Name of data vendor which provided the data. Defaults to None.\n            region (str | list[str] | None, optional): Region. Defaults to None.\n            publisher (str, optional): Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".\n            product (str | list[str] | None, optional): Product to associate dataset with. Defaults to None.\n            sub_category (str | list[str] | None, optional): Sub-category. Defaults to None.\n            tags (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n            created_date (str | None, optional): Created date. Defaults to None.\n            modified_date (str | None, optional): Modified date. Defaults to None.\n            delivery_channel (str | list[str], optional): Delivery channel. Defaults to \"API\".\n            language (str, optional): Language. Defaults to \"English\".\n            status (str, optional): Status. Defaults to \"Available\".\n            type_ (str | None, optional): Dataset type. Defaults to \"Source\".\n            container_type (str | None, optional): Container type. Defaults to \"Snapshot-Full\".\n            snowflake (str | None, optional): Snowflake account connection. Defaults to None.\n            complexity (str | None, optional): Complexity. Defaults to None.\n            is_immutable (bool | None, optional): Flag for immutable datasets. Defaults to None.\n            is_mnpi (bool | None, optional): is_mnpi. Defaults to None.\n            is_pci (bool | None, optional): is_pci. Defaults to None.\n            is_pii (bool | None, optional): is_pii. Defaults to None.\n            is_client (bool | None, optional): is_client. Defaults to None.\n            is_public (bool | None, optional): is_public. Defaults to None.\n            is_internal (bool | None, optional): is_internal. Defaults to None.\n            is_confidential (bool | None, optional): is_confidential. Defaults to None.\n            is_highly_confidential (bool | None, optional): is_highly_confidential. Defaults to None.\n            is_active (bool | None, optional): is_active. Defaults to None.\n            owners (list[str] | None, optional): The owners of the dataset. Defaults to None.\n            application_id (str | None, optional): The application ID of the dataset. Defaults to None.\n\n        Returns:\n            Dataset: Fusion Dataset class.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(identifier=\"DATASET_1\")\n\n        Note:\n            See the dataset module for more information on functionalities of dataset objects.\n\n        \"\"\"\n        dataset_obj = Dataset(\n            identifier=identifier,\n            title=title,\n            category=category,\n            description=description,\n            frequency=frequency,\n            is_internal_only_dataset=is_internal_only_dataset,\n            is_third_party_data=is_third_party_data,\n            is_restricted=is_restricted,\n            is_raw_data=is_raw_data,\n            maintainer=maintainer,\n            source=source,\n            region=region,\n            publisher=publisher,\n            product=product,\n            sub_category=sub_category,\n            tags=tags,\n            created_date=created_date,\n            modified_date=modified_date,\n            delivery_channel=delivery_channel,\n            language=language,\n            status=status,\n            type_=type_,\n            container_type=container_type,\n            snowflake=snowflake,\n            complexity=complexity,\n            is_immutable=is_immutable,\n            is_mnpi=is_mnpi,\n            is_pci=is_pci,\n            is_pii=is_pii,\n            is_client=is_client,\n            is_public=is_public,\n            is_internal=is_internal,\n            is_confidential=is_confidential,\n            is_highly_confidential=is_highly_confidential,\n            is_active=is_active,\n            owners=owners,\n            application_id=application_id,\n            **kwargs,\n        )\n        dataset_obj.client = self\n        return dataset_obj\n\n    def attribute(  # noqa: PLR0913\n        self,\n        identifier: str,\n        index: int,\n        data_type: str | Types = \"String\",\n        title: str = \"\",\n        description: str = \"\",\n        is_dataset_key: bool = False,\n        source: str | None = None,\n        source_field_id: str | None = None,\n        is_internal_dataset_key: bool | None = None,\n        is_externally_visible: bool | None = True,\n        unit: Any | None = None,\n        multiplier: float = 1.0,\n        is_propagation_eligible: bool | None = None,\n        is_metric: bool | None = None,\n        available_from: str | None = None,\n        deprecated_from: str | None = None,\n        term: str = \"bizterm1\",\n        dataset: int | None = None,\n        attribute_type: str | None = None,\n        application_id: str | dict[str, str] | None = None,\n        **kwargs: Any,\n    ) -&gt; Attribute:\n        \"\"\"Instantiate an Attribute object with this client for metadata creation.\n\n        Args:\n            identifier (str): The unique identifier for the attribute.\n            index (int): Attribute index.\n            data_type (str | Types, optional): Datatype of attribute. Defaults to \"String\".\n            title (str, optional): Attribute title. If not provided, defaults to identifier.\n            description (str, optional): Attribute description. If not provided, defaults to identifier.\n            is_dataset_key (bool, optional): Flag for primary keys. Defaults to False.\n            source (str | None, optional): Name of data vendor which provided the data. Defaults to None.\n            source_field_id (str | None, optional): Original identifier of attribute, if attribute has been renamed.\n                If not provided, defaults to identifier.\n            is_internal_dataset_key (bool | None, optional): Flag for internal primary keys. Defaults to None.\n            is_externally_visible (bool | None, optional): Flag for externally visible attributes. Defaults to True.\n            unit (Any | None, optional): Unit of attribute. Defaults to None.\n            multiplier (float, optional): Multiplier for unit. Defaults to 1.0.\n            is_propagation_eligible (bool | None, optional): Flag for propagation eligibility. Defaults to None.\n            is_metric (bool | None, optional): Flag for attributes that are metrics. Defaults to None.\n            available_from (str | None, optional): Date from which the attribute is available. Defaults to None.\n            deprecated_from (str | None, optional): Date from which the attribute is deprecated. Defaults to None.\n            term (str, optional): Term. Defaults to \"bizterm1\".\n            dataset (int | None, optional): Dataset. Defaults to None.\n            attribute_type (str | None, optional): Attribute type. Defaults to None.\n\n        Returns:\n            Attribute: Fusion Attribute class.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attr = fusion.attribute(identifier=\"attr1\", index=0)\n\n        Note:\n            See the attributes module for more information on functionalities of attribute objects.\n\n        \"\"\"\n        data_type = Types[str(data_type).strip().rsplit(\".\", maxsplit=1)[-1].title()]\n        attribute_obj = Attribute(\n            identifier=identifier,\n            index=index,\n            data_type=data_type,\n            title=title,\n            description=description,\n            is_dataset_key=is_dataset_key,\n            source=source,\n            source_field_id=source_field_id,\n            is_internal_dataset_key=is_internal_dataset_key,\n            is_externally_visible=is_externally_visible,\n            unit=unit,\n            multiplier=multiplier,\n            is_propagation_eligible=is_propagation_eligible,\n            is_metric=is_metric,\n            available_from=available_from,\n            deprecated_from=deprecated_from,\n            term=term,\n            dataset=dataset,\n            attribute_type=attribute_type,\n            application_id=application_id,\n            **kwargs,\n        )\n        attribute_obj.client = self\n        return attribute_obj\n\n    def attributes(\n        self,\n        attributes: list[Attribute] | None = None,\n    ) -&gt; Attributes:\n        \"\"\"Instantiate an Attributes object with this client for metadata creation.\n\n        Args:\n            attributes (list[Attribute] | None, optional): List of Attribute objects. Defaults to None.\n\n        Returns:\n            Attributes: Fusion Attributes class.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attr1 = fusion.attribute(\"attr1\", 0)\n            &gt;&gt;&gt; attr2 = fusion.attribute(\"attr2\", 1)\n            &gt;&gt;&gt; attrs = fusion.attributes([attr1, attr2])\n\n        Note:\n            See the attributes module for more information on functionalities of attributes object.\n\n        \"\"\"\n        attributes_obj = Attributes(attributes=attributes or [])\n        attributes_obj.client = self\n        return attributes_obj\n\n    def report_attribute(\n        self,\n        title: str,\n        sourceIdentifier: str | None = None,\n        description: str | None = None,\n        technicalDataType: str | None = None,\n        path: str | None = None,\n    ) -&gt; ReportAttribute:\n        \"\"\"\n        Instantiate a ReportAttribute object with this client for metadata creation.\n\n        Args:\n            title (str): The display title of the attribute (required).\n            sourceIdentifier (str | None, optional): A unique identifier or reference ID from the source system.\n            description (str | None, optional): A longer description of the attribute.\n            technicalDataType (str | None, optional): The technical data type (e.g., string, int, boolean).\n            path (str | None, optional): The hierarchical path or logical grouping for the attribute.\n\n        Returns:\n            ReportAttribute: A single ReportAttribute instance with the client context attached.\n\n        Example:\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attr = fusion.report_attribute(\n            ...     title=\"Customer ID\",\n            ...     sourceIdentifier=\"cust_id_123\",\n            ...     description=\"Unique customer identifier\",\n            ...     technicalDataType=\"String\",\n            ...     path=\"Customer.Details\"\n            ... )\n        \"\"\"\n        attribute_obj = ReportAttribute(\n            sourceIdentifier=sourceIdentifier,\n            title=title,\n            description=description,\n            technicalDataType=technicalDataType,\n            path=path,\n        )\n        attribute_obj.client = self\n        return attribute_obj\n\n\n    def report_attributes(\n        self,\n        attributes: list[ReportAttribute] | None = None,\n    ) -&gt; ReportAttributes:\n        \"\"\"\n        Instantiate a ReportAttributes collection with this client, allowing batch creation or manipulation.\n\n        Args:\n            attributes (list[ReportAttribute] | None, optional): A list of ReportAttribute objects to include.\n                Defaults to an empty list if not provided.\n\n        Returns:\n            ReportAttributes: A ReportAttributes collection object with the client context attached.\n\n        Example:\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attr1 = fusion.report_attribute(title=\"Code\")\n            &gt;&gt;&gt; attr2 = fusion.report_attribute(title=\"Label\")\n            &gt;&gt;&gt; attr_collection = fusion.report_attributes([attr1, attr2])\n            &gt;&gt;&gt; attr_collection.create(report_id=\"abc-123\")\n        \"\"\"\n        attributes_obj = ReportAttributes(attributes=attributes or [])\n        attributes_obj.client = self\n        return attributes_obj\n\n\n    def reports(self) -&gt; ReportsWrapper:\n        return ReportsWrapper(client=self)\n\n\n    def delete_datasetmembers(\n        self,\n        dataset: str,\n        series_members: str | list[str],\n        catalog: str | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; list[requests.Response] | None:\n        \"\"\"Delete dataset members.\n\n        Args:\n            dataset (str): A dataset identifier\n            series_members (str | list[str]): A string or list of strings that are dataset series member\n            identifiers to delete.\n            catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            list[requests.Response]: a list of response objects.\n\n        Examples:\n            Delete one dataset member.\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.delete_datasetmembers(dataset=\"dataset1\", series_members=\"series1\")\n\n            Delete multiple dataset members.\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.delete_datasetmembers(dataset=\"dataset1\", series_members=[\"series1\", \"series2\"])\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n        if isinstance(series_members, str):\n            series_members = [series_members]\n        responses = []\n        for series_member in series_members:\n            url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries/{series_member}\"\n            resp = self.session.delete(url)\n            requests_raise_for_status(resp)\n            responses.append(resp)\n        return responses if return_resp_obj else None\n\n    def delete_all_datasetmembers(\n        self,\n        dataset: str,\n        catalog: str | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Delete all dataset members within a dataset.\n\n        Args:\n            dataset (str): A dataset identifier\n            catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            list[requests.Response]: a list of response objects.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.delete_all_datasetmembers(dataset=\"dataset1\")\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries\"\n        resp = self.session.delete(url)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def list_registered_attributes(\n        self,\n        catalog: str | None = None,\n        output: bool = False,\n        display_all_columns: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Returns the list of attributes in a catalog.\n\n        Args:\n            catalog (str, optional): A catalog identifier. Defaults to 'common'.\n            output (bool, optional): If True then print the dataframe. Defaults to False.\n            display_all_columns (bool, optional): If True displays all columns returned by the API,\n                otherwise only the key columns are displayed\n\n        Returns:\n            class:`pandas.DataFrame`: A dataframe with a row for each attribute\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/attributes\"\n        ds_attr_df = Fusion._call_for_dataframe(url, self.session).reset_index(drop=True)\n\n        if not display_all_columns:\n            ds_attr_df = ds_attr_df[\n                ds_attr_df.columns.intersection(\n                    [\n                        \"identifier\",\n                        \"title\",\n                        \"dataType\",\n                        \"description\",\n                        \"publisher\",\n                        \"applicationId\",\n                    ]\n                )\n            ]\n\n        if output:\n            pass\n\n        return ds_attr_df\n\n    def input_dataflow(  # noqa: PLR0913\n        self,\n        identifier: str,\n        title: str = \"\",\n        category: str | list[str] | None = None,\n        description: str = \"\",\n        frequency: str = \"Once\",\n        is_internal_only_dataset: bool = False,\n        is_third_party_data: bool = True,\n        is_restricted: bool | None = None,\n        is_raw_data: bool = True,\n        maintainer: str | None = \"J.P. Morgan Fusion\",\n        source: str | list[str] | None = None,\n        region: str | list[str] | None = None,\n        publisher: str = \"J.P. Morgan\",\n        product: str | list[str] | None = None,\n        sub_category: str | list[str] | None = None,\n        tags: str | list[str] | None = None,\n        created_date: str | None = None,\n        modified_date: str | None = None,\n        delivery_channel: str | list[str] = \"API\",\n        language: str = \"English\",\n        status: str = \"Available\",\n        type_: str | None = \"Flow\",\n        container_type: str | None = \"Snapshot-Full\",\n        snowflake: str | None = None,\n        complexity: str | None = None,\n        is_immutable: bool | None = None,\n        is_mnpi: bool | None = None,\n        is_pci: bool | None = None,\n        is_pii: bool | None = None,\n        is_client: bool | None = None,\n        is_public: bool | None = None,\n        is_internal: bool | None = None,\n        is_confidential: bool | None = None,\n        is_highly_confidential: bool | None = None,\n        is_active: bool | None = None,\n        owners: list[str] | None = None,\n        application_id: str | dict[str, str] | None = None,\n        producer_application_id: dict[str, str] | None = None,\n        consumer_application_id: list[dict[str, str]] | dict[str, str] | None = None,\n        flow_details: dict[str, str] | None = None,\n        **kwargs: Any,\n    ) -&gt; InputDataFlow:\n        \"\"\"Instantiate an Input Dataflow object with this client for metadata creation.\n\n        Args:\n            identifier (str): Dataset identifier.\n            title (str, optional): Dataset title. If not provided, defaults to identifier.\n            category (str | list[str] | None, optional): A category or list of categories for the dataset.\n            Defaults to None.\n            description (str, optional): Dataset description. If not provided, defaults to identifier.\n            frequency (str, optional): The frequency of the dataset. Defaults to \"Once\".\n            is_internal_only_dataset (bool, optional): Flag for internal datasets. Defaults to False.\n            is_third_party_data (bool, optional): Flag for third party data. Defaults to True.\n            is_restricted (bool | None, optional): Flag for restricted datasets. Defaults to None.\n            is_raw_data (bool, optional): Flag for raw datasets. Defaults to True.\n            maintainer (str | None, optional): Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".\n            source (str | list[str] | None, optional): Name of data vendor which provided the data. Defaults to None.\n            region (str | list[str] | None, optional): Region. Defaults to None.\n            publisher (str, optional): Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".\n            product (str | list[str] | None, optional): Product to associate dataset with. Defaults to None.\n            sub_category (str | list[str] | None, optional): Sub-category. Defaults to None.\n            tags (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n            created_date (str | None, optional): Created date. Defaults to None.\n            modified_date (str | None, optional): Modified date. Defaults to None.\n            delivery_channel (str | list[str], optional): Delivery channel. Defaults to \"API\".\n            language (str, optional): Language. Defaults to \"English\".\n            status (str, optional): Status. Defaults to \"Available\".\n            type_ (str | None, optional): Dataset type. Defaults to \"Flow\".\n            container_type (str | None, optional): Container type. Defaults to \"Snapshot-Full\".\n            snowflake (str | None, optional): Snowflake account connection. Defaults to None.\n            complexity (str | None, optional): Complexity. Defaults to None.\n            is_immutable (bool | None, optional): Flag for immutable datasets. Defaults to None.\n            is_mnpi (bool | None, optional): is_mnpi. Defaults to None.\n            is_pci (bool | None, optional): is_pci. Defaults to None.\n            is_pii (bool | None, optional): is_pii. Defaults to None.\n            is_client (bool | None, optional): is_client. Defaults to None.\n            is_public (bool | None, optional): is_public. Defaults to None.\n            is_internal (bool | None, optional): is_internal. Defaults to None.\n            is_confidential (bool | None, optional): is_confidential. Defaults to None.\n            is_highly_confidential (bool | None, optional): is_highly_confidential. Defaults to None.\n            is_active (bool | None, optional): is_active. Defaults to None.\n            owners (list[str] | None, optional): The owners of the dataset. Defaults to None.\n            application_id (str | None, optional): The application ID of the dataset. Defaults to None.\n            producer_application_id (dict[str, str] | None, optional): The producer application ID (upstream application\n                producing the flow).\n            consumer_application_id (list[dict[str, str]] | dict[str, str] | None, optional): The consumer application\n                ID (downstream application, consuming the flow).\n            flow_details (dict[str, str] | None, optional): The flow details. Specifies input versus output flow.\n                Defaults to {\"flowDirection\": \"Input\"}.\n\n        Returns:\n            Dataset: Fusion InputDataFlow class.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.input_dataflow(identifier=\"MY_DATAFLOW\")\n\n        Note:\n            See the dataset module for more information on functionalities of input dataflow objects.\n\n        \"\"\"\n        flow_details = {\"flowDirection\": \"Input\"} if flow_details is None else flow_details\n        dataflow_obj = InputDataFlow(\n            identifier=identifier,\n            title=title,\n            category=category,\n            description=description,\n            frequency=frequency,\n            is_internal_only_dataset=is_internal_only_dataset,\n            is_third_party_data=is_third_party_data,\n            is_restricted=is_restricted,\n            is_raw_data=is_raw_data,\n            maintainer=maintainer,\n            source=source,\n            region=region,\n            publisher=publisher,\n            product=product,\n            sub_category=sub_category,\n            tags=tags,\n            created_date=created_date,\n            modified_date=modified_date,\n            delivery_channel=delivery_channel,\n            language=language,\n            status=status,\n            type_=type_,\n            container_type=container_type,\n            snowflake=snowflake,\n            complexity=complexity,\n            is_immutable=is_immutable,\n            is_mnpi=is_mnpi,\n            is_pci=is_pci,\n            is_pii=is_pii,\n            is_client=is_client,\n            is_public=is_public,\n            is_internal=is_internal,\n            is_confidential=is_confidential,\n            is_highly_confidential=is_highly_confidential,\n            is_active=is_active,\n            owners=owners,\n            application_id=application_id,\n            producer_application_id=producer_application_id,\n            consumer_application_id=consumer_application_id,\n            flow_details=flow_details,\n            **kwargs,\n        )\n        dataflow_obj.client = self\n        return dataflow_obj\n\n    def output_dataflow(  # noqa: PLR0913\n        self,\n        identifier: str,\n        title: str = \"\",\n        category: str | list[str] | None = None,\n        description: str = \"\",\n        frequency: str = \"Once\",\n        is_internal_only_dataset: bool = False,\n        is_third_party_data: bool = True,\n        is_restricted: bool | None = None,\n        is_raw_data: bool = True,\n        maintainer: str | None = \"J.P. Morgan Fusion\",\n        source: str | list[str] | None = None,\n        region: str | list[str] | None = None,\n        publisher: str = \"J.P. Morgan\",\n        product: str | list[str] | None = None,\n        sub_category: str | list[str] | None = None,\n        tags: str | list[str] | None = None,\n        created_date: str | None = None,\n        modified_date: str | None = None,\n        delivery_channel: str | list[str] = \"API\",\n        language: str = \"English\",\n        status: str = \"Available\",\n        type_: str | None = \"Flow\",\n        container_type: str | None = \"Snapshot-Full\",\n        snowflake: str | None = None,\n        complexity: str | None = None,\n        is_immutable: bool | None = None,\n        is_mnpi: bool | None = None,\n        is_pci: bool | None = None,\n        is_pii: bool | None = None,\n        is_client: bool | None = None,\n        is_public: bool | None = None,\n        is_internal: bool | None = None,\n        is_confidential: bool | None = None,\n        is_highly_confidential: bool | None = None,\n        is_active: bool | None = None,\n        owners: list[str] | None = None,\n        application_id: str | dict[str, str] | None = None,\n        producer_application_id: dict[str, str] | None = None,\n        consumer_application_id: list[dict[str, str]] | dict[str, str] | None = None,\n        flow_details: dict[str, str] | None = None,\n        **kwargs: Any,\n    ) -&gt; OutputDataFlow:\n        \"\"\"Instantiate an Output Dataflow object with this client for metadata creation.\n\n        Args:\n            identifier (str): Dataset identifier.\n            title (str, optional): Dataset title. If not provided, defaults to identifier.\n            category (str | list[str] | None, optional): A category or list of categories for the dataset.\n            Defaults to None.\n            description (str, optional): Dataset description. If not provided, defaults to identifier.\n            frequency (str, optional): The frequency of the dataset. Defaults to \"Once\".\n            is_internal_only_dataset (bool, optional): Flag for internal datasets. Defaults to False.\n            is_third_party_data (bool, optional): Flag for third party data. Defaults to True.\n            is_restricted (bool | None, optional): Flag for restricted datasets. Defaults to None.\n            is_raw_data (bool, optional): Flag for raw datasets. Defaults to True.\n            maintainer (str | None, optional): Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".\n            source (str | list[str] | None, optional): Name of data vendor which provided the data. Defaults to None.\n            region (str | list[str] | None, optional): Region. Defaults to None.\n            publisher (str, optional): Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".\n            product (str | list[str] | None, optional): Product to associate dataset with. Defaults to None.\n            sub_category (str | list[str] | None, optional): Sub-category. Defaults to None.\n            tags (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n            created_date (str | None, optional): Created date. Defaults to None.\n            modified_date (str | None, optional): Modified date. Defaults to None.\n            delivery_channel (str | list[str], optional): Delivery channel. Defaults to \"API\".\n            language (str, optional): Language. Defaults to \"English\".\n            status (str, optional): Status. Defaults to \"Available\".\n            type_ (str | None, optional): Dataset type. Defaults to \"Flow\".\n            container_type (str | None, optional): Container type. Defaults to \"Snapshot-Full\".\n            snowflake (str | None, optional): Snowflake account connection. Defaults to None.\n            complexity (str | None, optional): Complexity. Defaults to None.\n            is_immutable (bool | None, optional): Flag for immutable datasets. Defaults to None.\n            is_mnpi (bool | None, optional): is_mnpi. Defaults to None.\n            is_pci (bool | None, optional): is_pci. Defaults to None.\n            is_pii (bool | None, optional): is_pii. Defaults to None.\n            is_client (bool | None, optional): is_client. Defaults to None.\n            is_public (bool | None, optional): is_public. Defaults to None.\n            is_internal (bool | None, optional): is_internal. Defaults to None.\n            is_confidential (bool | None, optional): is_confidential. Defaults to None.\n            is_highly_confidential (bool | None, optional): is_highly_confidential. Defaults to None.\n            is_active (bool | None, optional): is_active. Defaults to None.\n            owners (list[str] | None, optional): The owners of the dataset. Defaults to None.\n            application_id (str | None, optional): The application ID of the dataset. Defaults to None.\n            producer_application_id (dict[str, str] | None, optional): The producer application ID (upstream application\n                producing the flow).\n            consumer_application_id (list[dict[str, str]] | dict[str, str] | None, optional): The consumer application\n                ID (downstream application, consuming the flow).\n            flow_details (dict[str, str] | None, optional): The flow details. Specifies input versus output flow.\n                Defaults to {\"flowDirection\": \"Output\"}.\n\n        Returns:\n            Dataset: Fusion OutputDataFlow class.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.output_dataflow(identifier=\"MY_DATAFLOW\")\n\n        Note:\n            See the dataset module for more information on functionalities of output dataflow objects.\n\n        \"\"\"\n        flow_details = {\"flowDirection\": \"Output\"} if flow_details is None else flow_details\n        dataflow_obj = OutputDataFlow(\n            identifier=identifier,\n            title=title,\n            category=category,\n            description=description,\n            frequency=frequency,\n            is_internal_only_dataset=is_internal_only_dataset,\n            is_third_party_data=is_third_party_data,\n            is_restricted=is_restricted,\n            is_raw_data=is_raw_data,\n            maintainer=maintainer,\n            source=source,\n            region=region,\n            publisher=publisher,\n            product=product,\n            sub_category=sub_category,\n            tags=tags,\n            created_date=created_date,\n            modified_date=modified_date,\n            delivery_channel=delivery_channel,\n            language=language,\n            status=status,\n            type_=type_,\n            container_type=container_type,\n            snowflake=snowflake,\n            complexity=complexity,\n            is_immutable=is_immutable,\n            is_mnpi=is_mnpi,\n            is_pci=is_pci,\n            is_pii=is_pii,\n            is_client=is_client,\n            is_public=is_public,\n            is_internal=is_internal,\n            is_confidential=is_confidential,\n            is_highly_confidential=is_highly_confidential,\n            is_active=is_active,\n            owners=owners,\n            application_id=application_id,\n            producer_application_id=producer_application_id,\n            consumer_application_id=consumer_application_id,\n            flow_details=flow_details,\n            **kwargs,\n        )\n        dataflow_obj.client = self\n        return dataflow_obj\n\n    def list_indexes(\n        self,\n        knowledge_base: str,\n        catalog: str | None = None,\n        show_details: bool | None = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"List the indexes in a knowledge base.\n\n        Args:\n            knowledge_base (str): Knowledge base (dataset) identifier.\n            catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n            show_details (bool | None, optional): If True then show detailed information. Defaults to False.\n\n        Returns:\n            pd.DataFrame: a dataframe with a column for each index.\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n        url = f\"{self.root_url}dataspaces/{catalog}/datasets/{knowledge_base}/indexes/\"\n        response = self.session.get(url)\n        requests_raise_for_status(response)\n        if show_details:\n            return _format_full_index_response(response)\n        else:\n            return _format_summary_index_response(response)\n\n    def get_fusion_vector_store_client(self, knowledge_base: str, catalog: str | None = None) -&gt; OpenSearch:\n        \"\"\"Returns Fusion Embeddings Search client.\n\n        Args:\n            knowledge_base (str): Knowledge base (dataset) identifier.\n            catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n\n        Returns:\n            OpenSearch: Fusion Embeddings Search client.\n\n        \"\"\"\n        from opensearchpy import OpenSearch\n\n        from fusion.embeddings import FusionEmbeddingsConnection\n\n        catalog = self._use_catalog(catalog)\n        return OpenSearch(\n            connection_class=FusionEmbeddingsConnection,\n            catalog=catalog,\n            knowledge_base=knowledge_base,\n            root_url=self.root_url,\n            credentials=self.credentials,\n        )\n\n    def get_async_fusion_vector_store_client(self, knowledge_base: str, catalog: str | None = None) -&gt; AsyncOpenSearch:\n        \"\"\"Returns Fusion Embeddings Search client.\n\n        Args:\n            knowledge_base (str): Knowledge base (dataset) identifier.\n            catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n\n        Returns:\n            OpenSearch: Fusion Embeddings Search client.\n\n        \"\"\"\n        from opensearchpy import AsyncOpenSearch\n\n        from fusion.embeddings import FusionAsyncHttpConnection\n\n        catalog = self._use_catalog(catalog)\n        return AsyncOpenSearch(\n            connection_class=FusionAsyncHttpConnection,\n            catalog=catalog,\n            knowledge_base=knowledge_base,\n            root_url=self.root_url,\n            credentials=self.credentials,\n        )\n\n    def list_datasetmembers_distributions(\n        self,\n        dataset: str,\n        catalog: str | None = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"List the distributions of dataset members.\n\n                Args:\n                    dataset (str): Dataset identifier.\n                    catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n                    output (bool, optional): If True then print the dataframe. Defaults to False.\n        F\n                Returns:\n                    pd.DataFrame: A dataframe with a row for each dataset member distribution.\n\n        \"\"\"\n        catalog = self._use_catalog(catalog)\n\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/changes?datasets={dataset}\"\n\n        resp = self.session.get(url)\n        dists = resp.json()[\"datasets\"][0][\"distributions\"]\n\n        data = []\n        for dist in dists:\n            values = dist.get(\"values\")\n            member_id = values[5]\n            member_format = values[6]\n            data.append((member_id, member_format))\n\n        members_df = pd.DataFrame(data, columns=[\"identifier\", \"format\"])\n        return members_df\n\n    def report(  # noqa: PLR0913\n        self,\n        description: str,\n        title: str,\n        frequency: str,\n        category: str,\n        sub_category: str,\n        data_node_id: dict[str, str],\n        regulatory_related: bool,\n        domain: dict[str, str],\n        tier_type: str | None = None, \n        lob: str | None = None,\n        alternative_id: dict[str, str] | None = None,\n        sub_lob: str | None = None,\n        is_bcbs239_program: bool | None = None,\n        risk_area: str | None = None,\n        risk_stripe: str | None = None,\n        sap_code: str | None = None,\n        **kwargs: Any,\n    ) -&gt; Report:\n        \"\"\"\n        Instantiate a Report object with the current Fusion client attached.\n\n        Args:\n            description (str): Description of the report.\n            title (str): Title of the report or process.\n            frequency (str): Reporting frequency (e.g., Monthly, Quarterly).\n            category (str): Main classification of the report.\n            sub_category (str): Sub-classification under the main category.\n            data_node_id (dict[str, str]): Associated data node details. Should include \"name\" and \"dataNodeType\".\n            regulatory_related (bool): Whether the report is regulatory-designated. This is a required field.\n            tier_type (str, optional): Tier classification (e.g., \"Tier 1\", \"Non Tier 1\").\n            lob (str, optional): Line of business.\n            alternative_id (dict[str, str], optional): Alternate identifiers for the report.\n            sub_lob (str, optional): Subdivision of the line of business.\n            is_bcbs239_program (bool, optional): Whether the report is part of the BCBS 239 program.\n            risk_area (str, optional): Risk area covered by the report.\n            risk_stripe (str, optional): Stripe or classification under the risk area.\n            sap_code (str, optional): SAP financial tracking code.\n            domain (dict[str, str | bool], optional): Domain details. Typically contains a \"name\" key.\n            **kwargs (Any): Additional optional fields such as:\n                - tier_designation (str)\n                - region (str)\n                - mnpi_indicator (bool)\n                - country_of_reporting_obligation (str)\n                - primary_regulator (str)\n\n        Returns:\n            Report: A Report object ready for API upload or further manipulation.\n        \"\"\"\n        report_obj = Report(\n            title=title,\n            description=description,\n            frequency=frequency,\n            category=category,\n            sub_category=sub_category,\n            data_node_id=data_node_id,\n            regulatory_related=regulatory_related,\n            tier_type=tier_type,\n            lob=lob,\n            alternative_id=alternative_id,\n            sub_lob=sub_lob,\n            is_bcbs239_program=is_bcbs239_program,\n            risk_area=risk_area,\n            risk_stripe=risk_stripe,\n            sap_code=sap_code,\n            domain=domain,\n            **kwargs,\n        )\n        report_obj.client = self\n        return report_obj\n\n\n\n    def link_attributes_to_terms(\n        self,\n        report_id: str,\n        mappings: list[Report.AttributeTermMapping],\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"\n        Link one or more report attributes to business glossary terms.\n\n        Each mapping should follow this format:\n            {\n                \"attribute\": {\"id\": \"attribute-id\"},\n                \"term\": {\"id\": \"term-id\"},\n                \"isKDE\": True  # Optional; defaults to True if not provided\n            }\n\n        This method wraps `Report.link_attributes_to_terms` and automatically attaches the Fusion client.\n        \"\"\"\n\n        processed_mappings = []\n        for mapping in mappings:\n            new_mapping = mapping.copy()\n            if \"isKDE\" not in new_mapping:\n                new_mapping[\"isKDE\"] = True \n            processed_mappings.append(new_mapping)\n\n        return Report.link_attributes_to_terms(\n            report_id=report_id,\n            mappings=processed_mappings,\n            client=self,\n            return_resp_obj=return_resp_obj\n        )\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.default_catalog","title":"<code>default_catalog</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the default catalog.</p> <p>Returns:</p> Type Description <code>str</code> <p>None</p>"},{"location":"api/#fusion.fusion.Fusion.__init__","title":"<code>__init__(credentials='config/client_credentials.json', root_url='https://fusion.jpmorgan.com/api/v1/', download_folder='downloads', log_level=logging.ERROR, fs=None, log_path='.', enable_logging=True)</code>","text":"<p>Constructor to instantiate a new Fusion object.</p> <p>Parameters:</p> Name Type Description Default <code>credentials</code> <code>Union[str, FusionCredentials]</code> <p>A path to a credentials file or a fully populated</p> <code>'config/client_credentials.json'</code> <code>root_url</code> <code>_type_</code> <p>The API root URL. Defaults to \"https://fusion.jpmorgan.com/api/v1/\".</p> <code>'https://fusion.jpmorgan.com/api/v1/'</code> <code>download_folder</code> <code>str</code> <p>The folder path where downloaded data files are saved. Defaults to \"downloads\".</p> <code>'downloads'</code> <code>log_level</code> <code>int</code> <p>Set the logging level. Defaults to logging.ERROR.</p> <code>ERROR</code> <code>fs</code> <code>filesystem</code> <p>filesystem.</p> <code>None</code> <code>log_path</code> <code>str</code> <p>The folder path where the log is stored.</p> <code>'.'</code> <code>enable_logging</code> <code>bool</code> <p>If True, enables logging to a file in addition to stdout. If False, logging is only directed to stdout. Defaults to True.</p> <code>True</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def __init__(\n    self,\n    credentials: str | FusionCredentials = \"config/client_credentials.json\",\n    root_url: str = \"https://fusion.jpmorgan.com/api/v1/\",\n    download_folder: str = \"downloads\",\n    log_level: int = logging.ERROR,\n    fs: fsspec.filesystem = None,\n    log_path: str = \".\",\n    enable_logging: bool = True,\n) -&gt; None:\n    \"\"\"Constructor to instantiate a new Fusion object.\n\n    Args:\n        credentials (Union[str, FusionCredentials]): A path to a credentials file or a fully populated\n        FusionCredentials object. Defaults to 'config/client_credentials.json'.\n        root_url (_type_, optional): The API root URL.\n            Defaults to \"https://fusion.jpmorgan.com/api/v1/\".\n        download_folder (str, optional): The folder path where downloaded data files\n            are saved. Defaults to \"downloads\".\n        log_level (int, optional): Set the logging level. Defaults to logging.ERROR.\n        fs (fsspec.filesystem): filesystem.\n        log_path (str, optional): The folder path where the log is stored.\n        enable_logging (bool, optional): If True, enables logging to a file in addition to stdout.\n            If False, logging is only directed to stdout. Defaults to True.\n    \"\"\"\n    self._default_catalog = \"common\"\n\n    self.root_url = root_url\n    self.download_folder = download_folder\n    Path(download_folder).mkdir(parents=True, exist_ok=True)\n\n    logging.addLevelName(VERBOSE_LVL, \"VERBOSE\")\n    logger.setLevel(log_level)\n    if not logger.handlers:\n        logger.addHandler(logging.NullHandler())\n\n    formatter = logging.Formatter(\n        \"%(asctime)s.%(msecs)03d %(name)s:%(levelname)s %(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n    )\n\n    if enable_logging and not any(isinstance(h, logging.FileHandler) for h in logger.handlers):\n        file_handler = logging.FileHandler(filename=f\"{log_path}/fusion_sdk.log\")\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n    if not any(isinstance(h, logging.StreamHandler) for h in logger.handlers):\n        stdout_handler = logging.StreamHandler(sys.stdout)\n        stdout_handler.setFormatter(formatter)\n        logger.addHandler(stdout_handler)\n\n    if len(logger.handlers) &gt; 1:\n        logger.handlers = [h for h in logger.handlers if not isinstance(h, logging.NullHandler)]\n\n    if isinstance(credentials, FusionCredentials):\n        self.credentials = credentials\n    elif isinstance(credentials, str):\n        try:\n            self.credentials = FusionCredentials.from_file(Path(credentials))\n        except CredentialError as e:\n            if hasattr(e, \"status_code\"):\n                message = \"Failed to load credentials. Please check the credentials file.\"\n                raise APIResponseError(e, message=message) from e\n            else:\n                raise e\n    else:\n        raise ValueError(\"credentials must be a path to a credentials file or FusionCredentials object\")\n\n    self.session = get_session(self.credentials, self.root_url)\n    self.fs = fs if fs else get_default_fs()\n    self.events: pd.DataFrame | None = None\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.__repr__","title":"<code>__repr__()</code>","text":"<p>Object representation to list all available methods.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Object representation to list all available methods.\"\"\"\n    return \"Fusion object \\nAvailable methods:\\n\" + tabulate(\n        pd.DataFrame(  # type: ignore\n            [\n                [\n                    method_name\n                    for method_name in dir(Fusion)\n                    if callable(getattr(Fusion, method_name)) and not method_name.startswith(\"_\")\n                ]\n                + [p for p in dir(Fusion) if isinstance(getattr(Fusion, p), property)],\n                [\n                    getattr(Fusion, method_name).__doc__.split(\"\\n\")[0]\n                    for method_name in dir(Fusion)\n                    if callable(getattr(Fusion, method_name)) and not method_name.startswith(\"_\")\n                ]\n                + [\n                    getattr(Fusion, p).__doc__.split(\"\\n\")[0]\n                    for p in dir(Fusion)\n                    if isinstance(getattr(Fusion, p), property)\n                ],\n            ]\n        ).T.set_index(0),\n        tablefmt=\"psql\",\n    )\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.attribute","title":"<code>attribute(identifier, index, data_type='String', title='', description='', is_dataset_key=False, source=None, source_field_id=None, is_internal_dataset_key=None, is_externally_visible=True, unit=None, multiplier=1.0, is_propagation_eligible=None, is_metric=None, available_from=None, deprecated_from=None, term='bizterm1', dataset=None, attribute_type=None, application_id=None, **kwargs)</code>","text":"<p>Instantiate an Attribute object with this client for metadata creation.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>The unique identifier for the attribute.</p> required <code>index</code> <code>int</code> <p>Attribute index.</p> required <code>data_type</code> <code>str | Types</code> <p>Datatype of attribute. Defaults to \"String\".</p> <code>'String'</code> <code>title</code> <code>str</code> <p>Attribute title. If not provided, defaults to identifier.</p> <code>''</code> <code>description</code> <code>str</code> <p>Attribute description. If not provided, defaults to identifier.</p> <code>''</code> <code>is_dataset_key</code> <code>bool</code> <p>Flag for primary keys. Defaults to False.</p> <code>False</code> <code>source</code> <code>str | None</code> <p>Name of data vendor which provided the data. Defaults to None.</p> <code>None</code> <code>source_field_id</code> <code>str | None</code> <p>Original identifier of attribute, if attribute has been renamed. If not provided, defaults to identifier.</p> <code>None</code> <code>is_internal_dataset_key</code> <code>bool | None</code> <p>Flag for internal primary keys. Defaults to None.</p> <code>None</code> <code>is_externally_visible</code> <code>bool | None</code> <p>Flag for externally visible attributes. Defaults to True.</p> <code>True</code> <code>unit</code> <code>Any | None</code> <p>Unit of attribute. Defaults to None.</p> <code>None</code> <code>multiplier</code> <code>float</code> <p>Multiplier for unit. Defaults to 1.0.</p> <code>1.0</code> <code>is_propagation_eligible</code> <code>bool | None</code> <p>Flag for propagation eligibility. Defaults to None.</p> <code>None</code> <code>is_metric</code> <code>bool | None</code> <p>Flag for attributes that are metrics. Defaults to None.</p> <code>None</code> <code>available_from</code> <code>str | None</code> <p>Date from which the attribute is available. Defaults to None.</p> <code>None</code> <code>deprecated_from</code> <code>str | None</code> <p>Date from which the attribute is deprecated. Defaults to None.</p> <code>None</code> <code>term</code> <code>str</code> <p>Term. Defaults to \"bizterm1\".</p> <code>'bizterm1'</code> <code>dataset</code> <code>int | None</code> <p>Dataset. Defaults to None.</p> <code>None</code> <code>attribute_type</code> <code>str | None</code> <p>Attribute type. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Attribute</code> <code>Attribute</code> <p>Fusion Attribute class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attr = fusion.attribute(identifier=\"attr1\", index=0)\n</code></pre> Note <p>See the attributes module for more information on functionalities of attribute objects.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def attribute(  # noqa: PLR0913\n    self,\n    identifier: str,\n    index: int,\n    data_type: str | Types = \"String\",\n    title: str = \"\",\n    description: str = \"\",\n    is_dataset_key: bool = False,\n    source: str | None = None,\n    source_field_id: str | None = None,\n    is_internal_dataset_key: bool | None = None,\n    is_externally_visible: bool | None = True,\n    unit: Any | None = None,\n    multiplier: float = 1.0,\n    is_propagation_eligible: bool | None = None,\n    is_metric: bool | None = None,\n    available_from: str | None = None,\n    deprecated_from: str | None = None,\n    term: str = \"bizterm1\",\n    dataset: int | None = None,\n    attribute_type: str | None = None,\n    application_id: str | dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; Attribute:\n    \"\"\"Instantiate an Attribute object with this client for metadata creation.\n\n    Args:\n        identifier (str): The unique identifier for the attribute.\n        index (int): Attribute index.\n        data_type (str | Types, optional): Datatype of attribute. Defaults to \"String\".\n        title (str, optional): Attribute title. If not provided, defaults to identifier.\n        description (str, optional): Attribute description. If not provided, defaults to identifier.\n        is_dataset_key (bool, optional): Flag for primary keys. Defaults to False.\n        source (str | None, optional): Name of data vendor which provided the data. Defaults to None.\n        source_field_id (str | None, optional): Original identifier of attribute, if attribute has been renamed.\n            If not provided, defaults to identifier.\n        is_internal_dataset_key (bool | None, optional): Flag for internal primary keys. Defaults to None.\n        is_externally_visible (bool | None, optional): Flag for externally visible attributes. Defaults to True.\n        unit (Any | None, optional): Unit of attribute. Defaults to None.\n        multiplier (float, optional): Multiplier for unit. Defaults to 1.0.\n        is_propagation_eligible (bool | None, optional): Flag for propagation eligibility. Defaults to None.\n        is_metric (bool | None, optional): Flag for attributes that are metrics. Defaults to None.\n        available_from (str | None, optional): Date from which the attribute is available. Defaults to None.\n        deprecated_from (str | None, optional): Date from which the attribute is deprecated. Defaults to None.\n        term (str, optional): Term. Defaults to \"bizterm1\".\n        dataset (int | None, optional): Dataset. Defaults to None.\n        attribute_type (str | None, optional): Attribute type. Defaults to None.\n\n    Returns:\n        Attribute: Fusion Attribute class.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attr = fusion.attribute(identifier=\"attr1\", index=0)\n\n    Note:\n        See the attributes module for more information on functionalities of attribute objects.\n\n    \"\"\"\n    data_type = Types[str(data_type).strip().rsplit(\".\", maxsplit=1)[-1].title()]\n    attribute_obj = Attribute(\n        identifier=identifier,\n        index=index,\n        data_type=data_type,\n        title=title,\n        description=description,\n        is_dataset_key=is_dataset_key,\n        source=source,\n        source_field_id=source_field_id,\n        is_internal_dataset_key=is_internal_dataset_key,\n        is_externally_visible=is_externally_visible,\n        unit=unit,\n        multiplier=multiplier,\n        is_propagation_eligible=is_propagation_eligible,\n        is_metric=is_metric,\n        available_from=available_from,\n        deprecated_from=deprecated_from,\n        term=term,\n        dataset=dataset,\n        attribute_type=attribute_type,\n        application_id=application_id,\n        **kwargs,\n    )\n    attribute_obj.client = self\n    return attribute_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.attributes","title":"<code>attributes(attributes=None)</code>","text":"<p>Instantiate an Attributes object with this client for metadata creation.</p> <p>Parameters:</p> Name Type Description Default <code>attributes</code> <code>list[Attribute] | None</code> <p>List of Attribute objects. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Attributes</code> <code>Attributes</code> <p>Fusion Attributes class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attr1 = fusion.attribute(\"attr1\", 0)\n&gt;&gt;&gt; attr2 = fusion.attribute(\"attr2\", 1)\n&gt;&gt;&gt; attrs = fusion.attributes([attr1, attr2])\n</code></pre> Note <p>See the attributes module for more information on functionalities of attributes object.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def attributes(\n    self,\n    attributes: list[Attribute] | None = None,\n) -&gt; Attributes:\n    \"\"\"Instantiate an Attributes object with this client for metadata creation.\n\n    Args:\n        attributes (list[Attribute] | None, optional): List of Attribute objects. Defaults to None.\n\n    Returns:\n        Attributes: Fusion Attributes class.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attr1 = fusion.attribute(\"attr1\", 0)\n        &gt;&gt;&gt; attr2 = fusion.attribute(\"attr2\", 1)\n        &gt;&gt;&gt; attrs = fusion.attributes([attr1, attr2])\n\n    Note:\n        See the attributes module for more information on functionalities of attributes object.\n\n    \"\"\"\n    attributes_obj = Attributes(attributes=attributes or [])\n    attributes_obj.client = self\n    return attributes_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.catalog_resources","title":"<code>catalog_resources(catalog=None, output=False)</code>","text":"<p>List the resources contained within the catalog, for example products and datasets.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each resource within the catalog</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def catalog_resources(self, catalog: str | None = None, output: bool = False) -&gt; pd.DataFrame:\n    \"\"\"List the resources contained within the catalog, for example products and datasets.\n\n    Args:\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n\n    Returns:\n       class:`pandas.DataFrame`: A dataframe with a row for each resource within the catalog\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}\"\n    cat_df = Fusion._call_for_dataframe(url, self.session)\n\n    if output:\n        pass\n    return cat_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.create_dataset_lineage","title":"<code>create_dataset_lineage(base_dataset, source_dataset_catalog_mapping, catalog=None, return_resp_obj=False)</code>","text":"<p>Upload lineage to a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>base_dataset</code> <code>str</code> <p>A dataset identifier to which you want to add lineage.</p> required <code>source_dataset_catalog_mapping</code> <code>Union[DataFrame, list[dict[str]]]</code> <p>Mapping for the dataset identifier(s) and catalog(s) from which to add lineage.</p> required <code>catalog</code> <code>Optional[str]</code> <p>Catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If source_dataset_catalog_mapping is not a pandas DataFrame or a list of dictionaries</p> <code>HTTPError</code> <p>If the request is unsuccessful.</p> <p>Examples:</p> <p>Creating lineage from a pandas DataFrame.</p> <pre><code>&gt;&gt;&gt; data = [{\"dataset\": \"a\", \"catalog\": \"a\"}, {\"dataset\": \"b\", \"catalog\": \"b\"}]\n&gt;&gt;&gt; df = pd.DataFrame(data)\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.create_dataset_lineage(base_dataset=\"c\", source_dataset_catalog_mapping=df, catalog=\"c\")\n</code></pre> <p>Creating lineage from a list of dictionaries.</p> <pre><code>&gt;&gt;&gt; data = [{\"dataset\": \"a\", \"catalog\": \"a\"}, {\"dataset\": \"b\", \"catalog\": \"b\"}]\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.create_dataset_lineage(base_dataset=\"c\", source_dataset_catalog_mapping=data, catalog=\"c\")\n</code></pre> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def create_dataset_lineage(\n    self,\n    base_dataset: str,\n    source_dataset_catalog_mapping: pd.DataFrame | list[dict[str, str]],\n    catalog: str | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Upload lineage to a dataset.\n\n    Args:\n        base_dataset (str): A dataset identifier to which you want to add lineage.\n        source_dataset_catalog_mapping (Union[pd.DataFrame, list[dict[str]]]): Mapping for the dataset\n            identifier(s) and catalog(s) from which to add lineage.\n        catalog (Optional[str], optional): Catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Raises:\n        ValueError: If source_dataset_catalog_mapping is not a pandas DataFrame or a list of dictionaries\n        HTTPError: If the request is unsuccessful.\n\n    Examples:\n        Creating lineage from a pandas DataFrame.\n        &gt;&gt;&gt; data = [{\"dataset\": \"a\", \"catalog\": \"a\"}, {\"dataset\": \"b\", \"catalog\": \"b\"}]\n        &gt;&gt;&gt; df = pd.DataFrame(data)\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.create_dataset_lineage(base_dataset=\"c\", source_dataset_catalog_mapping=df, catalog=\"c\")\n\n        Creating lineage from a list of dictionaries.\n        &gt;&gt;&gt; data = [{\"dataset\": \"a\", \"catalog\": \"a\"}, {\"dataset\": \"b\", \"catalog\": \"b\"}]\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.create_dataset_lineage(base_dataset=\"c\", source_dataset_catalog_mapping=data, catalog=\"c\")\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    if isinstance(source_dataset_catalog_mapping, pd.DataFrame):\n        dataset_mapping_list = [\n            {\"dataset\": row[\"dataset\"], \"catalog\": row[\"catalog\"]}\n            for _, row in source_dataset_catalog_mapping.iterrows()\n        ]\n    elif isinstance(source_dataset_catalog_mapping, list):\n        dataset_mapping_list = source_dataset_catalog_mapping\n    else:\n        raise ValueError(\"source_dataset_catalog_mapping must be a pandas DataFrame or a list of dictionaries.\")\n    data = {\"source\": dataset_mapping_list}\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{base_dataset}/lineage\"\n\n    resp = self.session.post(url, json=data)\n\n    resp.raise_for_status()\n\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.dataset","title":"<code>dataset(identifier, title='', category=None, description='', frequency='Once', is_internal_only_dataset=False, is_third_party_data=True, is_restricted=None, is_raw_data=True, maintainer='J.P. Morgan Fusion', source=None, region=None, publisher='J.P. Morgan', product=None, sub_category=None, tags=None, created_date=None, modified_date=None, delivery_channel='API', language='English', status='Available', type_='Source', container_type='Snapshot-Full', snowflake=None, complexity=None, is_immutable=None, is_mnpi=None, is_pci=None, is_pii=None, is_client=None, is_public=None, is_internal=None, is_confidential=None, is_highly_confidential=None, is_active=None, owners=None, application_id=None, **kwargs)</code>","text":"<p>Instantiate a Dataset object with this client for metadata creation.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Dataset identifier.</p> required <code>title</code> <code>str</code> <p>Dataset title. If not provided, defaults to identifier.</p> <code>''</code> <code>category</code> <code>str | list[str] | None</code> <p>A category or list of categories for the dataset.</p> <code>None</code> <code>description</code> <code>str</code> <p>Dataset description. If not provided, defaults to identifier.</p> <code>''</code> <code>frequency</code> <code>str</code> <p>The frequency of the dataset. Defaults to \"Once\".</p> <code>'Once'</code> <code>is_internal_only_dataset</code> <code>bool</code> <p>Flag for internal datasets. Defaults to False.</p> <code>False</code> <code>is_third_party_data</code> <code>bool</code> <p>Flag for third party data. Defaults to True.</p> <code>True</code> <code>is_restricted</code> <code>bool | None</code> <p>Flag for restricted datasets. Defaults to None.</p> <code>None</code> <code>is_raw_data</code> <code>bool</code> <p>Flag for raw datasets. Defaults to True.</p> <code>True</code> <code>maintainer</code> <code>str | None</code> <p>Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".</p> <code>'J.P. Morgan Fusion'</code> <code>source</code> <code>str | list[str] | None</code> <p>Name of data vendor which provided the data. Defaults to None.</p> <code>None</code> <code>region</code> <code>str | list[str] | None</code> <p>Region. Defaults to None.</p> <code>None</code> <code>publisher</code> <code>str</code> <p>Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".</p> <code>'J.P. Morgan'</code> <code>product</code> <code>str | list[str] | None</code> <p>Product to associate dataset with. Defaults to None.</p> <code>None</code> <code>sub_category</code> <code>str | list[str] | None</code> <p>Sub-category. Defaults to None.</p> <code>None</code> <code>tags</code> <code>str | list[str] | None</code> <p>Tags used for search purposes. Defaults to None.</p> <code>None</code> <code>created_date</code> <code>str | None</code> <p>Created date. Defaults to None.</p> <code>None</code> <code>modified_date</code> <code>str | None</code> <p>Modified date. Defaults to None.</p> <code>None</code> <code>delivery_channel</code> <code>str | list[str]</code> <p>Delivery channel. Defaults to \"API\".</p> <code>'API'</code> <code>language</code> <code>str</code> <p>Language. Defaults to \"English\".</p> <code>'English'</code> <code>status</code> <code>str</code> <p>Status. Defaults to \"Available\".</p> <code>'Available'</code> <code>type_</code> <code>str | None</code> <p>Dataset type. Defaults to \"Source\".</p> <code>'Source'</code> <code>container_type</code> <code>str | None</code> <p>Container type. Defaults to \"Snapshot-Full\".</p> <code>'Snapshot-Full'</code> <code>snowflake</code> <code>str | None</code> <p>Snowflake account connection. Defaults to None.</p> <code>None</code> <code>complexity</code> <code>str | None</code> <p>Complexity. Defaults to None.</p> <code>None</code> <code>is_immutable</code> <code>bool | None</code> <p>Flag for immutable datasets. Defaults to None.</p> <code>None</code> <code>is_mnpi</code> <code>bool | None</code> <p>is_mnpi. Defaults to None.</p> <code>None</code> <code>is_pci</code> <code>bool | None</code> <p>is_pci. Defaults to None.</p> <code>None</code> <code>is_pii</code> <code>bool | None</code> <p>is_pii. Defaults to None.</p> <code>None</code> <code>is_client</code> <code>bool | None</code> <p>is_client. Defaults to None.</p> <code>None</code> <code>is_public</code> <code>bool | None</code> <p>is_public. Defaults to None.</p> <code>None</code> <code>is_internal</code> <code>bool | None</code> <p>is_internal. Defaults to None.</p> <code>None</code> <code>is_confidential</code> <code>bool | None</code> <p>is_confidential. Defaults to None.</p> <code>None</code> <code>is_highly_confidential</code> <code>bool | None</code> <p>is_highly_confidential. Defaults to None.</p> <code>None</code> <code>is_active</code> <code>bool | None</code> <p>is_active. Defaults to None.</p> <code>None</code> <code>owners</code> <code>list[str] | None</code> <p>The owners of the dataset. Defaults to None.</p> <code>None</code> <code>application_id</code> <code>str | None</code> <p>The application ID of the dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Fusion Dataset class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(identifier=\"DATASET_1\")\n</code></pre> Note <p>See the dataset module for more information on functionalities of dataset objects.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def dataset(  # noqa: PLR0913\n    self,\n    identifier: str,\n    title: str = \"\",\n    category: str | list[str] | None = None,\n    description: str = \"\",\n    frequency: str = \"Once\",\n    is_internal_only_dataset: bool = False,\n    is_third_party_data: bool = True,\n    is_restricted: bool | None = None,\n    is_raw_data: bool = True,\n    maintainer: str | None = \"J.P. Morgan Fusion\",\n    source: str | list[str] | None = None,\n    region: str | list[str] | None = None,\n    publisher: str = \"J.P. Morgan\",\n    product: str | list[str] | None = None,\n    sub_category: str | list[str] | None = None,\n    tags: str | list[str] | None = None,\n    created_date: str | None = None,\n    modified_date: str | None = None,\n    delivery_channel: str | list[str] = \"API\",\n    language: str = \"English\",\n    status: str = \"Available\",\n    type_: str | None = \"Source\",\n    container_type: str | None = \"Snapshot-Full\",\n    snowflake: str | None = None,\n    complexity: str | None = None,\n    is_immutable: bool | None = None,\n    is_mnpi: bool | None = None,\n    is_pci: bool | None = None,\n    is_pii: bool | None = None,\n    is_client: bool | None = None,\n    is_public: bool | None = None,\n    is_internal: bool | None = None,\n    is_confidential: bool | None = None,\n    is_highly_confidential: bool | None = None,\n    is_active: bool | None = None,\n    owners: list[str] | None = None,\n    application_id: str | dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; Dataset:\n    \"\"\"Instantiate a Dataset object with this client for metadata creation.\n\n    Args:\n        identifier (str): Dataset identifier.\n        title (str, optional): Dataset title. If not provided, defaults to identifier.\n        category (str | list[str] | None, optional): A category or list of categories for the dataset.\n        Defaults to None.\n        description (str, optional): Dataset description. If not provided, defaults to identifier.\n        frequency (str, optional): The frequency of the dataset. Defaults to \"Once\".\n        is_internal_only_dataset (bool, optional): Flag for internal datasets. Defaults to False.\n        is_third_party_data (bool, optional): Flag for third party data. Defaults to True.\n        is_restricted (bool | None, optional): Flag for restricted datasets. Defaults to None.\n        is_raw_data (bool, optional): Flag for raw datasets. Defaults to True.\n        maintainer (str | None, optional): Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".\n        source (str | list[str] | None, optional): Name of data vendor which provided the data. Defaults to None.\n        region (str | list[str] | None, optional): Region. Defaults to None.\n        publisher (str, optional): Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".\n        product (str | list[str] | None, optional): Product to associate dataset with. Defaults to None.\n        sub_category (str | list[str] | None, optional): Sub-category. Defaults to None.\n        tags (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n        created_date (str | None, optional): Created date. Defaults to None.\n        modified_date (str | None, optional): Modified date. Defaults to None.\n        delivery_channel (str | list[str], optional): Delivery channel. Defaults to \"API\".\n        language (str, optional): Language. Defaults to \"English\".\n        status (str, optional): Status. Defaults to \"Available\".\n        type_ (str | None, optional): Dataset type. Defaults to \"Source\".\n        container_type (str | None, optional): Container type. Defaults to \"Snapshot-Full\".\n        snowflake (str | None, optional): Snowflake account connection. Defaults to None.\n        complexity (str | None, optional): Complexity. Defaults to None.\n        is_immutable (bool | None, optional): Flag for immutable datasets. Defaults to None.\n        is_mnpi (bool | None, optional): is_mnpi. Defaults to None.\n        is_pci (bool | None, optional): is_pci. Defaults to None.\n        is_pii (bool | None, optional): is_pii. Defaults to None.\n        is_client (bool | None, optional): is_client. Defaults to None.\n        is_public (bool | None, optional): is_public. Defaults to None.\n        is_internal (bool | None, optional): is_internal. Defaults to None.\n        is_confidential (bool | None, optional): is_confidential. Defaults to None.\n        is_highly_confidential (bool | None, optional): is_highly_confidential. Defaults to None.\n        is_active (bool | None, optional): is_active. Defaults to None.\n        owners (list[str] | None, optional): The owners of the dataset. Defaults to None.\n        application_id (str | None, optional): The application ID of the dataset. Defaults to None.\n\n    Returns:\n        Dataset: Fusion Dataset class.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(identifier=\"DATASET_1\")\n\n    Note:\n        See the dataset module for more information on functionalities of dataset objects.\n\n    \"\"\"\n    dataset_obj = Dataset(\n        identifier=identifier,\n        title=title,\n        category=category,\n        description=description,\n        frequency=frequency,\n        is_internal_only_dataset=is_internal_only_dataset,\n        is_third_party_data=is_third_party_data,\n        is_restricted=is_restricted,\n        is_raw_data=is_raw_data,\n        maintainer=maintainer,\n        source=source,\n        region=region,\n        publisher=publisher,\n        product=product,\n        sub_category=sub_category,\n        tags=tags,\n        created_date=created_date,\n        modified_date=modified_date,\n        delivery_channel=delivery_channel,\n        language=language,\n        status=status,\n        type_=type_,\n        container_type=container_type,\n        snowflake=snowflake,\n        complexity=complexity,\n        is_immutable=is_immutable,\n        is_mnpi=is_mnpi,\n        is_pci=is_pci,\n        is_pii=is_pii,\n        is_client=is_client,\n        is_public=is_public,\n        is_internal=is_internal,\n        is_confidential=is_confidential,\n        is_highly_confidential=is_highly_confidential,\n        is_active=is_active,\n        owners=owners,\n        application_id=application_id,\n        **kwargs,\n    )\n    dataset_obj.client = self\n    return dataset_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.dataset_resources","title":"<code>dataset_resources(dataset, catalog=None, output=False)</code>","text":"<p>List the resources available for a dataset, currently this will always be a datasetseries.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each resource</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def dataset_resources(self, dataset: str, catalog: str | None = None, output: bool = False) -&gt; pd.DataFrame:\n    \"\"\"List the resources available for a dataset, currently this will always be a datasetseries.\n\n    Args:\n        dataset (str): A dataset identifier\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n\n    Returns:\n        class:`pandas.DataFrame`: A dataframe with a row for each resource\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}\"\n    ds_res_df = Fusion._call_for_dataframe(url, self.session)\n\n    if output:\n        pass\n\n    return ds_res_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.datasetmember_resources","title":"<code>datasetmember_resources(dataset, series, catalog=None, output=False)</code>","text":"<p>List the available resources for a datasetseries member.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>series</code> <code>str</code> <p>The datasetseries identifier</p> required <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each datasetseries member resource. Currently, this will always be distributions.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def datasetmember_resources(\n    self,\n    dataset: str,\n    series: str,\n    catalog: str | None = None,\n    output: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"List the available resources for a datasetseries member.\n\n    Args:\n        dataset (str): A dataset identifier\n        series (str): The datasetseries identifier\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n\n    Returns:\n        class:`pandas.DataFrame`: A dataframe with a row for each datasetseries member resource.\n            Currently, this will always be distributions.\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries/{series}\"\n    ds_mem_res_df = Fusion._call_for_dataframe(url, self.session)\n\n    if output:\n        pass\n\n    return ds_mem_res_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.delete_all_datasetmembers","title":"<code>delete_all_datasetmembers(dataset, catalog=None, return_resp_obj=False)</code>","text":"<p>Delete all dataset members within a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>list[requests.Response]: a list of response objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.delete_all_datasetmembers(dataset=\"dataset1\")\n</code></pre> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def delete_all_datasetmembers(\n    self,\n    dataset: str,\n    catalog: str | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Delete all dataset members within a dataset.\n\n    Args:\n        dataset (str): A dataset identifier\n        catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        list[requests.Response]: a list of response objects.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.delete_all_datasetmembers(dataset=\"dataset1\")\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries\"\n    resp = self.session.delete(url)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.delete_datasetmembers","title":"<code>delete_datasetmembers(dataset, series_members, catalog=None, return_resp_obj=False)</code>","text":"<p>Delete dataset members.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>series_members</code> <code>str | list[str]</code> <p>A string or list of strings that are dataset series member</p> required <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[Response] | None</code> <p>list[requests.Response]: a list of response objects.</p> <p>Examples:</p> <p>Delete one dataset member.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.delete_datasetmembers(dataset=\"dataset1\", series_members=\"series1\")\n</code></pre> <p>Delete multiple dataset members.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.delete_datasetmembers(dataset=\"dataset1\", series_members=[\"series1\", \"series2\"])\n</code></pre> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def delete_datasetmembers(\n    self,\n    dataset: str,\n    series_members: str | list[str],\n    catalog: str | None = None,\n    return_resp_obj: bool = False,\n) -&gt; list[requests.Response] | None:\n    \"\"\"Delete dataset members.\n\n    Args:\n        dataset (str): A dataset identifier\n        series_members (str | list[str]): A string or list of strings that are dataset series member\n        identifiers to delete.\n        catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        list[requests.Response]: a list of response objects.\n\n    Examples:\n        Delete one dataset member.\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.delete_datasetmembers(dataset=\"dataset1\", series_members=\"series1\")\n\n        Delete multiple dataset members.\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.delete_datasetmembers(dataset=\"dataset1\", series_members=[\"series1\", \"series2\"])\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n    if isinstance(series_members, str):\n        series_members = [series_members]\n    responses = []\n    for series_member in series_members:\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries/{series_member}\"\n        resp = self.session.delete(url)\n        requests_raise_for_status(resp)\n        responses.append(resp)\n    return responses if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.download","title":"<code>download(dataset, dt_str='latest', dataset_format='parquet', catalog=None, n_par=None, show_progress=True, force_download=False, download_folder=None, return_paths=False, partitioning=None, preserve_original_name=False)</code>","text":"<p>Downloads the requested distributions of a dataset to disk.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>dt_str</code> <code>str</code> <p>Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset. If more than one series member exists on the latest date, the series member identifiers will be sorted alphabetically and the last one will be downloaded.</p> <code>'latest'</code> <code>dataset_format</code> <code>str</code> <p>The file format, e.g. CSV or Parquet. Defaults to 'parquet'. If set to None, the function will download if only one format is available, else it will raise an error.</p> <code>'parquet'</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>n_par</code> <code>int</code> <p>Specify how many distributions to download in parallel. Defaults to all cpus available.</p> <code>None</code> <code>show_progress</code> <code>bool</code> <p>Display a progress bar during data download Defaults to True.</p> <code>True</code> <code>force_download</code> <code>bool</code> <p>If True then will always download a file even if it is already on disk. Defaults to True.</p> <code>False</code> <code>download_folder</code> <code>str</code> <p>The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in init</p> <code>None</code> <code>return_paths</code> <code>bool</code> <p>Return paths and success statuses of the downloaded files.</p> <code>False</code> <code>partitioning</code> <code>str</code> <p>Partitioning specification.</p> <code>None</code> <code>preserve_original_name</code> <code>bool</code> <p>Preserve the original name of the file. Defaults to False.</p> <code>False</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def download(  # noqa: PLR0912, PLR0913\n    self,\n    dataset: str,\n    dt_str: str = \"latest\",\n    dataset_format: str | None = \"parquet\",\n    catalog: str | None = None,\n    n_par: int | None = None,\n    show_progress: bool = True,\n    force_download: bool = False,\n    download_folder: str | None = None,\n    return_paths: bool = False,\n    partitioning: str | None = None,\n    preserve_original_name: bool = False,\n) -&gt; list[tuple[bool, str, str | None]] | None:\n    \"\"\"Downloads the requested distributions of a dataset to disk.\n\n    Args:\n        dataset (str): A dataset identifier\n        dt_str (str, optional): Either a single date or a range identified by a start or end date,\n            or both separated with a \":\". Defaults to 'latest' which will return the most recent\n            instance of the dataset. If more than one series member exists on the latest date, the\n            series member identifiers will be sorted alphabetically and the last one will be downloaded.\n        dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n            If set to None, the function will download if only one format is available, else it will raise an error.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        n_par (int, optional): Specify how many distributions to download in parallel.\n            Defaults to all cpus available.\n        show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n        force_download (bool, optional): If True then will always download a file even\n            if it is already on disk. Defaults to True.\n        download_folder (str, optional): The path, absolute or relative, where downloaded files are saved.\n            Defaults to download_folder as set in __init__\n        return_paths (bool, optional): Return paths and success statuses of the downloaded files.\n        partitioning (str, optional): Partitioning specification.\n        preserve_original_name (bool, optional): Preserve the original name of the file. Defaults to False.\n\n    Returns:\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    # check access to the dataset\n    dataset_resp = self.session.get(f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}\")\n    requests_raise_for_status(dataset_resp)\n\n    access_status = dataset_resp.json().get(\"status\")\n    if access_status != \"Subscribed\":\n        raise APIResponseError(\n            ValueError(f\"You are not subscribed to {dataset} in catalog {catalog}. Please request access.\"),\n            status_code=401,\n        )\n\n    valid_date_range = re.compile(r\"^(\\d{4}\\d{2}\\d{2})$|^((\\d{4}\\d{2}\\d{2})?([:])(\\d{4}\\d{2}\\d{2})?)$\")\n\n    # check that format is valid and if none, check if there is only one format available\n    available_formats = list(self.list_datasetmembers_distributions(dataset, catalog)[\"format\"].unique())\n    if dataset_format and dataset_format not in available_formats:\n        raise FileFormatError(\n            f\"Dataset format {dataset_format} is not available for {dataset} in catalog {catalog}. \"\n            f\"Available formats are {available_formats}.\"\n        )\n    if dataset_format is None:\n        if len(available_formats) == 1:\n            dataset_format = available_formats[0]\n        else:\n            raise FileFormatError(\n                f\"Multiple formats found for {dataset} in catalog {catalog}. Dataset format is required to\"\n                f\"download. Available formats are {available_formats}.\"\n            )\n\n    if valid_date_range.match(dt_str) or dt_str == \"latest\":\n        required_series = self._resolve_distro_tuples(dataset, dt_str, dataset_format, catalog)\n    else:\n        # sample data is limited to csv\n        if dt_str == \"sample\":\n            dataset_format = self.list_distributions(dataset, dt_str, catalog)[\"identifier\"].iloc[0]\n        required_series = [(catalog, dataset, dt_str, dataset_format)] # type: ignore[list-item]\n\n    if dataset_format not in RECOGNIZED_FORMATS + [\"raw\"]:\n        raise FileFormatError(f\"Dataset format {dataset_format} is not supported.\")\n\n    if not download_folder:\n        download_folder = self.download_folder\n\n    download_folders = [download_folder] * len(required_series)\n\n    if partitioning == \"hive\":\n        members = [series[2].strip(\"/\") for series in required_series]\n        download_folders = [\n            f\"{download_folders[i]}/{series[0]}/{series[1]}/{members[i]}\"\n            for i, series in enumerate(required_series)\n        ]\n\n    for d in download_folders:\n        if not self.fs.exists(d):\n            self.fs.mkdir(d, create_parents=True)\n\n    n_par = cpu_count(n_par)\n    download_spec = [\n        {\n            \"lfs\": self.fs,\n            \"rpath\": distribution_to_url(\n                self.root_url,\n                series[1],\n                series[2],\n                series[3],\n                series[0],\n                is_download=True,\n            ),\n            \"lpath\": distribution_to_filename(\n                download_folders[i],\n                series[1],\n                series[2],\n                series[3],\n                series[0],\n                partitioning=partitioning,\n            ),\n            \"overwrite\": force_download,\n            \"preserve_original_name\": preserve_original_name,\n        }\n        for i, series in enumerate(required_series)\n    ]\n\n    logger.log(\n        VERBOSE_LVL,\n        f\"Beginning {len(download_spec)} downloads in batches of {n_par}\",\n    )\n    if show_progress:\n        with Progress() as p:\n            task = p.add_task(\"Downloading\", total=len(download_spec))\n            res = []\n            for spec in download_spec:\n                r = self.get_fusion_filesystem().download(**spec)\n                res.append(r)\n                p.update(task, advance=1)\n    else:\n        res = [self.get_fusion_filesystem().download(**spec) for spec in download_spec]\n\n    if (len(res) &gt; 0) and (not all(r[0] for r in res)):\n        for r in res:\n            if not r[0]:\n                warnings.warn(f\"The download of {r[1]} was not successful\", stacklevel=2)\n    return res if return_paths else None\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.from_bytes","title":"<code>from_bytes(data, dataset, series_member='latest', catalog=None, distribution='parquet', show_progress=True, multipart=True, return_paths=False, chunk_size=5 * 2 ** 20, from_date=None, to_date=None, file_name=None, **kwargs)</code>","text":"<p>Uploads data from an object in memory.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>an object in memory to upload</p> required <code>dataset</code> <code>str</code> <p>Dataset name to which the bytes will be uploaded.</p> required <code>series_member</code> <code>str</code> <p>A single date or label. Defaults to 'latest' which will return the most recent.</p> <code>'latest'</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>distribution</code> <code>str</code> <p>A distribution type, e.g. a file format or raw</p> <code>'parquet'</code> <code>show_progress</code> <code>bool</code> <p>Display a progress bar during data download Defaults to True.</p> <code>True</code> <code>multipart</code> <code>bool</code> <p>Is multipart upload.</p> <code>True</code> <code>return_paths</code> <code>bool</code> <p>Return paths and success statuses of the downloaded files.</p> <code>False</code> <code>chunk_size</code> <code>int</code> <p>Maximum chunk size.</p> <code>5 * 2 ** 20</code> <code>from_date</code> <code>str</code> <p>start of the data date range contained in the distribution, defaults to upload date</p> <code>None</code> <code>to_date</code> <code>str</code> <p>end of the data date range contained in the distribution, defaults to upload date.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>file name to be used for the uploaded file. Defaults to Fusion standard naming.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[tuple[bool, str, str | None]] | None</code> <p>Optional[list[tuple[bool, str, Optional[str]]]: a list of tuples, one for each distribution</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def from_bytes(  # noqa: PLR0913\n    self,\n    data: BytesIO,\n    dataset: str,\n    series_member: str = \"latest\",\n    catalog: str | None = None,\n    distribution: str = \"parquet\",\n    show_progress: bool = True,\n    multipart: bool = True,\n    return_paths: bool = False,\n    chunk_size: int = 5 * 2**20,\n    from_date: str | None = None,\n    to_date: str | None = None,\n    file_name: str | None = None,\n    **kwargs: Any,  # noqa: ARG002\n) -&gt; list[tuple[bool, str, str | None]] | None:\n    \"\"\"Uploads data from an object in memory.\n\n    Args:\n        data (str): an object in memory to upload\n        dataset (str): Dataset name to which the bytes will be uploaded.\n        series_member (str, optional): A single date or label. Defaults to 'latest' which will return\n            the most recent.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        distribution (str, optional): A distribution type, e.g. a file format or raw\n        show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n        multipart (bool, optional): Is multipart upload.\n        return_paths (bool, optional): Return paths and success statuses of the downloaded files.\n        chunk_size (int, optional): Maximum chunk size.\n        from_date (str, optional): start of the data date range contained in the distribution,\n            defaults to upload date\n        to_date (str, optional): end of the data date range contained in the distribution, defaults to upload date.\n        file_name (str, optional): file name to be used for the uploaded file. Defaults to Fusion standard naming.\n\n    Returns:\n        Optional[list[tuple[bool, str, Optional[str]]]: a list of tuples, one for each distribution\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    fs_fusion = self.get_fusion_filesystem()\n    if distribution not in RECOGNIZED_FORMATS + [\"raw\"]:\n        raise ValueError(f\"Dataset format {distribution} is not supported\")\n\n    is_raw = js.loads(fs_fusion.cat(f\"{catalog}/datasets/{dataset}\"))[\"isRawData\"]\n    local_url_eqiv = path_to_url(f\"{dataset}__{catalog}__{series_member}.{distribution}\", is_raw)\n\n    data_map_df = pd.DataFrame([\"\", local_url_eqiv, file_name]).T\n    data_map_df.columns = [\"path\", \"url\", \"file_name\"]  # type: ignore[assignment]\n\n    res = upload_files(\n        fs_fusion,\n        data,\n        data_map_df,\n        multipart=multipart,\n        chunk_size=chunk_size,\n        show_progress=show_progress,\n        from_date=from_date,\n        to_date=to_date,\n    )\n\n    if not all(r[0] for r in res):\n        failed_res = [r for r in res if not r[0]]\n        msg = f\"Not all uploads were successfully completed. The following failed:\\n{failed_res}\"\n        logger.warning(msg)\n        warnings.warn(msg, stacklevel=2)\n\n    return res if return_paths else None\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.get_async_fusion_vector_store_client","title":"<code>get_async_fusion_vector_store_client(knowledge_base, catalog=None)</code>","text":"<p>Returns Fusion Embeddings Search client.</p> <p>Parameters:</p> Name Type Description Default <code>knowledge_base</code> <code>str</code> <p>Knowledge base (dataset) identifier.</p> required <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>OpenSearch</code> <code>AsyncOpenSearch</code> <p>Fusion Embeddings Search client.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def get_async_fusion_vector_store_client(self, knowledge_base: str, catalog: str | None = None) -&gt; AsyncOpenSearch:\n    \"\"\"Returns Fusion Embeddings Search client.\n\n    Args:\n        knowledge_base (str): Knowledge base (dataset) identifier.\n        catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n\n    Returns:\n        OpenSearch: Fusion Embeddings Search client.\n\n    \"\"\"\n    from opensearchpy import AsyncOpenSearch\n\n    from fusion.embeddings import FusionAsyncHttpConnection\n\n    catalog = self._use_catalog(catalog)\n    return AsyncOpenSearch(\n        connection_class=FusionAsyncHttpConnection,\n        catalog=catalog,\n        knowledge_base=knowledge_base,\n        root_url=self.root_url,\n        credentials=self.credentials,\n    )\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.get_events","title":"<code>get_events(last_event_id=None, catalog=None, in_background=True, url=None)</code>","text":"<p>Run server sent event listener and print out the new events. Keyboard terminate to stop.</p> <p>Parameters:</p> Name Type Description Default <code>last_event_id</code> <code>str</code> <p>id of the last event.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>catalog.</p> <code>None</code> <code>in_background</code> <code>bool</code> <p>execute event monitoring in the background (default = True).</p> <code>True</code> <code>url</code> <code>str</code> <p>subscription url. Defaults to client's root url.</p> <code>None</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def get_events(\n    self,\n    last_event_id: str | None = None,\n    catalog: str | None = None,\n    in_background: bool = True,\n    url: str | None = None,\n) -&gt; None | pd.DataFrame:\n    \"\"\"Run server sent event listener and print out the new events. Keyboard terminate to stop.\n\n    Args:\n        last_event_id (str): id of the last event.\n        catalog (str): catalog.\n        in_background (bool): execute event monitoring in the background (default = True).\n        url (str): subscription url. Defaults to client's root url.\n    Returns:\n        Union[None, class:`pandas.DataFrame`]: If in_background is True then the function returns no output.\n            If in_background is set to False then pandas DataFrame is output upon keyboard termination.\n    \"\"\"\n\n    catalog = self._use_catalog(catalog)\n    url = self.root_url if url is None else url\n\n    if not in_background:\n        from sseclient import SSEClient\n\n        _ = self.catalog_resources()  # refresh token\n        interrupted = False\n        messages = SSEClient(\n            session=self.session,\n            url=f\"{url}catalogs/{catalog}/notifications/subscribe\",\n            last_id=last_event_id,\n            headers={\n                \"authorization\": f\"bearer {self.credentials.bearer_token}\",\n            },\n        )\n        lst = []\n        try:\n            for msg in messages:\n                event = js.loads(msg.data)\n                # Preserve the original metaData column\n                original_meta_data = event.get(\"metaData\", {})\n\n                # Flatten the metaData dictionary into the event dictionary\n                if isinstance(original_meta_data, dict):\n                    event.update(original_meta_data)\n\n                if event[\"type\"] != \"HeartBeatNotification\":\n                    lst.append(event)\n        except KeyboardInterrupt:\n            interrupted = True\n        except Exception as e:\n            raise e\n        finally:\n            result = pd.DataFrame(lst) if interrupted or lst else None\n        return result\n    else:\n        return self.events\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.get_fusion_filesystem","title":"<code>get_fusion_filesystem(**kwargs)</code>","text":"<p>Retrieve Fusion file system instance.</p> <p>Note: This function always returns a reference to the exact same FFS instance since an FFS instance is based off the FusionCredentials object.</p> <p>Returns: Fusion Filesystem</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def get_fusion_filesystem(self, **kwargs: Any) -&gt; FusionHTTPFileSystem:\n    \"\"\"Retrieve Fusion file system instance.\n\n    Note: This function always returns a reference to the exact same FFS instance since\n    an FFS instance is based off the FusionCredentials object.\n\n    Returns: Fusion Filesystem\n\n    \"\"\"\n    as_async = kwargs.get(\"asynchronous\", False)\n    return FusionHTTPFileSystem(\n        asynchronous=as_async, client_kwargs={\"root_url\": self.root_url, \"credentials\": self.credentials}\n    )\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.get_fusion_vector_store_client","title":"<code>get_fusion_vector_store_client(knowledge_base, catalog=None)</code>","text":"<p>Returns Fusion Embeddings Search client.</p> <p>Parameters:</p> Name Type Description Default <code>knowledge_base</code> <code>str</code> <p>Knowledge base (dataset) identifier.</p> required <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>OpenSearch</code> <code>OpenSearch</code> <p>Fusion Embeddings Search client.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def get_fusion_vector_store_client(self, knowledge_base: str, catalog: str | None = None) -&gt; OpenSearch:\n    \"\"\"Returns Fusion Embeddings Search client.\n\n    Args:\n        knowledge_base (str): Knowledge base (dataset) identifier.\n        catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n\n    Returns:\n        OpenSearch: Fusion Embeddings Search client.\n\n    \"\"\"\n    from opensearchpy import OpenSearch\n\n    from fusion.embeddings import FusionEmbeddingsConnection\n\n    catalog = self._use_catalog(catalog)\n    return OpenSearch(\n        connection_class=FusionEmbeddingsConnection,\n        catalog=catalog,\n        knowledge_base=knowledge_base,\n        root_url=self.root_url,\n        credentials=self.credentials,\n    )\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.input_dataflow","title":"<code>input_dataflow(identifier, title='', category=None, description='', frequency='Once', is_internal_only_dataset=False, is_third_party_data=True, is_restricted=None, is_raw_data=True, maintainer='J.P. Morgan Fusion', source=None, region=None, publisher='J.P. Morgan', product=None, sub_category=None, tags=None, created_date=None, modified_date=None, delivery_channel='API', language='English', status='Available', type_='Flow', container_type='Snapshot-Full', snowflake=None, complexity=None, is_immutable=None, is_mnpi=None, is_pci=None, is_pii=None, is_client=None, is_public=None, is_internal=None, is_confidential=None, is_highly_confidential=None, is_active=None, owners=None, application_id=None, producer_application_id=None, consumer_application_id=None, flow_details=None, **kwargs)</code>","text":"<p>Instantiate an Input Dataflow object with this client for metadata creation.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Dataset identifier.</p> required <code>title</code> <code>str</code> <p>Dataset title. If not provided, defaults to identifier.</p> <code>''</code> <code>category</code> <code>str | list[str] | None</code> <p>A category or list of categories for the dataset.</p> <code>None</code> <code>description</code> <code>str</code> <p>Dataset description. If not provided, defaults to identifier.</p> <code>''</code> <code>frequency</code> <code>str</code> <p>The frequency of the dataset. Defaults to \"Once\".</p> <code>'Once'</code> <code>is_internal_only_dataset</code> <code>bool</code> <p>Flag for internal datasets. Defaults to False.</p> <code>False</code> <code>is_third_party_data</code> <code>bool</code> <p>Flag for third party data. Defaults to True.</p> <code>True</code> <code>is_restricted</code> <code>bool | None</code> <p>Flag for restricted datasets. Defaults to None.</p> <code>None</code> <code>is_raw_data</code> <code>bool</code> <p>Flag for raw datasets. Defaults to True.</p> <code>True</code> <code>maintainer</code> <code>str | None</code> <p>Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".</p> <code>'J.P. Morgan Fusion'</code> <code>source</code> <code>str | list[str] | None</code> <p>Name of data vendor which provided the data. Defaults to None.</p> <code>None</code> <code>region</code> <code>str | list[str] | None</code> <p>Region. Defaults to None.</p> <code>None</code> <code>publisher</code> <code>str</code> <p>Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".</p> <code>'J.P. Morgan'</code> <code>product</code> <code>str | list[str] | None</code> <p>Product to associate dataset with. Defaults to None.</p> <code>None</code> <code>sub_category</code> <code>str | list[str] | None</code> <p>Sub-category. Defaults to None.</p> <code>None</code> <code>tags</code> <code>str | list[str] | None</code> <p>Tags used for search purposes. Defaults to None.</p> <code>None</code> <code>created_date</code> <code>str | None</code> <p>Created date. Defaults to None.</p> <code>None</code> <code>modified_date</code> <code>str | None</code> <p>Modified date. Defaults to None.</p> <code>None</code> <code>delivery_channel</code> <code>str | list[str]</code> <p>Delivery channel. Defaults to \"API\".</p> <code>'API'</code> <code>language</code> <code>str</code> <p>Language. Defaults to \"English\".</p> <code>'English'</code> <code>status</code> <code>str</code> <p>Status. Defaults to \"Available\".</p> <code>'Available'</code> <code>type_</code> <code>str | None</code> <p>Dataset type. Defaults to \"Flow\".</p> <code>'Flow'</code> <code>container_type</code> <code>str | None</code> <p>Container type. Defaults to \"Snapshot-Full\".</p> <code>'Snapshot-Full'</code> <code>snowflake</code> <code>str | None</code> <p>Snowflake account connection. Defaults to None.</p> <code>None</code> <code>complexity</code> <code>str | None</code> <p>Complexity. Defaults to None.</p> <code>None</code> <code>is_immutable</code> <code>bool | None</code> <p>Flag for immutable datasets. Defaults to None.</p> <code>None</code> <code>is_mnpi</code> <code>bool | None</code> <p>is_mnpi. Defaults to None.</p> <code>None</code> <code>is_pci</code> <code>bool | None</code> <p>is_pci. Defaults to None.</p> <code>None</code> <code>is_pii</code> <code>bool | None</code> <p>is_pii. Defaults to None.</p> <code>None</code> <code>is_client</code> <code>bool | None</code> <p>is_client. Defaults to None.</p> <code>None</code> <code>is_public</code> <code>bool | None</code> <p>is_public. Defaults to None.</p> <code>None</code> <code>is_internal</code> <code>bool | None</code> <p>is_internal. Defaults to None.</p> <code>None</code> <code>is_confidential</code> <code>bool | None</code> <p>is_confidential. Defaults to None.</p> <code>None</code> <code>is_highly_confidential</code> <code>bool | None</code> <p>is_highly_confidential. Defaults to None.</p> <code>None</code> <code>is_active</code> <code>bool | None</code> <p>is_active. Defaults to None.</p> <code>None</code> <code>owners</code> <code>list[str] | None</code> <p>The owners of the dataset. Defaults to None.</p> <code>None</code> <code>application_id</code> <code>str | None</code> <p>The application ID of the dataset. Defaults to None.</p> <code>None</code> <code>producer_application_id</code> <code>dict[str, str] | None</code> <p>The producer application ID (upstream application producing the flow).</p> <code>None</code> <code>consumer_application_id</code> <code>list[dict[str, str]] | dict[str, str] | None</code> <p>The consumer application ID (downstream application, consuming the flow).</p> <code>None</code> <code>flow_details</code> <code>dict[str, str] | None</code> <p>The flow details. Specifies input versus output flow. Defaults to {\"flowDirection\": \"Input\"}.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>InputDataFlow</code> <p>Fusion InputDataFlow class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.input_dataflow(identifier=\"MY_DATAFLOW\")\n</code></pre> Note <p>See the dataset module for more information on functionalities of input dataflow objects.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def input_dataflow(  # noqa: PLR0913\n    self,\n    identifier: str,\n    title: str = \"\",\n    category: str | list[str] | None = None,\n    description: str = \"\",\n    frequency: str = \"Once\",\n    is_internal_only_dataset: bool = False,\n    is_third_party_data: bool = True,\n    is_restricted: bool | None = None,\n    is_raw_data: bool = True,\n    maintainer: str | None = \"J.P. Morgan Fusion\",\n    source: str | list[str] | None = None,\n    region: str | list[str] | None = None,\n    publisher: str = \"J.P. Morgan\",\n    product: str | list[str] | None = None,\n    sub_category: str | list[str] | None = None,\n    tags: str | list[str] | None = None,\n    created_date: str | None = None,\n    modified_date: str | None = None,\n    delivery_channel: str | list[str] = \"API\",\n    language: str = \"English\",\n    status: str = \"Available\",\n    type_: str | None = \"Flow\",\n    container_type: str | None = \"Snapshot-Full\",\n    snowflake: str | None = None,\n    complexity: str | None = None,\n    is_immutable: bool | None = None,\n    is_mnpi: bool | None = None,\n    is_pci: bool | None = None,\n    is_pii: bool | None = None,\n    is_client: bool | None = None,\n    is_public: bool | None = None,\n    is_internal: bool | None = None,\n    is_confidential: bool | None = None,\n    is_highly_confidential: bool | None = None,\n    is_active: bool | None = None,\n    owners: list[str] | None = None,\n    application_id: str | dict[str, str] | None = None,\n    producer_application_id: dict[str, str] | None = None,\n    consumer_application_id: list[dict[str, str]] | dict[str, str] | None = None,\n    flow_details: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; InputDataFlow:\n    \"\"\"Instantiate an Input Dataflow object with this client for metadata creation.\n\n    Args:\n        identifier (str): Dataset identifier.\n        title (str, optional): Dataset title. If not provided, defaults to identifier.\n        category (str | list[str] | None, optional): A category or list of categories for the dataset.\n        Defaults to None.\n        description (str, optional): Dataset description. If not provided, defaults to identifier.\n        frequency (str, optional): The frequency of the dataset. Defaults to \"Once\".\n        is_internal_only_dataset (bool, optional): Flag for internal datasets. Defaults to False.\n        is_third_party_data (bool, optional): Flag for third party data. Defaults to True.\n        is_restricted (bool | None, optional): Flag for restricted datasets. Defaults to None.\n        is_raw_data (bool, optional): Flag for raw datasets. Defaults to True.\n        maintainer (str | None, optional): Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".\n        source (str | list[str] | None, optional): Name of data vendor which provided the data. Defaults to None.\n        region (str | list[str] | None, optional): Region. Defaults to None.\n        publisher (str, optional): Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".\n        product (str | list[str] | None, optional): Product to associate dataset with. Defaults to None.\n        sub_category (str | list[str] | None, optional): Sub-category. Defaults to None.\n        tags (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n        created_date (str | None, optional): Created date. Defaults to None.\n        modified_date (str | None, optional): Modified date. Defaults to None.\n        delivery_channel (str | list[str], optional): Delivery channel. Defaults to \"API\".\n        language (str, optional): Language. Defaults to \"English\".\n        status (str, optional): Status. Defaults to \"Available\".\n        type_ (str | None, optional): Dataset type. Defaults to \"Flow\".\n        container_type (str | None, optional): Container type. Defaults to \"Snapshot-Full\".\n        snowflake (str | None, optional): Snowflake account connection. Defaults to None.\n        complexity (str | None, optional): Complexity. Defaults to None.\n        is_immutable (bool | None, optional): Flag for immutable datasets. Defaults to None.\n        is_mnpi (bool | None, optional): is_mnpi. Defaults to None.\n        is_pci (bool | None, optional): is_pci. Defaults to None.\n        is_pii (bool | None, optional): is_pii. Defaults to None.\n        is_client (bool | None, optional): is_client. Defaults to None.\n        is_public (bool | None, optional): is_public. Defaults to None.\n        is_internal (bool | None, optional): is_internal. Defaults to None.\n        is_confidential (bool | None, optional): is_confidential. Defaults to None.\n        is_highly_confidential (bool | None, optional): is_highly_confidential. Defaults to None.\n        is_active (bool | None, optional): is_active. Defaults to None.\n        owners (list[str] | None, optional): The owners of the dataset. Defaults to None.\n        application_id (str | None, optional): The application ID of the dataset. Defaults to None.\n        producer_application_id (dict[str, str] | None, optional): The producer application ID (upstream application\n            producing the flow).\n        consumer_application_id (list[dict[str, str]] | dict[str, str] | None, optional): The consumer application\n            ID (downstream application, consuming the flow).\n        flow_details (dict[str, str] | None, optional): The flow details. Specifies input versus output flow.\n            Defaults to {\"flowDirection\": \"Input\"}.\n\n    Returns:\n        Dataset: Fusion InputDataFlow class.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.input_dataflow(identifier=\"MY_DATAFLOW\")\n\n    Note:\n        See the dataset module for more information on functionalities of input dataflow objects.\n\n    \"\"\"\n    flow_details = {\"flowDirection\": \"Input\"} if flow_details is None else flow_details\n    dataflow_obj = InputDataFlow(\n        identifier=identifier,\n        title=title,\n        category=category,\n        description=description,\n        frequency=frequency,\n        is_internal_only_dataset=is_internal_only_dataset,\n        is_third_party_data=is_third_party_data,\n        is_restricted=is_restricted,\n        is_raw_data=is_raw_data,\n        maintainer=maintainer,\n        source=source,\n        region=region,\n        publisher=publisher,\n        product=product,\n        sub_category=sub_category,\n        tags=tags,\n        created_date=created_date,\n        modified_date=modified_date,\n        delivery_channel=delivery_channel,\n        language=language,\n        status=status,\n        type_=type_,\n        container_type=container_type,\n        snowflake=snowflake,\n        complexity=complexity,\n        is_immutable=is_immutable,\n        is_mnpi=is_mnpi,\n        is_pci=is_pci,\n        is_pii=is_pii,\n        is_client=is_client,\n        is_public=is_public,\n        is_internal=is_internal,\n        is_confidential=is_confidential,\n        is_highly_confidential=is_highly_confidential,\n        is_active=is_active,\n        owners=owners,\n        application_id=application_id,\n        producer_application_id=producer_application_id,\n        consumer_application_id=consumer_application_id,\n        flow_details=flow_details,\n        **kwargs,\n    )\n    dataflow_obj.client = self\n    return dataflow_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.link_attributes_to_terms","title":"<code>link_attributes_to_terms(report_id, mappings, return_resp_obj=False)</code>","text":"<p>Link one or more report attributes to business glossary terms.</p> Each mapping should follow this format <p>{     \"attribute\": {\"id\": \"attribute-id\"},     \"term\": {\"id\": \"term-id\"},     \"isKDE\": True  # Optional; defaults to True if not provided }</p> <p>This method wraps <code>Report.link_attributes_to_terms</code> and automatically attaches the Fusion client.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def link_attributes_to_terms(\n    self,\n    report_id: str,\n    mappings: list[Report.AttributeTermMapping],\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"\n    Link one or more report attributes to business glossary terms.\n\n    Each mapping should follow this format:\n        {\n            \"attribute\": {\"id\": \"attribute-id\"},\n            \"term\": {\"id\": \"term-id\"},\n            \"isKDE\": True  # Optional; defaults to True if not provided\n        }\n\n    This method wraps `Report.link_attributes_to_terms` and automatically attaches the Fusion client.\n    \"\"\"\n\n    processed_mappings = []\n    for mapping in mappings:\n        new_mapping = mapping.copy()\n        if \"isKDE\" not in new_mapping:\n            new_mapping[\"isKDE\"] = True \n        processed_mappings.append(new_mapping)\n\n    return Report.link_attributes_to_terms(\n        report_id=report_id,\n        mappings=processed_mappings,\n        client=self,\n        return_resp_obj=return_resp_obj\n    )\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_catalogs","title":"<code>list_catalogs(output=False)</code>","text":"<p>Lists the catalogs available to the API account.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each catalog</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_catalogs(self, output: bool = False) -&gt; pd.DataFrame:\n    \"\"\"Lists the catalogs available to the API account.\n\n    Args:\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n\n    Returns:\n        class:`pandas.DataFrame`: A dataframe with a row for each catalog\n    \"\"\"\n    url = f\"{self.root_url}catalogs/\"\n    cat_df = Fusion._call_for_dataframe(url, self.session)\n\n    if output:\n        pass\n\n    return cat_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_dataset_attributes","title":"<code>list_dataset_attributes(dataset, catalog=None, output=False, display_all_columns=False)</code>","text":"<p>Returns the list of attributes that are in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <code>display_all_columns</code> <code>bool</code> <p>If True displays all columns returned by the API, otherwise only the key columns are displayed</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each attribute</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_dataset_attributes(\n    self,\n    dataset: str,\n    catalog: str | None = None,\n    output: bool = False,\n    display_all_columns: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Returns the list of attributes that are in the dataset.\n\n    Args:\n        dataset (str): A dataset identifier\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n        display_all_columns (bool, optional): If True displays all columns returned by the API,\n            otherwise only the key columns are displayed\n\n    Returns:\n        class:`pandas.DataFrame`: A dataframe with a row for each attribute\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/attributes\"\n    ds_attr_df = Fusion._call_for_dataframe(url, self.session)\n\n    if \"index\" in ds_attr_df.columns:\n        ds_attr_df = ds_attr_df.sort_values(by=\"index\").reset_index(drop=True)\n\n    if not display_all_columns:\n        ds_attr_df = ds_attr_df[\n            ds_attr_df.columns.intersection(\n                [\n                    \"identifier\",\n                    \"title\",\n                    \"dataType\",\n                    \"isDatasetKey\",\n                    \"description\",\n                    \"source\",\n                ]\n            )\n        ]\n\n    if output:\n        pass\n\n    return ds_attr_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_dataset_lineage","title":"<code>list_dataset_lineage(dataset_id, catalog=None, output=False, max_results=-1)</code>","text":"<p>List the upstream and downstream lineage of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <code>max_results</code> <code>int</code> <p>Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each resource</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If the dataset is not found in the catalog.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_dataset_lineage(\n    self,\n    dataset_id: str,\n    catalog: str | None = None,\n    output: bool = False,\n    max_results: int = -1,\n) -&gt; pd.DataFrame:\n    \"\"\"List the upstream and downstream lineage of the dataset.\n\n    Args:\n        dataset (str): A dataset identifier\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n        max_results (int, optional): Limit the number of rows returned in the dataframe.\n            Defaults to -1 which returns all results.\n\n    Returns:\n        class:`pandas.DataFrame`: A dataframe with a row for each resource\n\n    Raises:\n        HTTPError: If the dataset is not found in the catalog.\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url_dataset = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset_id}\"\n    resp_dataset = self.session.get(url_dataset)\n    resp_dataset.raise_for_status()\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset_id}/lineage\"\n    resp = self.session.get(url)\n    data = resp.json()\n    relations_data = data[\"relations\"]\n\n    restricted_datasets = [\n        dataset_metadata[\"identifier\"]\n        for dataset_metadata in data[\"datasets\"]\n        if dataset_metadata.get(\"status\", None) == \"Restricted\"\n    ]\n\n    data_dict = {}\n\n    for entry in relations_data:\n        source_dataset_id = entry[\"source\"][\"dataset\"]\n        source_catalog = entry[\"source\"][\"catalog\"]\n        destination_dataset_id = entry[\"destination\"][\"dataset\"]\n        destination_catalog = entry[\"destination\"][\"catalog\"]\n\n        if destination_dataset_id == dataset_id:\n            for dataset in data[\"datasets\"]:\n                if dataset[\"identifier\"] == source_dataset_id and dataset.get(\"status\", None) != \"Restricted\":\n                    source_dataset_title = dataset[\"title\"]\n                elif dataset[\"identifier\"] == source_dataset_id and dataset.get(\"status\", None) == \"Restricted\":\n                    source_dataset_title = \"Access Restricted\"\n            data_dict[source_dataset_id] = (\n                \"source\",\n                source_catalog,\n                source_dataset_title,\n            )\n\n        if source_dataset_id == dataset_id:\n            for dataset in data[\"datasets\"]:\n                if dataset[\"identifier\"] == destination_dataset_id and dataset.get(\"status\", None) != \"Restricted\":\n                    destination_dataset_title = dataset[\"title\"]\n                elif (\n                    dataset[\"identifier\"] == destination_dataset_id and dataset.get(\"status\", None) == \"Restricted\"\n                ):\n                    destination_dataset_title = \"Access Restricted\"\n            data_dict[destination_dataset_id] = (\n                \"produced\",\n                destination_catalog,\n                destination_dataset_title,\n            )\n\n    output_data = {\n        \"type\": [v[0] for v in data_dict.values()],\n        \"dataset_identifier\": list(data_dict.keys()),\n        \"title\": [v[2] for v in data_dict.values()],\n        \"catalog\": [v[1] for v in data_dict.values()],\n    }\n\n    lineage_df = pd.DataFrame(output_data)\n    lineage_df.loc[\n        lineage_df[\"dataset_identifier\"].isin(restricted_datasets),\n        [\"dataset_identifier\", \"catalog\", \"title\"],\n    ] = \"Access Restricted\"\n\n    if max_results &gt; -1:\n        lineage_df = lineage_df[0:max_results]\n\n    if output:\n        pass\n\n    return lineage_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_datasetmembers","title":"<code>list_datasetmembers(dataset, catalog=None, output=False, max_results=-1)</code>","text":"<p>List the available members in the dataset series.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <code>max_results</code> <code>int</code> <p>Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: a dataframe with a row for each dataset member.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_datasetmembers(\n    self,\n    dataset: str,\n    catalog: str | None = None,\n    output: bool = False,\n    max_results: int = -1,\n) -&gt; pd.DataFrame:\n    \"\"\"List the available members in the dataset series.\n\n    Args:\n        dataset (str): A dataset identifier\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n        max_results (int, optional): Limit the number of rows returned in the dataframe.\n            Defaults to -1 which returns all results.\n\n    Returns:\n        class:`pandas.DataFrame`: a dataframe with a row for each dataset member.\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries\"\n    ds_members_df = Fusion._call_for_dataframe(url, self.session)\n\n    if max_results &gt; -1:\n        ds_members_df = ds_members_df[0:max_results]\n\n    if output:\n        pass\n\n    return ds_members_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_datasetmembers_distributions","title":"<code>list_datasetmembers_distributions(dataset, catalog=None)</code>","text":"<p>List the distributions of dataset members.</p> <pre><code>    Args:\n        dataset (str): Dataset identifier.\n        catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n</code></pre> <p>F         Returns:             pd.DataFrame: A dataframe with a row for each dataset member distribution.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_datasetmembers_distributions(\n    self,\n    dataset: str,\n    catalog: str | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"List the distributions of dataset members.\n\n            Args:\n                dataset (str): Dataset identifier.\n                catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n                output (bool, optional): If True then print the dataframe. Defaults to False.\n    F\n            Returns:\n                pd.DataFrame: A dataframe with a row for each dataset member distribution.\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/changes?datasets={dataset}\"\n\n    resp = self.session.get(url)\n    dists = resp.json()[\"datasets\"][0][\"distributions\"]\n\n    data = []\n    for dist in dists:\n        values = dist.get(\"values\")\n        member_id = values[5]\n        member_format = values[6]\n        data.append((member_id, member_format))\n\n    members_df = pd.DataFrame(data, columns=[\"identifier\", \"format\"])\n    return members_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_datasets","title":"<code>list_datasets(contains=None, id_contains=False, product=None, catalog=None, output=False, max_results=-1, display_all_columns=False, status=None, dataset_type=None)</code>","text":"<p>Get the datasets contained in a catalog.</p> <p>Parameters:</p> Name Type Description Default <code>contains</code> <code>Union[str, list]</code> <p>A string or a list of strings that are dataset identifiers to filter the datasets list. If a list is provided then it will return datasets whose identifier matches any of the strings. If a single dataset identifier is provided and there is an exact match, only that dataset will be returned. Defaults to None.</p> <code>None</code> <code>id_contains</code> <code>bool</code> <p>Filter datasets only where the string(s) are contained in the identifier, ignoring description.</p> <code>False</code> <code>product</code> <code>Union[str, list]</code> <p>A string or a list of strings that are product identifiers to filter the datasets list. Defaults to None.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <code>max_results</code> <code>int</code> <p>Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results.</p> <code>-1</code> <code>display_all_columns</code> <code>bool</code> <p>If True displays all columns returned by the API, otherwise only the key columns are displayed</p> <code>False</code> <code>status</code> <code>str</code> <p>filter the datasets by status, default is to show all results.</p> <code>None</code> <code>dataset_type</code> <code>str</code> <p>filter the datasets by type, default is to show all results.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: a dataframe with a row for each dataset.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_datasets(  # noqa: PLR0912, PLR0913\n    self,\n    contains: str | list[str] | None = None,\n    id_contains: bool = False,\n    product: str | list[str] | None = None,\n    catalog: str | None = None,\n    output: bool = False,\n    max_results: int = -1,\n    display_all_columns: bool = False,\n    status: str | None = None,\n    dataset_type: str | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Get the datasets contained in a catalog.\n\n    Args:\n        contains (Union[str, list], optional): A string or a list of strings that are dataset\n            identifiers to filter the datasets list. If a list is provided then it will return\n            datasets whose identifier matches any of the strings. If a single dataset identifier is provided and\n            there is an exact match, only that dataset will be returned. Defaults to None.\n        id_contains (bool): Filter datasets only where the string(s) are contained in the identifier,\n            ignoring description.\n        product (Union[str, list], optional): A string or a list of strings that are product\n            identifiers to filter the datasets list. Defaults to None.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n        max_results (int, optional): Limit the number of rows returned in the dataframe.\n            Defaults to -1 which returns all results.\n        display_all_columns (bool, optional): If True displays all columns returned by the API,\n            otherwise only the key columns are displayed\n        status (str, optional): filter the datasets by status, default is to show all results.\n        dataset_type (str, optional): filter the datasets by type, default is to show all results.\n\n    Returns:\n        class:`pandas.DataFrame`: a dataframe with a row for each dataset.\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    # try for exact match\n    if contains and isinstance(contains, str):\n        url = f\"{self.root_url}catalogs/{catalog}/datasets/{contains}\"\n        resp = self.session.get(url)\n        status_success = 200\n        if resp.status_code == status_success:\n            resp_json = resp.json()\n            if not display_all_columns:\n                cols = [\n                    \"identifier\",\n                    \"title\",\n                    \"containerType\",\n                    \"region\",\n                    \"category\",\n                    \"coverageStartDate\",\n                    \"coverageEndDate\",\n                    \"description\",\n                    \"status\",\n                    \"type\",\n                ]\n                data = {col: resp_json.get(col, None) for col in cols}\n                return pd.DataFrame([data])\n            else:\n                return pd.json_normalize(resp_json)\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets\"\n    ds_df = Fusion._call_for_dataframe(url, self.session)\n\n    if contains:\n        if isinstance(contains, list):\n            contains = \"|\".join(f\"{s}\" for s in contains)\n        if id_contains:\n            ds_df = ds_df[ds_df[\"identifier\"].str.contains(contains, case=False)]\n        else:\n            ds_df = ds_df[\n                ds_df[\"identifier\"].str.contains(contains, case=False)\n                | ds_df[\"description\"].str.contains(contains, case=False)\n            ]\n\n    if product:\n        url = f\"{self.root_url}catalogs/{catalog}/productDatasets\"\n        prd_df = Fusion._call_for_dataframe(url, self.session)\n        prd_df = (\n            prd_df[prd_df[\"product\"] == product]\n            if isinstance(product, str)\n            else prd_df[prd_df[\"product\"].isin(product)]\n        )\n        ds_df = ds_df[ds_df[\"identifier\"].str.lower().isin(prd_df[\"dataset\"].str.lower())].reset_index(drop=True)\n\n    if max_results &gt; -1:\n        ds_df = ds_df[0:max_results]\n\n    ds_df[\"category\"] = ds_df.category.str.join(\", \")\n    ds_df[\"region\"] = ds_df.region.str.join(\", \")\n    if not display_all_columns:\n        cols = [\n            \"identifier\",\n            \"title\",\n            \"containerType\",\n            \"region\",\n            \"category\",\n            \"coverageStartDate\",\n            \"coverageEndDate\",\n            \"description\",\n            \"status\",\n            \"type\",\n        ]\n        cols = [c for c in cols if c in ds_df.columns]\n        ds_df = ds_df[cols]\n\n    if status is not None:\n        ds_df = ds_df[ds_df[\"status\"] == status]\n\n    if dataset_type is not None:\n        ds_df = ds_df[ds_df[\"type\"] == dataset_type]\n\n    if output:\n        pass\n\n    return ds_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_distributions","title":"<code>list_distributions(dataset, series, catalog=None, output=False)</code>","text":"<p>List the available distributions (downloadable instances of the dataset with a format type).</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>series</code> <code>str</code> <p>The datasetseries identifier</p> required <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each distribution.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_distributions(\n    self,\n    dataset: str,\n    series: str,\n    catalog: str | None = None,\n    output: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"List the available distributions (downloadable instances of the dataset with a format type).\n\n    Args:\n        dataset (str): A dataset identifier\n        series (str): The datasetseries identifier\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n\n    Returns:\n        class:`pandas.DataFrame`: A dataframe with a row for each distribution.\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/datasets/{dataset}/datasetseries/{series}/distributions\"\n    distros_df = Fusion._call_for_dataframe(url, self.session)\n\n    if output:\n        pass\n\n    return distros_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_indexes","title":"<code>list_indexes(knowledge_base, catalog=None, show_details=False)</code>","text":"<p>List the indexes in a knowledge base.</p> <p>Parameters:</p> Name Type Description Default <code>knowledge_base</code> <code>str</code> <p>Knowledge base (dataset) identifier.</p> required <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>show_details</code> <code>bool | None</code> <p>If True then show detailed information. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: a dataframe with a column for each index.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_indexes(\n    self,\n    knowledge_base: str,\n    catalog: str | None = None,\n    show_details: bool | None = False,\n) -&gt; pd.DataFrame:\n    \"\"\"List the indexes in a knowledge base.\n\n    Args:\n        knowledge_base (str): Knowledge base (dataset) identifier.\n        catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n        show_details (bool | None, optional): If True then show detailed information. Defaults to False.\n\n    Returns:\n        pd.DataFrame: a dataframe with a column for each index.\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n    url = f\"{self.root_url}dataspaces/{catalog}/datasets/{knowledge_base}/indexes/\"\n    response = self.session.get(url)\n    requests_raise_for_status(response)\n    if show_details:\n        return _format_full_index_response(response)\n    else:\n        return _format_summary_index_response(response)\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_product_dataset_mapping","title":"<code>list_product_dataset_mapping(dataset=None, product=None, catalog=None)</code>","text":"<p>get the product to dataset linking contained in  a catalog. A product is a grouping of datasets.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str | list[str] | None</code> <p>A string or list of strings that are dataset</p> <code>None</code> <code>product</code> <code>str | list[str] | None</code> <p>A string or list of strings that are product</p> <code>None</code> <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: a dataframe with a row  for each dataset to product mapping.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_product_dataset_mapping(\n    self,\n    dataset: str | list[str] | None = None,\n    product: str | list[str] | None = None,\n    catalog: str | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"get the product to dataset linking contained in  a catalog. A product is a grouping of datasets.\n\n    Args:\n        dataset (str | list[str] | None, optional): A string or list of strings that are dataset\n        identifiers to filter the output. If a list is provided then it will return\n        datasets whose identifier matches any of the strings. Defaults to None.\n        product (str | list[str] | None, optional): A string or list of strings that are product\n        identifiers to filter the output. If a list is provided then it will return\n        products whose identifier matches any of the strings. Defaults to None.\n        catalog (str | None, optional): A catalog identifier. Defaults to 'common'.\n\n    Returns:\n        pd.DataFrame: a dataframe with a row  for each dataset to product mapping.\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n    url = f\"{self.root_url}catalogs/{catalog}/productDatasets\"\n    mapping_df = pd.DataFrame(self._call_for_dataframe(url, self.session))\n\n    if dataset:\n        if isinstance(dataset, list):\n            contains = \"|\".join(f\"{s}\" for s in dataset)\n            mapping_df = mapping_df[mapping_df[\"dataset\"].str.contains(contains, case=False)]\n        if isinstance(dataset, str):\n            mapping_df = mapping_df[mapping_df[\"dataset\"].str.contains(dataset, case=False)]\n    if product:\n        if isinstance(product, list):\n            contains = \"|\".join(f\"{s}\" for s in product)\n            mapping_df = mapping_df[mapping_df[\"product\"].str.contains(contains, case=False)]\n        if isinstance(product, str):\n            mapping_df = mapping_df[mapping_df[\"product\"].str.contains(product, case=False)]\n    return mapping_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_products","title":"<code>list_products(contains=None, id_contains=False, catalog=None, output=False, max_results=-1, display_all_columns=False)</code>","text":"<p>Get the products contained in a catalog. A product is a grouping of datasets.</p> <p>Parameters:</p> Name Type Description Default <code>contains</code> <code>Union[str, list]</code> <p>A string or a list of strings that are product identifiers to filter the products list. If a list is provided then it will return products whose identifier matches any of the strings. Defaults to None.</p> <code>None</code> <code>id_contains</code> <code>bool</code> <p>Filter datasets only where the string(s) are contained in the identifier, ignoring description.</p> <code>False</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <code>max_results</code> <code>int</code> <p>Limit the number of rows returned in the dataframe. Defaults to -1 which returns all results.</p> <code>-1</code> <code>display_all_columns</code> <code>bool</code> <p>If True displays all columns returned by the API, otherwise only the key columns are displayed</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: a dataframe with a row for each product</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_products(\n    self,\n    contains: str | list[str] | None = None,\n    id_contains: bool = False,\n    catalog: str | None = None,\n    output: bool = False,\n    max_results: int = -1,\n    display_all_columns: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Get the products contained in a catalog. A product is a grouping of datasets.\n\n    Args:\n        contains (Union[str, list], optional): A string or a list of strings that are product\n            identifiers to filter the products list. If a list is provided then it will return\n            products whose identifier matches any of the strings. Defaults to None.\n        id_contains (bool): Filter datasets only where the string(s) are contained in the identifier,\n            ignoring description.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n        max_results (int, optional): Limit the number of rows returned in the dataframe.\n            Defaults to -1 which returns all results.\n        display_all_columns (bool, optional): If True displays all columns returned by the API,\n            otherwise only the key columns are displayed\n\n    Returns:\n        class:`pandas.DataFrame`: a dataframe with a row for each product\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/products\"\n    full_prod_df: pd.DataFrame = Fusion._call_for_dataframe(url, self.session)\n\n    if contains:\n        if isinstance(contains, list):\n            contains = \"|\".join(f\"{s}\" for s in contains)\n        if id_contains:\n            filtered_df = full_prod_df[full_prod_df[\"identifier\"].str.contains(contains, case=False)]\n        else:\n            filtered_df = full_prod_df[\n                full_prod_df[\"identifier\"].str.contains(contains, case=False)\n                | full_prod_df[\"description\"].str.contains(contains, case=False)\n            ]\n    else:\n        filtered_df = full_prod_df\n\n    filtered_df[\"category\"] = filtered_df.category.str.join(\", \")\n    filtered_df[\"region\"] = filtered_df.region.str.join(\", \")\n    if not display_all_columns:\n        filtered_df = filtered_df[\n            filtered_df.columns.intersection(\n                [\n                    \"identifier\",\n                    \"title\",\n                    \"region\",\n                    \"category\",\n                    \"status\",\n                    \"description\",\n                ]\n            )\n        ]\n\n    if max_results &gt; -1: \n        filtered_df = filtered_df[0:max_results]\n\n    if output:\n        pass\n\n    return filtered_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_registered_attributes","title":"<code>list_registered_attributes(catalog=None, output=False, display_all_columns=False)</code>","text":"<p>Returns the list of attributes in a catalog.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>output</code> <code>bool</code> <p>If True then print the dataframe. Defaults to False.</p> <code>False</code> <code>display_all_columns</code> <code>bool</code> <p>If True displays all columns returned by the API, otherwise only the key columns are displayed</p> <code>False</code> <p>Returns:</p> Name Type Description <code>class</code> <code>DataFrame</code> <p><code>pandas.DataFrame</code>: A dataframe with a row for each attribute</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_registered_attributes(\n    self,\n    catalog: str | None = None,\n    output: bool = False,\n    display_all_columns: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Returns the list of attributes in a catalog.\n\n    Args:\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        output (bool, optional): If True then print the dataframe. Defaults to False.\n        display_all_columns (bool, optional): If True displays all columns returned by the API,\n            otherwise only the key columns are displayed\n\n    Returns:\n        class:`pandas.DataFrame`: A dataframe with a row for each attribute\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    url = f\"{self.root_url}catalogs/{catalog}/attributes\"\n    ds_attr_df = Fusion._call_for_dataframe(url, self.session).reset_index(drop=True)\n\n    if not display_all_columns:\n        ds_attr_df = ds_attr_df[\n            ds_attr_df.columns.intersection(\n                [\n                    \"identifier\",\n                    \"title\",\n                    \"dataType\",\n                    \"description\",\n                    \"publisher\",\n                    \"applicationId\",\n                ]\n            )\n        ]\n\n    if output:\n        pass\n\n    return ds_attr_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_report_attributes","title":"<code>list_report_attributes(report_id, output=False, display_all_columns=False)</code>","text":"<p>Retrieve the attributes (report elements) of a specific report.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_report_attributes(\n    self,\n    report_id: str,\n    output: bool = False,\n    display_all_columns: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Retrieve the attributes (report elements) of a specific report.\"\"\"\n    url = f\"{self._get_new_root_url()}/api/corelineage-service/v1/reports/{report_id}/reportElements\"\n    resp = self.session.get(url)\n\n    if resp.status_code == HTTPStatus.OK:\n        rep_df = pd.json_normalize(resp.json())\n        if not display_all_columns:\n            key_columns = [\n                \"id\", \"path\", \"status\", \"dataType\", \"isMandatory\",\n                \"description\", \"createdBy\", \"name\"\n            ]\n            rep_df = rep_df[[c for c in key_columns if c in rep_df.columns]]\n        if output:\n            pass\n        return rep_df\n    else:\n        resp.raise_for_status()\n    return pd.DataFrame(columns=[\"id\", \"path\", \"status\", \"dataType\", \"isMandatory\", \n                                 \"description\", \"createdBy\", \"name\"])\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.list_reports","title":"<code>list_reports(report_id=None, output=False, display_all_columns=False)</code>","text":"<p>Retrieve a single report or all reports from the Fusion system.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def list_reports(\n    self,\n    report_id: str | None = None,\n    output: bool = False,\n    display_all_columns: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Retrieve a single report or all reports from the Fusion system.\"\"\"\n    key_columns = [\n        \"id\", \"name\", \"alternateId\", \"tierType\", \"frequency\",\n        \"category\", \"subCategory\", \"reportOwner\", \"lob\", \"description\"\n    ]\n\n    if report_id:\n        url = f\"{self._get_new_root_url()}/api/corelineage-service/v1/reports/{report_id}\"\n        resp = self.session.get(url)\n        if resp.status_code == HTTPStatus.OK:\n            rep_df = pd.json_normalize(resp.json())\n            if not display_all_columns:\n                rep_df = rep_df[[c for c in key_columns if c in rep_df.columns]]\n            if output:\n                pass\n            return rep_df\n        else:\n            resp.raise_for_status()\n    else:\n        url = f\"{self._get_new_root_url()}/api/corelineage-service/v1/reports/list\"\n        resp = self.session.post(url)\n        if resp.status_code == HTTPStatus.OK:\n            data = resp.json()\n            rep_df = pd.json_normalize(data.get(\"content\", data))\n            if not display_all_columns:\n                rep_df = rep_df[[c for c in key_columns if c in rep_df.columns]]\n            if output:\n                pass\n            return rep_df\n        else:\n            resp.raise_for_status()\n    return pd.DataFrame(columns=key_columns)\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.listen_to_events","title":"<code>listen_to_events(last_event_id=None, catalog=None, url=None)</code>","text":"<p>Run server sent event listener in the background. Retrieve results by running get_events.</p> <p>Parameters:</p> Name Type Description Default <code>last_event_id</code> <code>str</code> <p>Last event ID (exclusive).</p> <code>None</code> <code>catalog</code> <code>str</code> <p>catalog.</p> <code>None</code> <code>url</code> <code>str</code> <p>subscription url. Defaults to client's root url.</p> <code>None</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def listen_to_events(\n    self,\n    last_event_id: str | None = None,\n    catalog: str | None = None,\n    url: str | None = None,\n) -&gt; None:\n    \"\"\"Run server sent event listener in the background. Retrieve results by running get_events.\n\n    Args:\n        last_event_id (str): Last event ID (exclusive).\n        catalog (str): catalog.\n        url (str): subscription url. Defaults to client's root url.\n    Returns:\n        None\n    \"\"\"\n\n    catalog = self._use_catalog(catalog)\n    url = self.root_url if url is None else url\n\n    import asyncio\n    import json\n    import threading\n\n    from aiohttp_sse_client import client as sse_client\n\n    from .utils import get_client\n\n    kwargs: dict[str, Any] = {}\n    if last_event_id:\n        kwargs = {\"headers\": {\"Last-Event-ID\": last_event_id}}\n\n    async def async_events() -&gt; None:\n        \"\"\"Events sync function.\n\n        Returns:\n            None\n        \"\"\"\n        timeout = 1e100\n        session = await get_client(self.credentials, timeout=timeout)\n        async with sse_client.EventSource(\n            f\"{url}catalogs/{catalog}/notifications/subscribe\",\n            session=session,\n            **kwargs,\n        ) as messages:\n            lst = []\n            try:\n                async for msg in messages:\n                    event = json.loads(msg.data)\n                    # Preserve the original metaData column\n                    original_meta_data = event.get(\"metaData\", {})\n\n                    # Flatten the metaData dictionary into the event dictionary\n                    if isinstance(original_meta_data, dict):\n                        event.update(original_meta_data)\n                    lst.append(event)\n                    if self.events is None:\n                        self.events = pd.DataFrame()\n                    else:\n                        self.events = pd.concat([self.events, pd.DataFrame(lst)], ignore_index=True)\n                        self.events = self.events.drop_duplicates(\n                            subset=[\"id\", \"type\", \"timestamp\"], ignore_index=True\n                        )\n            except TimeoutError as ex:\n                raise ex from None\n            except BaseException:\n                raise\n\n    _ = self.catalog_resources()  # refresh token\n    if \"headers\" in kwargs:\n        kwargs[\"headers\"].update({\"authorization\": f\"bearer {self.credentials.bearer_token}\"})\n    else:\n        kwargs[\"headers\"] = {\n            \"authorization\": f\"bearer {self.credentials.bearer_token}\",\n        }\n    if \"http\" in self.credentials.proxies:\n        kwargs[\"proxy\"] = self.credentials.proxies[\"http\"]\n    elif \"https\" in self.credentials.proxies:\n        kwargs[\"proxy\"] = self.credentials.proxies[\"https\"]\n    th = threading.Thread(target=asyncio.run, args=(async_events(),), daemon=True)\n    th.start()\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.output_dataflow","title":"<code>output_dataflow(identifier, title='', category=None, description='', frequency='Once', is_internal_only_dataset=False, is_third_party_data=True, is_restricted=None, is_raw_data=True, maintainer='J.P. Morgan Fusion', source=None, region=None, publisher='J.P. Morgan', product=None, sub_category=None, tags=None, created_date=None, modified_date=None, delivery_channel='API', language='English', status='Available', type_='Flow', container_type='Snapshot-Full', snowflake=None, complexity=None, is_immutable=None, is_mnpi=None, is_pci=None, is_pii=None, is_client=None, is_public=None, is_internal=None, is_confidential=None, is_highly_confidential=None, is_active=None, owners=None, application_id=None, producer_application_id=None, consumer_application_id=None, flow_details=None, **kwargs)</code>","text":"<p>Instantiate an Output Dataflow object with this client for metadata creation.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Dataset identifier.</p> required <code>title</code> <code>str</code> <p>Dataset title. If not provided, defaults to identifier.</p> <code>''</code> <code>category</code> <code>str | list[str] | None</code> <p>A category or list of categories for the dataset.</p> <code>None</code> <code>description</code> <code>str</code> <p>Dataset description. If not provided, defaults to identifier.</p> <code>''</code> <code>frequency</code> <code>str</code> <p>The frequency of the dataset. Defaults to \"Once\".</p> <code>'Once'</code> <code>is_internal_only_dataset</code> <code>bool</code> <p>Flag for internal datasets. Defaults to False.</p> <code>False</code> <code>is_third_party_data</code> <code>bool</code> <p>Flag for third party data. Defaults to True.</p> <code>True</code> <code>is_restricted</code> <code>bool | None</code> <p>Flag for restricted datasets. Defaults to None.</p> <code>None</code> <code>is_raw_data</code> <code>bool</code> <p>Flag for raw datasets. Defaults to True.</p> <code>True</code> <code>maintainer</code> <code>str | None</code> <p>Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".</p> <code>'J.P. Morgan Fusion'</code> <code>source</code> <code>str | list[str] | None</code> <p>Name of data vendor which provided the data. Defaults to None.</p> <code>None</code> <code>region</code> <code>str | list[str] | None</code> <p>Region. Defaults to None.</p> <code>None</code> <code>publisher</code> <code>str</code> <p>Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".</p> <code>'J.P. Morgan'</code> <code>product</code> <code>str | list[str] | None</code> <p>Product to associate dataset with. Defaults to None.</p> <code>None</code> <code>sub_category</code> <code>str | list[str] | None</code> <p>Sub-category. Defaults to None.</p> <code>None</code> <code>tags</code> <code>str | list[str] | None</code> <p>Tags used for search purposes. Defaults to None.</p> <code>None</code> <code>created_date</code> <code>str | None</code> <p>Created date. Defaults to None.</p> <code>None</code> <code>modified_date</code> <code>str | None</code> <p>Modified date. Defaults to None.</p> <code>None</code> <code>delivery_channel</code> <code>str | list[str]</code> <p>Delivery channel. Defaults to \"API\".</p> <code>'API'</code> <code>language</code> <code>str</code> <p>Language. Defaults to \"English\".</p> <code>'English'</code> <code>status</code> <code>str</code> <p>Status. Defaults to \"Available\".</p> <code>'Available'</code> <code>type_</code> <code>str | None</code> <p>Dataset type. Defaults to \"Flow\".</p> <code>'Flow'</code> <code>container_type</code> <code>str | None</code> <p>Container type. Defaults to \"Snapshot-Full\".</p> <code>'Snapshot-Full'</code> <code>snowflake</code> <code>str | None</code> <p>Snowflake account connection. Defaults to None.</p> <code>None</code> <code>complexity</code> <code>str | None</code> <p>Complexity. Defaults to None.</p> <code>None</code> <code>is_immutable</code> <code>bool | None</code> <p>Flag for immutable datasets. Defaults to None.</p> <code>None</code> <code>is_mnpi</code> <code>bool | None</code> <p>is_mnpi. Defaults to None.</p> <code>None</code> <code>is_pci</code> <code>bool | None</code> <p>is_pci. Defaults to None.</p> <code>None</code> <code>is_pii</code> <code>bool | None</code> <p>is_pii. Defaults to None.</p> <code>None</code> <code>is_client</code> <code>bool | None</code> <p>is_client. Defaults to None.</p> <code>None</code> <code>is_public</code> <code>bool | None</code> <p>is_public. Defaults to None.</p> <code>None</code> <code>is_internal</code> <code>bool | None</code> <p>is_internal. Defaults to None.</p> <code>None</code> <code>is_confidential</code> <code>bool | None</code> <p>is_confidential. Defaults to None.</p> <code>None</code> <code>is_highly_confidential</code> <code>bool | None</code> <p>is_highly_confidential. Defaults to None.</p> <code>None</code> <code>is_active</code> <code>bool | None</code> <p>is_active. Defaults to None.</p> <code>None</code> <code>owners</code> <code>list[str] | None</code> <p>The owners of the dataset. Defaults to None.</p> <code>None</code> <code>application_id</code> <code>str | None</code> <p>The application ID of the dataset. Defaults to None.</p> <code>None</code> <code>producer_application_id</code> <code>dict[str, str] | None</code> <p>The producer application ID (upstream application producing the flow).</p> <code>None</code> <code>consumer_application_id</code> <code>list[dict[str, str]] | dict[str, str] | None</code> <p>The consumer application ID (downstream application, consuming the flow).</p> <code>None</code> <code>flow_details</code> <code>dict[str, str] | None</code> <p>The flow details. Specifies input versus output flow. Defaults to {\"flowDirection\": \"Output\"}.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>OutputDataFlow</code> <p>Fusion OutputDataFlow class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.output_dataflow(identifier=\"MY_DATAFLOW\")\n</code></pre> Note <p>See the dataset module for more information on functionalities of output dataflow objects.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def output_dataflow(  # noqa: PLR0913\n    self,\n    identifier: str,\n    title: str = \"\",\n    category: str | list[str] | None = None,\n    description: str = \"\",\n    frequency: str = \"Once\",\n    is_internal_only_dataset: bool = False,\n    is_third_party_data: bool = True,\n    is_restricted: bool | None = None,\n    is_raw_data: bool = True,\n    maintainer: str | None = \"J.P. Morgan Fusion\",\n    source: str | list[str] | None = None,\n    region: str | list[str] | None = None,\n    publisher: str = \"J.P. Morgan\",\n    product: str | list[str] | None = None,\n    sub_category: str | list[str] | None = None,\n    tags: str | list[str] | None = None,\n    created_date: str | None = None,\n    modified_date: str | None = None,\n    delivery_channel: str | list[str] = \"API\",\n    language: str = \"English\",\n    status: str = \"Available\",\n    type_: str | None = \"Flow\",\n    container_type: str | None = \"Snapshot-Full\",\n    snowflake: str | None = None,\n    complexity: str | None = None,\n    is_immutable: bool | None = None,\n    is_mnpi: bool | None = None,\n    is_pci: bool | None = None,\n    is_pii: bool | None = None,\n    is_client: bool | None = None,\n    is_public: bool | None = None,\n    is_internal: bool | None = None,\n    is_confidential: bool | None = None,\n    is_highly_confidential: bool | None = None,\n    is_active: bool | None = None,\n    owners: list[str] | None = None,\n    application_id: str | dict[str, str] | None = None,\n    producer_application_id: dict[str, str] | None = None,\n    consumer_application_id: list[dict[str, str]] | dict[str, str] | None = None,\n    flow_details: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; OutputDataFlow:\n    \"\"\"Instantiate an Output Dataflow object with this client for metadata creation.\n\n    Args:\n        identifier (str): Dataset identifier.\n        title (str, optional): Dataset title. If not provided, defaults to identifier.\n        category (str | list[str] | None, optional): A category or list of categories for the dataset.\n        Defaults to None.\n        description (str, optional): Dataset description. If not provided, defaults to identifier.\n        frequency (str, optional): The frequency of the dataset. Defaults to \"Once\".\n        is_internal_only_dataset (bool, optional): Flag for internal datasets. Defaults to False.\n        is_third_party_data (bool, optional): Flag for third party data. Defaults to True.\n        is_restricted (bool | None, optional): Flag for restricted datasets. Defaults to None.\n        is_raw_data (bool, optional): Flag for raw datasets. Defaults to True.\n        maintainer (str | None, optional): Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".\n        source (str | list[str] | None, optional): Name of data vendor which provided the data. Defaults to None.\n        region (str | list[str] | None, optional): Region. Defaults to None.\n        publisher (str, optional): Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".\n        product (str | list[str] | None, optional): Product to associate dataset with. Defaults to None.\n        sub_category (str | list[str] | None, optional): Sub-category. Defaults to None.\n        tags (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n        created_date (str | None, optional): Created date. Defaults to None.\n        modified_date (str | None, optional): Modified date. Defaults to None.\n        delivery_channel (str | list[str], optional): Delivery channel. Defaults to \"API\".\n        language (str, optional): Language. Defaults to \"English\".\n        status (str, optional): Status. Defaults to \"Available\".\n        type_ (str | None, optional): Dataset type. Defaults to \"Flow\".\n        container_type (str | None, optional): Container type. Defaults to \"Snapshot-Full\".\n        snowflake (str | None, optional): Snowflake account connection. Defaults to None.\n        complexity (str | None, optional): Complexity. Defaults to None.\n        is_immutable (bool | None, optional): Flag for immutable datasets. Defaults to None.\n        is_mnpi (bool | None, optional): is_mnpi. Defaults to None.\n        is_pci (bool | None, optional): is_pci. Defaults to None.\n        is_pii (bool | None, optional): is_pii. Defaults to None.\n        is_client (bool | None, optional): is_client. Defaults to None.\n        is_public (bool | None, optional): is_public. Defaults to None.\n        is_internal (bool | None, optional): is_internal. Defaults to None.\n        is_confidential (bool | None, optional): is_confidential. Defaults to None.\n        is_highly_confidential (bool | None, optional): is_highly_confidential. Defaults to None.\n        is_active (bool | None, optional): is_active. Defaults to None.\n        owners (list[str] | None, optional): The owners of the dataset. Defaults to None.\n        application_id (str | None, optional): The application ID of the dataset. Defaults to None.\n        producer_application_id (dict[str, str] | None, optional): The producer application ID (upstream application\n            producing the flow).\n        consumer_application_id (list[dict[str, str]] | dict[str, str] | None, optional): The consumer application\n            ID (downstream application, consuming the flow).\n        flow_details (dict[str, str] | None, optional): The flow details. Specifies input versus output flow.\n            Defaults to {\"flowDirection\": \"Output\"}.\n\n    Returns:\n        Dataset: Fusion OutputDataFlow class.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.output_dataflow(identifier=\"MY_DATAFLOW\")\n\n    Note:\n        See the dataset module for more information on functionalities of output dataflow objects.\n\n    \"\"\"\n    flow_details = {\"flowDirection\": \"Output\"} if flow_details is None else flow_details\n    dataflow_obj = OutputDataFlow(\n        identifier=identifier,\n        title=title,\n        category=category,\n        description=description,\n        frequency=frequency,\n        is_internal_only_dataset=is_internal_only_dataset,\n        is_third_party_data=is_third_party_data,\n        is_restricted=is_restricted,\n        is_raw_data=is_raw_data,\n        maintainer=maintainer,\n        source=source,\n        region=region,\n        publisher=publisher,\n        product=product,\n        sub_category=sub_category,\n        tags=tags,\n        created_date=created_date,\n        modified_date=modified_date,\n        delivery_channel=delivery_channel,\n        language=language,\n        status=status,\n        type_=type_,\n        container_type=container_type,\n        snowflake=snowflake,\n        complexity=complexity,\n        is_immutable=is_immutable,\n        is_mnpi=is_mnpi,\n        is_pci=is_pci,\n        is_pii=is_pii,\n        is_client=is_client,\n        is_public=is_public,\n        is_internal=is_internal,\n        is_confidential=is_confidential,\n        is_highly_confidential=is_highly_confidential,\n        is_active=is_active,\n        owners=owners,\n        application_id=application_id,\n        producer_application_id=producer_application_id,\n        consumer_application_id=consumer_application_id,\n        flow_details=flow_details,\n        **kwargs,\n    )\n    dataflow_obj.client = self\n    return dataflow_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.product","title":"<code>product(identifier, title='', category=None, short_abstract='', description='', is_active=True, is_restricted=None, maintainer=None, region='Global', publisher='J.P. Morgan', sub_category=None, tag=None, delivery_channel='API', theme=None, release_date=None, language='English', status='Available', image='', logo='', dataset=None, **kwargs)</code>","text":"<p>Instantiate a Product object with this client for metadata creation.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Product identifier.</p> required <code>title</code> <code>str</code> <p>Product title. If not provided, defaults to identifier.</p> <code>''</code> <code>category</code> <code>str | list[str] | None</code> <p>Category. Defaults to None.</p> <code>None</code> <code>short_abstract</code> <code>str</code> <p>Short description. Defaults to \"\".</p> <code>''</code> <code>description</code> <code>str</code> <p>Description. If not provided, defaults to identifier.</p> <code>''</code> <code>is_active</code> <code>bool</code> <p>Boolean for Active status. Defaults to True.</p> <code>True</code> <code>is_restricted</code> <code>bool | None</code> <p>Flag for restricted products. Defaults to None.</p> <code>None</code> <code>maintainer</code> <code>str | list[str] | None</code> <p>Product maintainer. Defaults to None.</p> <code>None</code> <code>region</code> <code>str | list[str] | None</code> <p>Product region. Defaults to None.</p> <code>'Global'</code> <code>publisher</code> <code>str | None</code> <p>Name of vendor that publishes the data. Defaults to None.</p> <code>'J.P. Morgan'</code> <code>sub_category</code> <code>str | list[str] | None</code> <p>Product sub-category. Defaults to None.</p> <code>None</code> <code>tag</code> <code>str | list[str] | None</code> <p>Tags used for search purposes. Defaults to None.</p> <code>None</code> <code>delivery_channel</code> <code>str | list[str]</code> <p>Product delivery channel. Defaults to \"API\".</p> <code>'API'</code> <code>theme</code> <code>str | None</code> <p>Product theme. Defaults to None.</p> <code>None</code> <code>release_date</code> <code>str | None</code> <p>Product release date. Defaults to None.</p> <code>None</code> <code>language</code> <code>str</code> <p>Product language. Defaults to \"English\".</p> <code>'English'</code> <code>status</code> <code>str</code> <p>Product status. Defaults to \"Available\".</p> <code>'Available'</code> <code>image</code> <code>str</code> <p>Product image. Defaults to \"\".</p> <code>''</code> <code>logo</code> <code>str</code> <p>Product logo. Defaults to \"\".</p> <code>''</code> <code>dataset</code> <code>str | list[str] | None</code> <p>Product datasets. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Product</code> <code>Product</code> <p>Fusion Product class instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.product(identifier=\"PRODUCT_1\", title=\"Product\")\n</code></pre> Note <p>See the product module for more information on functionalities of product objects.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def product(  # noqa: PLR0913\n    self,\n    identifier: str,\n    title: str = \"\",\n    category: str | list[str] | None = None,\n    short_abstract: str = \"\",\n    description: str = \"\",\n    is_active: bool = True,\n    is_restricted: bool | None = None,\n    maintainer: str | list[str] | None = None,\n    region: str | list[str] = \"Global\",\n    publisher: str = \"J.P. Morgan\",\n    sub_category: str | list[str] | None = None,\n    tag: str | list[str] | None = None,\n    delivery_channel: str | list[str] = \"API\",\n    theme: str | None = None,\n    release_date: str | None = None,\n    language: str = \"English\",\n    status: str = \"Available\",\n    image: str = \"\",\n    logo: str = \"\",\n    dataset: str | list[str] | None = None,\n    **kwargs: Any,\n) -&gt; Product:\n    \"\"\"Instantiate a Product object with this client for metadata creation.\n\n    Args:\n        identifier (str): Product identifier.\n        title (str, optional): Product title. If not provided, defaults to identifier.\n        category (str | list[str] | None, optional): Category. Defaults to None.\n        short_abstract (str, optional): Short description. Defaults to \"\".\n        description (str, optional): Description. If not provided, defaults to identifier.\n        is_active (bool, optional): Boolean for Active status. Defaults to True.\n        is_restricted (bool | None, optional): Flag for restricted products. Defaults to None.\n        maintainer (str | list[str] | None, optional): Product maintainer. Defaults to None.\n        region (str | list[str] | None, optional): Product region. Defaults to None.\n        publisher (str | None, optional): Name of vendor that publishes the data. Defaults to None.\n        sub_category (str | list[str] | None, optional): Product sub-category. Defaults to None.\n        tag (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n        delivery_channel (str | list[str], optional): Product delivery channel. Defaults to \"API\".\n        theme (str | None, optional): Product theme. Defaults to None.\n        release_date (str | None, optional): Product release date. Defaults to None.\n        language (str, optional): Product language. Defaults to \"English\".\n        status (str, optional): Product status. Defaults to \"Available\".\n        image (str, optional): Product image. Defaults to \"\".\n        logo (str, optional): Product logo. Defaults to \"\".\n        dataset (str | list[str] | None, optional): Product datasets. Defaults to None.\n\n    Returns:\n        Product: Fusion Product class instance.\n\n    Examples:\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.product(identifier=\"PRODUCT_1\", title=\"Product\")\n\n    Note:\n        See the product module for more information on functionalities of product objects.\n\n    \"\"\"\n    product_obj = Product(\n        identifier=identifier,\n        title=title,\n        category=category,\n        short_abstract=short_abstract,\n        description=description,\n        is_active=is_active,\n        is_restricted=is_restricted,\n        maintainer=maintainer,\n        region=region,\n        publisher=publisher,\n        sub_category=sub_category,\n        tag=tag,\n        delivery_channel=delivery_channel,\n        theme=theme,\n        release_date=release_date,\n        language=language,\n        status=status,\n        image=image,\n        logo=logo,\n        dataset=dataset,\n        **kwargs,\n    )\n    product_obj.client = self\n    return product_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.report","title":"<code>report(description, title, frequency, category, sub_category, data_node_id, regulatory_related, domain, tier_type=None, lob=None, alternative_id=None, sub_lob=None, is_bcbs239_program=None, risk_area=None, risk_stripe=None, sap_code=None, **kwargs)</code>","text":"<p>Instantiate a Report object with the current Fusion client attached.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>Description of the report.</p> required <code>title</code> <code>str</code> <p>Title of the report or process.</p> required <code>frequency</code> <code>str</code> <p>Reporting frequency (e.g., Monthly, Quarterly).</p> required <code>category</code> <code>str</code> <p>Main classification of the report.</p> required <code>sub_category</code> <code>str</code> <p>Sub-classification under the main category.</p> required <code>data_node_id</code> <code>dict[str, str]</code> <p>Associated data node details. Should include \"name\" and \"dataNodeType\".</p> required <code>regulatory_related</code> <code>bool</code> <p>Whether the report is regulatory-designated. This is a required field.</p> required <code>tier_type</code> <code>str</code> <p>Tier classification (e.g., \"Tier 1\", \"Non Tier 1\").</p> <code>None</code> <code>lob</code> <code>str</code> <p>Line of business.</p> <code>None</code> <code>alternative_id</code> <code>dict[str, str]</code> <p>Alternate identifiers for the report.</p> <code>None</code> <code>sub_lob</code> <code>str</code> <p>Subdivision of the line of business.</p> <code>None</code> <code>is_bcbs239_program</code> <code>bool</code> <p>Whether the report is part of the BCBS 239 program.</p> <code>None</code> <code>risk_area</code> <code>str</code> <p>Risk area covered by the report.</p> <code>None</code> <code>risk_stripe</code> <code>str</code> <p>Stripe or classification under the risk area.</p> <code>None</code> <code>sap_code</code> <code>str</code> <p>SAP financial tracking code.</p> <code>None</code> <code>domain</code> <code>dict[str, str | bool]</code> <p>Domain details. Typically contains a \"name\" key.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional optional fields such as: - tier_designation (str) - region (str) - mnpi_indicator (bool) - country_of_reporting_obligation (str) - primary_regulator (str)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Report</code> <code>Report</code> <p>A Report object ready for API upload or further manipulation.</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def report(  # noqa: PLR0913\n    self,\n    description: str,\n    title: str,\n    frequency: str,\n    category: str,\n    sub_category: str,\n    data_node_id: dict[str, str],\n    regulatory_related: bool,\n    domain: dict[str, str],\n    tier_type: str | None = None, \n    lob: str | None = None,\n    alternative_id: dict[str, str] | None = None,\n    sub_lob: str | None = None,\n    is_bcbs239_program: bool | None = None,\n    risk_area: str | None = None,\n    risk_stripe: str | None = None,\n    sap_code: str | None = None,\n    **kwargs: Any,\n) -&gt; Report:\n    \"\"\"\n    Instantiate a Report object with the current Fusion client attached.\n\n    Args:\n        description (str): Description of the report.\n        title (str): Title of the report or process.\n        frequency (str): Reporting frequency (e.g., Monthly, Quarterly).\n        category (str): Main classification of the report.\n        sub_category (str): Sub-classification under the main category.\n        data_node_id (dict[str, str]): Associated data node details. Should include \"name\" and \"dataNodeType\".\n        regulatory_related (bool): Whether the report is regulatory-designated. This is a required field.\n        tier_type (str, optional): Tier classification (e.g., \"Tier 1\", \"Non Tier 1\").\n        lob (str, optional): Line of business.\n        alternative_id (dict[str, str], optional): Alternate identifiers for the report.\n        sub_lob (str, optional): Subdivision of the line of business.\n        is_bcbs239_program (bool, optional): Whether the report is part of the BCBS 239 program.\n        risk_area (str, optional): Risk area covered by the report.\n        risk_stripe (str, optional): Stripe or classification under the risk area.\n        sap_code (str, optional): SAP financial tracking code.\n        domain (dict[str, str | bool], optional): Domain details. Typically contains a \"name\" key.\n        **kwargs (Any): Additional optional fields such as:\n            - tier_designation (str)\n            - region (str)\n            - mnpi_indicator (bool)\n            - country_of_reporting_obligation (str)\n            - primary_regulator (str)\n\n    Returns:\n        Report: A Report object ready for API upload or further manipulation.\n    \"\"\"\n    report_obj = Report(\n        title=title,\n        description=description,\n        frequency=frequency,\n        category=category,\n        sub_category=sub_category,\n        data_node_id=data_node_id,\n        regulatory_related=regulatory_related,\n        tier_type=tier_type,\n        lob=lob,\n        alternative_id=alternative_id,\n        sub_lob=sub_lob,\n        is_bcbs239_program=is_bcbs239_program,\n        risk_area=risk_area,\n        risk_stripe=risk_stripe,\n        sap_code=sap_code,\n        domain=domain,\n        **kwargs,\n    )\n    report_obj.client = self\n    return report_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.report_attribute","title":"<code>report_attribute(title, sourceIdentifier=None, description=None, technicalDataType=None, path=None)</code>","text":"<p>Instantiate a ReportAttribute object with this client for metadata creation.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>The display title of the attribute (required).</p> required <code>sourceIdentifier</code> <code>str | None</code> <p>A unique identifier or reference ID from the source system.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>A longer description of the attribute.</p> <code>None</code> <code>technicalDataType</code> <code>str | None</code> <p>The technical data type (e.g., string, int, boolean).</p> <code>None</code> <code>path</code> <code>str | None</code> <p>The hierarchical path or logical grouping for the attribute.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ReportAttribute</code> <code>ReportAttribute</code> <p>A single ReportAttribute instance with the client context attached.</p> Example <p>fusion = Fusion() attr = fusion.report_attribute( ...     title=\"Customer ID\", ...     sourceIdentifier=\"cust_id_123\", ...     description=\"Unique customer identifier\", ...     technicalDataType=\"String\", ...     path=\"Customer.Details\" ... )</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def report_attribute(\n    self,\n    title: str,\n    sourceIdentifier: str | None = None,\n    description: str | None = None,\n    technicalDataType: str | None = None,\n    path: str | None = None,\n) -&gt; ReportAttribute:\n    \"\"\"\n    Instantiate a ReportAttribute object with this client for metadata creation.\n\n    Args:\n        title (str): The display title of the attribute (required).\n        sourceIdentifier (str | None, optional): A unique identifier or reference ID from the source system.\n        description (str | None, optional): A longer description of the attribute.\n        technicalDataType (str | None, optional): The technical data type (e.g., string, int, boolean).\n        path (str | None, optional): The hierarchical path or logical grouping for the attribute.\n\n    Returns:\n        ReportAttribute: A single ReportAttribute instance with the client context attached.\n\n    Example:\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attr = fusion.report_attribute(\n        ...     title=\"Customer ID\",\n        ...     sourceIdentifier=\"cust_id_123\",\n        ...     description=\"Unique customer identifier\",\n        ...     technicalDataType=\"String\",\n        ...     path=\"Customer.Details\"\n        ... )\n    \"\"\"\n    attribute_obj = ReportAttribute(\n        sourceIdentifier=sourceIdentifier,\n        title=title,\n        description=description,\n        technicalDataType=technicalDataType,\n        path=path,\n    )\n    attribute_obj.client = self\n    return attribute_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.report_attributes","title":"<code>report_attributes(attributes=None)</code>","text":"<p>Instantiate a ReportAttributes collection with this client, allowing batch creation or manipulation.</p> <p>Parameters:</p> Name Type Description Default <code>attributes</code> <code>list[ReportAttribute] | None</code> <p>A list of ReportAttribute objects to include. Defaults to an empty list if not provided.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ReportAttributes</code> <code>ReportAttributes</code> <p>A ReportAttributes collection object with the client context attached.</p> Example <p>fusion = Fusion() attr1 = fusion.report_attribute(title=\"Code\") attr2 = fusion.report_attribute(title=\"Label\") attr_collection = fusion.report_attributes([attr1, attr2]) attr_collection.create(report_id=\"abc-123\")</p> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def report_attributes(\n    self,\n    attributes: list[ReportAttribute] | None = None,\n) -&gt; ReportAttributes:\n    \"\"\"\n    Instantiate a ReportAttributes collection with this client, allowing batch creation or manipulation.\n\n    Args:\n        attributes (list[ReportAttribute] | None, optional): A list of ReportAttribute objects to include.\n            Defaults to an empty list if not provided.\n\n    Returns:\n        ReportAttributes: A ReportAttributes collection object with the client context attached.\n\n    Example:\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attr1 = fusion.report_attribute(title=\"Code\")\n        &gt;&gt;&gt; attr2 = fusion.report_attribute(title=\"Label\")\n        &gt;&gt;&gt; attr_collection = fusion.report_attributes([attr1, attr2])\n        &gt;&gt;&gt; attr_collection.create(report_id=\"abc-123\")\n    \"\"\"\n    attributes_obj = ReportAttributes(attributes=attributes or [])\n    attributes_obj.client = self\n    return attributes_obj\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.to_bytes","title":"<code>to_bytes(dataset, series_member, dataset_format='parquet', catalog=None)</code>","text":"<p>Returns an instance of dataset (the distribution) as a bytes object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>series_member</code> <code>(str,)</code> <p>A dataset series member identifier</p> required <code>dataset_format</code> <code>str</code> <p>The file format, e.g. CSV or Parquet. Defaults to 'parquet'.</p> <code>'parquet'</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def to_bytes(\n    self,\n    dataset: str,\n    series_member: str,\n    dataset_format: str = \"parquet\",\n    catalog: str | None = None,\n) -&gt; BytesIO:\n    \"\"\"Returns an instance of dataset (the distribution) as a bytes object.\n\n    Args:\n        dataset (str): A dataset identifier\n        series_member (str,): A dataset series member identifier\n        dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n    \"\"\"\n\n    catalog = self._use_catalog(catalog)\n\n    url = distribution_to_url(\n        self.root_url,\n        dataset,\n        series_member,\n        dataset_format,\n        catalog,\n    )\n\n    return Fusion._call_for_bytes_object(url, self.session)\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.to_df","title":"<code>to_df(dataset, dt_str='latest', dataset_format='parquet', catalog=None, n_par=None, show_progress=True, columns=None, filters=None, force_download=False, download_folder=None, dataframe_type='pandas', **kwargs)</code>","text":"<p>Gets distributions for a specified date or date range and returns the data as a dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>dt_str</code> <code>str</code> <p>Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset.</p> <code>'latest'</code> <code>dataset_format</code> <code>str</code> <p>The file format, e.g. CSV or Parquet. Defaults to 'parquet'.</p> <code>'parquet'</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>n_par</code> <code>int</code> <p>Specify how many distributions to download in parallel. Defaults to all cpus available.</p> <code>None</code> <code>show_progress</code> <code>bool</code> <p>Display a progress bar during data download Defaults to True.</p> <code>True</code> <code>columns</code> <code>List</code> <p>A list of columns to return from a parquet file. Defaults to None</p> <code>None</code> <code>filters</code> <code>List</code> <p>List[Tuple] or List[List[Tuple]] or None (default) Rows which do not match the filter predicate will be removed from scanned data. Partition keys embedded in a nested directory structure will be exploited to avoid loading files at all if they contain no matching rows. If use_legacy_dataset is True, filters can only reference partition keys and only a hive-style directory structure is supported. When setting use_legacy_dataset to False, also within-file level filtering and different partitioning schemes are supported. More on https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html</p> <code>None</code> <code>force_download</code> <code>bool</code> <p>If True then will always download a file even if it is already on disk. Defaults to False.</p> <code>False</code> <code>download_folder</code> <code>str</code> <p>The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in init</p> <code>None</code> <code>dataframe_type</code> <code>str</code> <p>Type</p> <code>'pandas'</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def to_df(  # noqa: PLR0913\n    self,\n    dataset: str,\n    dt_str: str = \"latest\",\n    dataset_format: str = \"parquet\",\n    catalog: str | None = None,\n    n_par: int | None = None,\n    show_progress: bool = True,\n    columns: list[str] | None = None,\n    filters: PyArrowFilterT | None = None,\n    force_download: bool = False,\n    download_folder: str | None = None,\n    dataframe_type: str = \"pandas\",\n    **kwargs: Any,\n) -&gt; pd.DataFrame:\n    \"\"\"Gets distributions for a specified date or date range and returns the data as a dataframe.\n\n    Args:\n        dataset (str): A dataset identifier\n        dt_str (str, optional): Either a single date or a range identified by a start or end date,\n            or both separated with a \":\". Defaults to 'latest' which will return the most recent\n            instance of the dataset.\n        dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        n_par (int, optional): Specify how many distributions to download in parallel.\n            Defaults to all cpus available.\n        show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n        columns (List, optional): A list of columns to return from a parquet file. Defaults to None\n        filters (List, optional): List[Tuple] or List[List[Tuple]] or None (default)\n            Rows which do not match the filter predicate will be removed from scanned data.\n            Partition keys embedded in a nested directory structure will be exploited to avoid\n            loading files at all if they contain no matching rows. If use_legacy_dataset is True,\n            filters can only reference partition keys and only a hive-style directory structure\n            is supported. When setting use_legacy_dataset to False, also within-file level filtering\n            and different partitioning schemes are supported.\n            More on https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html\n        force_download (bool, optional): If True then will always download a file even\n            if it is already on disk. Defaults to False.\n        download_folder (str, optional): The path, absolute or relative, where downloaded files are saved.\n            Defaults to download_folder as set in __init__\n        dataframe_type (str, optional): Type\n    Returns:\n        class:`pandas.DataFrame`: a dataframe containing the requested data.\n            If multiple dataset instances are retrieved then these are concatenated first.\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    # sample data is limited to csv\n    if dt_str == \"sample\":\n        dataset_format = \"csv\"\n\n    if not download_folder:\n        download_folder = self.download_folder\n\n    download_res = self.download(\n        dataset,\n        dt_str,\n        dataset_format,\n        catalog,\n        n_par,\n        show_progress,\n        force_download,\n        download_folder,\n        return_paths=True,\n    )\n\n    if not download_res:\n        raise ValueError(\"Must specify 'return_paths=True' in download call to use this function\")\n\n    if not all(res[0] for res in download_res):\n        failed_res = [res for res in download_res if not res[0]]\n        raise Exception(\n            f\"Not all downloads were successfully completed. \"\n            f\"Re-run to collect missing files. The following failed:\\n{failed_res}\"\n        )\n\n    files = [res[1] for res in download_res]\n\n    pd_read_fn_map = {\n        \"csv\": read_csv,\n        \"parquet\": read_parquet,\n        \"parq\": read_parquet,\n        \"json\": read_json,\n        \"raw\": read_csv,\n    }\n\n    pd_read_default_kwargs: dict[str, dict[str, object]] = {\n        \"csv\": {\n            \"columns\": columns,\n            \"filters\": filters,\n            \"fs\": self.fs,\n            \"dataframe_type\": dataframe_type,\n        },\n        \"parquet\": {\n            \"columns\": columns,\n            \"filters\": filters,\n            \"fs\": self.fs,\n            \"dataframe_type\": dataframe_type,\n        },\n        \"json\": {\n            \"columns\": columns,\n            \"filters\": filters,\n            \"fs\": self.fs,\n            \"dataframe_type\": dataframe_type,\n        },\n        \"raw\": {\n            \"columns\": columns,\n            \"filters\": filters,\n            \"fs\": self.fs,\n            \"dataframe_type\": dataframe_type,\n        },\n    }\n\n    pd_read_default_kwargs[\"parq\"] = pd_read_default_kwargs[\"parquet\"]\n\n    pd_reader = pd_read_fn_map.get(dataset_format)\n    pd_read_kwargs = pd_read_default_kwargs.get(dataset_format, {})\n    if not pd_reader:\n        raise Exception(f\"No pandas function to read file in format {dataset_format}\")\n\n    pd_read_kwargs.update(kwargs)\n\n    if len(files) == 0:\n        raise APIResponseError(\n            Exception(\n                f\"No series members for dataset: {dataset} in date or date range: {dt_str} \"\n                f\"and format: {dataset_format}\"\n            ),\n            status_code=404,\n        )\n    if dataset_format in [\"parquet\", \"parq\"]:\n        data_df = pd_reader(files, **pd_read_kwargs)  # type: ignore\n    elif dataset_format == \"raw\":\n        dataframes = (\n            pd.concat(\n                [pd_reader(ZipFile(f).open(p), **pd_read_kwargs) for p in ZipFile(f).namelist()],  # type: ignore  # noqa: SIM115\n                ignore_index=True,\n            )\n            for f in files\n        )\n        data_df = pd.concat(dataframes, ignore_index=True)\n    else:\n        dataframes = (pd_reader(f, **pd_read_kwargs) for f in files)  # type: ignore\n        if dataframe_type == \"pandas\":\n            data_df = pd.concat(dataframes, ignore_index=True)\n        if dataframe_type == \"polars\":\n            import polars as pl\n\n            data_df = pl.concat(dataframes, how=\"diagonal\") # type: ignore\n\n    return data_df\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.to_table","title":"<code>to_table(dataset, dt_str='latest', dataset_format='parquet', catalog=None, n_par=None, show_progress=True, columns=None, filters=None, force_download=False, download_folder=None, **kwargs)</code>","text":"<p>Gets distributions for a specified date or date range and returns the data as an arrow table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>A dataset identifier</p> required <code>dt_str</code> <code>str</code> <p>Either a single date or a range identified by a start or end date, or both separated with a \":\". Defaults to 'latest' which will return the most recent instance of the dataset.</p> <code>'latest'</code> <code>dataset_format</code> <code>str</code> <p>The file format, e.g. CSV or Parquet. Defaults to 'parquet'.</p> <code>'parquet'</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>n_par</code> <code>int</code> <p>Specify how many distributions to download in parallel. Defaults to all cpus available.</p> <code>None</code> <code>show_progress</code> <code>bool</code> <p>Display a progress bar during data download Defaults to True.</p> <code>True</code> <code>columns</code> <code>List</code> <p>A list of columns to return from a parquet file. Defaults to None</p> <code>None</code> <code>filters</code> <code>List</code> <p>List[Tuple] or List[List[Tuple]] or None (default) Rows which do not match the filter predicate will be removed from scanned data. Partition keys embedded in a nested directory structure will be exploited to avoid loading files at all if they contain no matching rows. If use_legacy_dataset is True, filters can only reference partition keys and only a hive-style directory structure is supported. When setting use_legacy_dataset to False, also within-file level filtering and different partitioning schemes are supported. More on https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html</p> <code>None</code> <code>force_download</code> <code>bool</code> <p>If True then will always download a file even if it is already on disk. Defaults to False.</p> <code>False</code> <code>download_folder</code> <code>str</code> <p>The path, absolute or relative, where downloaded files are saved. Defaults to download_folder as set in init</p> <code>None</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def to_table(  # noqa: PLR0913\n    self,\n    dataset: str,\n    dt_str: str = \"latest\",\n    dataset_format: str = \"parquet\",\n    catalog: str | None = None,\n    n_par: int | None = None,\n    show_progress: bool = True,\n    columns: list[str] | None = None,\n    filters: PyArrowFilterT | None = None,\n    force_download: bool = False,\n    download_folder: str | None = None,\n    **kwargs: Any,\n) -&gt; pa.Table:\n    \"\"\"Gets distributions for a specified date or date range and returns the data as an arrow table.\n\n    Args:\n        dataset (str): A dataset identifier\n        dt_str (str, optional): Either a single date or a range identified by a start or end date,\n            or both separated with a \":\". Defaults to 'latest' which will return the most recent\n            instance of the dataset.\n        dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        n_par (int, optional): Specify how many distributions to download in parallel.\n            Defaults to all cpus available.\n        show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n        columns (List, optional): A list of columns to return from a parquet file. Defaults to None\n        filters (List, optional): List[Tuple] or List[List[Tuple]] or None (default)\n            Rows which do not match the filter predicate will be removed from scanned data.\n            Partition keys embedded in a nested directory structure will be exploited to avoid\n            loading files at all if they contain no matching rows. If use_legacy_dataset is True,\n            filters can only reference partition keys and only a hive-style directory structure\n            is supported. When setting use_legacy_dataset to False, also within-file level filtering\n            and different partitioning schemes are supported.\n            More on https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html\n        force_download (bool, optional): If True then will always download a file even\n            if it is already on disk. Defaults to False.\n        download_folder (str, optional): The path, absolute or relative, where downloaded files are saved.\n            Defaults to download_folder as set in __init__\n    Returns:\n        class:`pyarrow.Table`: a dataframe containing the requested data.\n            If multiple dataset instances are retrieved then these are concatenated first.\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n    n_par = cpu_count(n_par)\n    if not download_folder:\n        download_folder = self.download_folder\n    download_res = self.download(\n        dataset,\n        dt_str,\n        dataset_format,\n        catalog,\n        n_par,\n        show_progress,\n        force_download,\n        download_folder,\n        return_paths=True,\n    )\n\n    if not download_res:\n        raise ValueError(\"Must specify 'return_paths=True' in download call to use this function\")\n\n    if not all(res[0] for res in download_res):\n        failed_res = [res for res in download_res if not res[0]]\n        raise RuntimeError(\n            f\"Not all downloads were successfully completed. \"\n            f\"Re-run to collect missing files. The following failed:\\n{failed_res}\"\n        )\n\n    files = [res[1] for res in download_res]\n\n    read_fn_map = {\n        \"csv\": csv_to_table,\n        \"parquet\": parquet_to_table,\n        \"parq\": parquet_to_table,\n        \"json\": json_to_table,\n        \"raw\": csv_to_table,\n    }\n\n    read_default_kwargs: dict[str, dict[str, object]] = {\n        \"csv\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n        \"parquet\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n        \"json\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n        \"raw\": {\"columns\": columns, \"filters\": filters, \"fs\": self.fs},\n    }\n\n    read_default_kwargs[\"parq\"] = read_default_kwargs[\"parquet\"]\n\n    reader = read_fn_map.get(dataset_format)\n    read_kwargs = read_default_kwargs.get(dataset_format, {})\n    if not reader:\n        raise AssertionError(f\"No function to read file in format {dataset_format}\")\n\n    read_kwargs.update(kwargs)\n\n    if len(files) == 0:\n        raise APIResponseError(\n            Exception(\n                f\"No series members for dataset: {dataset} in date or date range: {dt_str} \"\n                f\"and format: {dataset_format}\"\n            ),\n            status_code=404,\n        )\n    if dataset_format in [\"parquet\", \"parq\"]:\n        tbl = reader(files, **read_kwargs)  # type: ignore\n    else:\n        tbl = (reader(f, **read_kwargs) for f in files)  # type: ignore\n        tbl = pa.concat_tables(tbl)\n\n    return tbl\n</code></pre>"},{"location":"api/#fusion.fusion.Fusion.upload","title":"<code>upload(path, dataset=None, dt_str='latest', catalog=None, n_par=None, show_progress=True, return_paths=False, multipart=True, chunk_size=5 * 2 ** 20, from_date=None, to_date=None, preserve_original_name=False, additional_headers=None)</code>","text":"<p>Uploads the requested files/files to Fusion.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path to a file or a folder with sub folders and files</p> required <code>dataset</code> <code>str</code> <p>Dataset identifier to which the files will be uploaded.                     If not provided the dataset will be implied from file's name.                     This is mandatory when uploading a directory.</p> <code>None</code> <code>dt_str</code> <code>str</code> <p>A file name. Can be any string but is usually a date.                     Defaults to 'latest' which will return the most recent.                     Relevant for a single file upload only. If not provided the dataset will                     be implied from file's name. dt_str will be ignored when uploading                      a directory.</p> <code>'latest'</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to 'common'.</p> <code>None</code> <code>n_par</code> <code>int</code> <p>Specify how many distributions to upload in parallel. Defaults to all cpus available.</p> <code>None</code> <code>show_progress</code> <code>bool</code> <p>Display a progress bar during data upload Defaults to True.</p> <code>True</code> <code>return_paths</code> <code>bool</code> <p>Return paths and success statuses of the uploaded files.</p> <code>False</code> <code>multipart</code> <code>bool</code> <p>Is multipart upload. Defaults to True.</p> <code>True</code> <code>chunk_size</code> <code>int</code> <p>Maximum chunk size.</p> <code>5 * 2 ** 20</code> <code>from_date</code> <code>str</code> <p>start of the data date range contained in the distribution, defaults to upoad date</p> <code>None</code> <code>to_date</code> <code>str</code> <p>end of the data date range contained in the distribution, defaults to upload date.</p> <code>None</code> <code>preserve_original_name</code> <code>bool</code> <p>Preserve the original name of the file. Defaults to False. Original name not preserved when uploading a directory.</p> <code>False</code> Source code in <code>py_src/fusion/fusion.py</code> <pre><code>def upload(  # noqa: PLR0912, PLR0913, PLR0915\n    self,\n    path: str,\n    dataset: str | None = None,\n    dt_str: str = \"latest\",\n    catalog: str | None = None,\n    n_par: int | None = None,\n    show_progress: bool = True,\n    return_paths: bool = False,\n    multipart: bool = True,\n    chunk_size: int = 5 * 2**20,\n    from_date: str | None = None,\n    to_date: str | None = None,\n    preserve_original_name: bool | None = False,\n    additional_headers: dict[str, str] | None = None,\n) -&gt; list[tuple[bool, str, str | None]] | None:\n    \"\"\"Uploads the requested files/files to Fusion.\n\n    Args:\n        path (str): path to a file or a folder with sub folders and files\n        dataset (str, optional): Dataset identifier to which the files will be uploaded.\n                                If not provided the dataset will be implied from file's name.\n                                This is mandatory when uploading a directory.\n        dt_str (str, optional): A file name. Can be any string but is usually a date.\n                                Defaults to 'latest' which will return the most recent.\n                                Relevant for a single file upload only. If not provided the dataset will\n                                be implied from file's name. dt_str will be ignored when uploading \n                                a directory.\n        catalog (str, optional): A catalog identifier. Defaults to 'common'.\n        n_par (int, optional): Specify how many distributions to upload in parallel.\n            Defaults to all cpus available.\n        show_progress (bool, optional): Display a progress bar during data upload Defaults to True.\n        return_paths (bool, optional): Return paths and success statuses of the uploaded files.\n        multipart (bool, optional): Is multipart upload. Defaults to True.\n        chunk_size (int, optional): Maximum chunk size.\n        from_date (str, optional): start of the data date range contained in the distribution,\n            defaults to upoad date\n        to_date (str, optional): end of the data date range contained in the distribution,\n            defaults to upload date.\n        preserve_original_name (bool, optional): Preserve the original name of the file. Defaults to False.\n            Original name not preserved when uploading a directory.\n\n    Returns:\n\n\n    \"\"\"\n    catalog = self._use_catalog(catalog)\n\n    if not self.fs.exists(path):\n        raise RuntimeError(\"The provided path does not exist\")\n\n    fs_fusion = self.get_fusion_filesystem()\n    if self.fs.info(path)[\"type\"] == \"directory\":\n        validate_file_formats(self.fs, path)\n        if dt_str and dt_str != \"latest\":\n            logger.warning(\"`dt_str` is not considered when uploading a directory. \"\n                            \"File names in the directory are used as series members instead.\")\n\n        file_path_lst = [f for f in self.fs.find(path) if self.fs.info(f)[\"type\"] == \"file\"]\n\n        base_path = Path(path).resolve()\n        # Construct unique file names by flattening the relative path from the base directory.\n        # For example, if the base directory is 'data_folder' and a file is at 'data_folder/sub1/file.txt',\n        # the resulting name will be 'data_folder__sub1__file.txt'.\n        # This ensures that files in different subdirectories with the same base name do not conflict\n        # and helps preserve the folder structure in the filename.  \n        file_name = [\n            base_path.name + \"__\" + \"__\".join(Path(f).resolve().relative_to(base_path).parts)\n            for f in file_path_lst\n        ]\n\n        if catalog and dataset:\n            # Construct URL mappings using the constructed file names as the series member\n            local_url_eqiv = [\n                file_name_to_url(fname, dataset, catalog, is_download=False)\n                for fname in file_name\n            ]\n        else:\n            # No catalog/dataset: validate file names and infer raw\n            local_file_validation = validate_file_names(file_path_lst)\n            file_path_lst = [f for flag, f in zip(local_file_validation, file_path_lst) if flag]\n            file_name = [f.split(\"/\")[-1] for f in file_path_lst]\n            is_raw_lst = is_dataset_raw(file_path_lst, fs_fusion)\n            local_url_eqiv = [path_to_url(i, r) for i, r in zip(file_path_lst, is_raw_lst)]\n    else:\n        file_path_lst = [path]\n        if not catalog or not dataset:\n            local_file_validation = validate_file_names(file_path_lst)\n            file_path_lst = [f for flag, f in zip(local_file_validation, file_path_lst) if flag]\n            is_raw_lst = is_dataset_raw(file_path_lst, fs_fusion)\n            local_url_eqiv = [path_to_url(i, r) for i, r in zip(file_path_lst, is_raw_lst)]\n            if preserve_original_name:\n                raise ValueError(\"preserve_original_name can only be used when catalog and dataset are provided.\")\n        else:\n            # Normalize the dt_str\n            date_identifier = re.compile(r\"^(\\d{4})(\\d{2})(\\d{2})$\")\n            if dt_str == \"latest\":\n                dt_str = pd.Timestamp(\"today\").date().strftime(\"%Y%m%d\")\n            elif date_identifier.match(dt_str):\n                dt_str = pd.Timestamp(dt_str).date().strftime(\"%Y%m%d\")\n\n            file_format = path.split(\".\")[-1]\n            file_name = [path.split(\"/\")[-1]]\n            file_format = \"raw\" if file_format not in RECOGNIZED_FORMATS else file_format\n\n            local_url_eqiv = [\n                \"/\".join(distribution_to_url(\"\", dataset, dt_str, file_format, catalog, False).split(\"/\")[1:])\n            ]\n\n    if self.fs.info(path)[\"type\"] == \"directory\" or preserve_original_name:\n        data_map_df = pd.DataFrame([file_path_lst, local_url_eqiv, file_name]).T\n        data_map_df.columns = pd.Index([\"path\", \"url\", \"file_name\"])\n    else:\n        data_map_df = pd.DataFrame([file_path_lst, local_url_eqiv]).T\n        data_map_df.columns = pd.Index([\"path\", \"url\"])\n\n    n_par = cpu_count(n_par)\n    res = upload_files(\n        fs_fusion,\n        self.fs,\n        data_map_df,\n        multipart=multipart,\n        chunk_size=chunk_size,\n        show_progress=show_progress,\n        from_date=from_date,\n        to_date=to_date,\n        additional_headers=additional_headers,\n    )\n\n    if not all(r[0] for r in res):\n        failed_res = [r for r in res if not r[0]]\n        msg = f\"Not all uploads were successfully completed. The following failed:\\n{failed_res}\"\n        logger.warning(msg)\n        warnings.warn(msg, stacklevel=2)\n\n    return res if return_paths else None\n</code></pre>"},{"location":"api/#fusion.product.Product","title":"<code>Product</code>  <code>dataclass</code>","text":"<p>Fusion Product class for managing product metadata in a Fusion catalog.</p> <p>Attributes:</p> Name Type Description <code>identifier</code> <code>str</code> <p>A unique identifier for the product.</p> <code>title</code> <code>str</code> <p>Product title. Defaults to \"\".</p> <code>category</code> <code>str | list[str] | None</code> <p>Product category. Defaults to None.</p> <code>short_abstract</code> <code>str</code> <p>Short abstract of the product. Defaults to \"\".</p> <code>description</code> <code>str</code> <p>Product description. If not provided, defaults to identifier.</p> <code>is_active</code> <code>bool</code> <p>Boolean for Active status. Defaults to True.</p> <code>is_restricted</code> <code>bool | None</code> <p>Flag for restricted products. Defaults to None.</p> <code>maintainer</code> <code>str | list[str] | None</code> <p>Product maintainer. Defaults to None.</p> <code>region</code> <code>str | list[str] | None</code> <p>Product region. Defaults to None.</p> <code>publisher</code> <code>str | None</code> <p>Name of vendor that publishes the data. Defaults to None.</p> <code>sub_category</code> <code>str | list[str] | None</code> <p>Product sub-category. Defaults to None.</p> <code>tag</code> <code>str | list[str] | None</code> <p>Tags used for search purposes. Defaults to None.</p> <code>delivery_channel</code> <code>str | list[str]</code> <p>Product delivery channel. Defaults to [\"API\"].</p> <code>theme</code> <code>str | None</code> <p>Product theme. Defaults to None.</p> <code>release_date</code> <code>str | None</code> <p>Product release date. Defaults to None.</p> <code>language</code> <code>str</code> <p>Product language. Defaults to \"English\".</p> <code>status</code> <code>str</code> <p>Product status. Defaults to \"Available\".</p> <code>image</code> <code>str</code> <p>Product image. Defaults to \"\".</p> <code>logo</code> <code>str</code> <p>Product logo. Defaults to \"\".</p> <code>dataset</code> <code>str | list[str] | None</code> <p>Product datasets. Defaults to None.</p> <code>_client</code> <code>Any</code> <p>Fusion client object. Defaults to None.</p> Source code in <code>py_src/fusion/product.py</code> <pre><code>@dataclass\nclass Product(metaclass=CamelCaseMeta):\n    \"\"\"Fusion Product class for managing product metadata in a Fusion catalog.\n\n    Attributes:\n        identifier (str): A unique identifier for the product.\n        title (str, optional): Product title. Defaults to \"\".\n        category (str | list[str] | None, optional): Product category. Defaults to None.\n        short_abstract (str, optional): Short abstract of the product. Defaults to \"\".\n        description (str, optional): Product description. If not provided, defaults to identifier.\n        is_active (bool, optional): Boolean for Active status. Defaults to True.\n        is_restricted (bool | None, optional): Flag for restricted products. Defaults to None.\n        maintainer (str | list[str] | None, optional): Product maintainer. Defaults to None.\n        region (str | list[str] | None, optional): Product region. Defaults to None.\n        publisher (str | None, optional): Name of vendor that publishes the data. Defaults to None.\n        sub_category (str | list[str] | None, optional): Product sub-category. Defaults to None.\n        tag (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n        delivery_channel (str | list[str], optional): Product delivery channel. Defaults to [\"API\"].\n        theme (str | None, optional): Product theme. Defaults to None.\n        release_date (str | None, optional): Product release date. Defaults to None.\n        language (str, optional): Product language. Defaults to \"English\".\n        status (str, optional): Product status. Defaults to \"Available\".\n        image (str, optional): Product image. Defaults to \"\".\n        logo (str, optional): Product logo. Defaults to \"\".\n        dataset (str | list[str] | None, optional): Product datasets. Defaults to None.\n        _client (Any, optional): Fusion client object. Defaults to None.\n\n    \"\"\"\n\n    identifier: str\n    title: str = \"\"\n    category: str | list[str] | None = None\n    short_abstract: str = \"\"\n    description: str = \"\"\n    is_active: bool = True\n    is_restricted: bool | None = None\n    maintainer: str | list[str] | None = None\n    region: str | list[str] = field(default_factory=lambda: [\"Global\"])\n    publisher: str = \"J.P. Morgan\"\n    sub_category: str | list[str] | None = None\n    tag: str | list[str] | None = None\n    delivery_channel: str | list[str] = field(default_factory=lambda: [\"API\"])\n    theme: str | None = None\n    release_date: str | None = None\n    language: str = \"English\"\n    status: str = \"Available\"\n    image: str = \"\"\n    logo: str = \"\"\n    dataset: str | list[str] | None = None\n\n    _client: Fusion | None = field(init=False, repr=False, compare=False, default=None)\n\n    def __repr__(self: Product) -&gt; str:\n        \"\"\"Return an object representation of the Product object.\n\n        Returns:\n            str: Object representaiton of the product.\n\n        \"\"\"\n        attrs = {k: v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n        return f\"Product(\\n\" + \",\\n \".join(f\"{k}={v!r}\" for k, v in attrs.items()) + \"\\n)\"\n\n    def __post_init__(self: Product) -&gt; None:\n        \"\"\"Format Product metadata fields after object instantiation.\"\"\"\n        self.identifier = tidy_string(self.identifier).upper().replace(\" \", \"_\")\n        self.title = tidy_string(self.title) if self.title != \"\" else self.identifier.replace(\"_\", \" \").title()\n        self.description = tidy_string(self.description) if self.description != \"\" else self.title\n        self.short_abstract = tidy_string(self.short_abstract) if self.short_abstract != \"\" else self.title\n        self.description = tidy_string(self.description)\n        self.category = (\n            self.category if isinstance(self.category, list) or self.category is None else make_list(self.category)\n        )\n        self.tag = self.tag if isinstance(self.tag, list) or self.tag is None else make_list(self.tag)\n        self.dataset = (\n            self.dataset if isinstance(self.dataset, list) or self.dataset is None else make_list(self.dataset)\n        )\n        self.sub_category = (\n            self.sub_category\n            if isinstance(self.sub_category, list) or self.sub_category is None\n            else make_list(self.sub_category)\n        )\n        self.is_active = self.is_active if isinstance(self.is_active, bool) else make_bool(self.is_active)\n        self.is_restricted = (\n            self.is_restricted\n            if isinstance(self.is_restricted, bool) or self.is_restricted is None\n            else make_bool(self.is_restricted)\n        )\n        self.maintainer = (\n            self.maintainer\n            if isinstance(self.maintainer, list) or self.maintainer is None\n            else make_list(self.maintainer)\n        )\n        self.region = self.region if isinstance(self.region, list) or self.region is None else make_list(self.region)\n        self.delivery_channel = (\n            self.delivery_channel if isinstance(self.delivery_channel, list) else make_list(self.delivery_channel)\n        )\n        self.release_date = convert_date_format(self.release_date) if self.release_date else None\n\n    def __getattr__(self, name: str) -&gt; Any:\n        # Redirect attribute access to the snake_case version\n        snake_name = camel_to_snake(name)\n        if snake_name in self.__dict__:\n            return self.__dict__[snake_name]\n        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        if name == \"client\":\n            # Use the property setter for client\n            object.__setattr__(self, name, value)\n        else:\n            snake_name = camel_to_snake(name)\n            self.__dict__[snake_name] = value\n\n    @property\n    def client(self) -&gt; Fusion | None:\n        \"\"\"Return the client.\"\"\"\n        return self._client\n\n    @client.setter\n    def client(self, client: Fusion | None) -&gt; None:\n        \"\"\"Set the client for the Product. Set automatically, if the Product is instantiated from a Fusion object.\n\n        Args:\n            client (Any): Fusion client object.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\"my_product\")\n            &gt;&gt;&gt; product.client = fusion\n\n        \"\"\"\n        self._client = client\n\n    def _use_client(self, client: Fusion | None) -&gt; Fusion:\n        \"\"\"Determine client.\"\"\"\n\n        res = self._client if client is None else client\n        if res is None:\n            raise ValueError(\"A Fusion client object is required.\")\n        return res\n\n    @classmethod\n    def _from_series(cls: type[Product], series: pd.Series[Any]) -&gt; Product:\n        \"\"\"Instantiate a Product object from a pandas Series.\n\n        Args:\n            series (pd.Series[Any]): Product metadata as a pandas Series.\n\n        Returns:\n            Product: Product object.\n\n        \"\"\"\n        series = series.rename(lambda x: x.replace(\" \", \"\").replace(\"_\", \"\").lower())\n        series = series.rename({\"tag\": \"tags\", \"dataset\": \"datasets\"})\n        short_abstract = series.get(\"abstract\", \"\")\n        short_abstract = series.get(\"shortabstract\", \"\") if short_abstract is None else short_abstract\n\n        return cls(\n            title=series.get(\"title\", \"\"),\n            identifier=series.get(\"identifier\", \"\"),\n            category=series.get(\"category\", None),\n            short_abstract=short_abstract,\n            description=series.get(\"description\", \"\"),\n            theme=series.get(\"theme\", None),\n            release_date=series.get(\"releasedate\", None),\n            is_active=series.get(\"isactive\", True),\n            is_restricted=series.get(\"isrestricted\", None),\n            maintainer=series.get(\"maintainer\", None),\n            region=series.get(\"region\", \"Global\"),\n            publisher=series.get(\"publisher\", \"J.P. Morgan\"),\n            sub_category=series.get(\"subcategory\", None),\n            tag=series.get(\"tags\", None),\n            delivery_channel=series.get(\"deliverychannel\", \"API\"),\n            language=series.get(\"language\", \"English\"),\n            status=series.get(\"status\", \"Available\"),\n            dataset=series.get(\"datasets\", None),\n        )\n\n    @classmethod\n    def _from_dict(cls: type[Product], data: dict[str, Any]) -&gt; Product:\n        \"\"\"Instantiate a Product object from a dictionary.\n\n        Args:\n            data (dict[str, Any]): Product metadata as a dictionary.\n\n        Returns:\n            Product: Product object.\n\n        \"\"\"\n        keys = [f.name for f in fields(cls)]\n        data = {camel_to_snake(k): v for k, v in data.items()}\n        data = {k: v for k, v in data.items() if k in keys}\n        return cls(**data)\n\n    @classmethod\n    def _from_csv(cls: type[Product], file_path: str, identifier: str | None = None) -&gt; Product:\n        \"\"\"Instantiate a Product object from a CSV file.\n\n        Args:\n            file_path (str): Path to the CSV file.\n            identifier (str | None, optional): Product identifer for filtering if multipler products are defined in csv.\n                Defaults to None.\n\n        Returns:\n            Product: Product object.\n\n        \"\"\"\n        data = pd.read_csv(file_path)\n\n        return (\n            Product._from_series(data[data[\"identifier\"] == identifier].reset_index(drop=True).iloc[0])\n            if identifier\n            else Product._from_series(data.reset_index(drop=True).iloc[0])\n        )\n\n    def from_object(\n        self,\n        product_source: Product | dict[str, Any] | str | pd.Series[Any],\n    ) -&gt; Product:\n        \"\"\"Instantiate a Product object from a Product object, dictionary, path to CSV, JSON string, or pandas Series.\n\n        Args:\n            product_source (Product | dict[str, Any] | str | pd.Series[Any]): Product metadata source.\n\n        Raises:\n            TypeError: If the object provided is not a Product, dictionary, path to CSV file, JSON string,\n            or pandas Series.\n\n        Returns:\n            Product: Product object.\n\n        Examples:\n            Instantiating a Product object from a dictionary:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; from fusion.product import Product\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product_dict = {\n            ...     \"identifier\": \"my_product\",\n            ...     \"title\": \"My Product\",\n            ...     \"category\": \"Data\",\n            ...     \"short_abstract\": \"My product is awesome\",\n            ...     \"description\": \"My product is very awesome\",\n            ...     \"is_active\": True,\n            ...     \"is_restricted\": False,\n            ...     \"maintainer\": \"My Company\",\n            ...     \"region\": \"Global\",\n            ...     \"publisher\": \"My Company\",\n            ...     \"sub_category\": \"Data\",\n            ...     \"tag\": \"My Company\",\n            ...     \"delivery_channel\": \"API\",\n            ...     \"theme\": \"Data\",\n            ...     \"release_date\": \"2021-01-01\",\n            ...     \"language\": \"English\",\n            ...     \"status\": \"Available\"\n            ... }\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_dict)\n\n            Instantiating a Product object from a JSON string:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; from fusion.product import Product\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product_json = '{\n            ...     \"identifier\": \"my_product\",\n            ...     \"title\": \"My Product\",\n            ...     \"category\": \"Data\",\n            ...     \"short_abstract\": \"My product is awesome\",\n            ...     \"description\": \"My product is very awesome\",\n            ...     \"is_active\": True,\n            ...     \"is_restricted\": False,\n            ...     \"maintainer\": \"My Company\",\n            ...     \"region\": \"Global\",\n            ...     \"publisher\": \"My Company\",\n            ...     \"sub_category\": \"Data\",\n            ...     \"tag\": \"My Company\",\n            ...     \"delivery_channel\": \"API\",\n            ...     \"theme\": \"Data\",\n            ...     \"release_date\": \"2021-01-01\",\n            ...     \"language\": \"English\",\n            ...     \"status\": \"Available\",\n            ... }'\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_json)\n\n            Instantiating a Product object from a CSV file:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; from fusion.product import Product\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(\"path/to/product.csv\")\n\n            Instantiating a Product object from a pandas Series:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; from fusion.product import Product\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product_series = pd.Series({\n            ...     \"identifier\": \"my_product\",\n            ...     \"title\": \"My Product\",\n            ...     \"category\": \"Data\",\n            ...     \"short_abstract\": \"My product is awesome\",\n            ...     \"description\": \"My product is very awesome\",\n            ...     \"is_active\": True,\n            ...     \"is_restricted\": False,\n            ...     \"maintainer\": \"My Company\",\n            ...     \"region\": \"Global\",\n            ...     \"publisher\": \"My Company\",\n            ...     \"sub_category\": \"Data\",\n            ...     \"tag\": \"My Company\",\n            ...     \"delivery_channel\": \"API\",\n            ...     \"theme\": \"Data\",\n            ...     \"release_date\": \"2021-01-01\",\n            ...     \"language\": \"English\",\n            ...     \"status\": \"Available\",\n            ... })\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_series)\n\n        \"\"\"\n        if isinstance(product_source, Product):\n            product = product_source\n        elif isinstance(product_source, dict):\n            product = Product._from_dict(product_source)\n        elif isinstance(product_source, str):\n            if _is_json(product_source):\n                product = Product._from_dict(js.loads(product_source))\n            else:\n                product = Product._from_csv(product_source)\n        elif isinstance(product_source, pd.Series):\n            product = Product._from_series(product_source)\n        else:\n            raise TypeError(f\"Could not resolve the object provided: {product_source}\")\n        product.client = self._client\n        return product\n\n    def from_catalog(self, catalog: str | None = None, client: Fusion | None = None) -&gt; Product:\n        \"\"\"Instantiate a Product object from a Fusion catalog.\n\n        Args:\n            catalog (str | None, optional): Catalog identifer. Defaults to None.\n            client (Fusion | None, optional): Fusion session. Defaults to None.\n                If instantiated from a Fusion object, then the client is set automatically.\n\n        Returns:\n            Product: Product object.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        resp = client.session.get(f\"{client.root_url}catalogs/{catalog}/products\")\n        requests_raise_for_status(resp)\n        list_products = resp.json()[\"resources\"]\n        dict_ = [dict_ for dict_ in list_products if dict_[\"identifier\"] == self.identifier][0]\n        product_obj = Product._from_dict(dict_)\n        product_obj.client = client\n\n        return product_obj\n\n    def to_dict(self: Product) -&gt; dict[str, Any]:\n        \"\"\"Convert the Product instance to a dictionary.\n\n        Returns:\n            dict[str, Any]: Product metadata as a dictionary.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\"my_product\")\n            &gt;&gt;&gt; product_dict = product.to_dict()\n\n        \"\"\"\n        product_dict = {snake_to_camel(k): v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n        return product_dict\n\n    def create(\n        self,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Upload a new product to a Fusion catalog.\n\n        Args:\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            From scratch:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\n            ...     identifer=\"my_product\"\n            ...     title=\"My Product\",\n            ...     category=\"Data\",\n            ...     short_abstract=\"My product is awesome\",\n            ...     description=\"My product is very awesome\",\n            ...     )\n            &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n            From a dictionary:\n\n            &gt;&gt;&gt; product_dict = {\n            ...     \"identifier\": \"my_product\",\n            ...     \"title\": \"My Product\",\n            ...     \"category\": \"Data\"\n            ...     }\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_dict)\n            &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n            From a JSON string:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product_json = '{\n            ...     \"identifier\": \"my_product\",\n            ...     \"title\": \"My Product\",\n            ...     \"category\": \"Data\"\n            ...     }'\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_json)\n            &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n            From a CSV file:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(\"path/to/product.csv\")\n            &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n            From a pandas Series:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product_series = pd.Series({\n            ...     \"identifier\": \"my_product\",\n            ...     \"title\": \"My Product\",\n            ...     \"category\": \"Data\"\n            ...     })\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_series)\n            &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n            From existing product in a catalog:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog()\n            &gt;&gt;&gt; product.identifier = \"my_new_product\"\n            &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        release_date = self.release_date if self.release_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n        delivery_channel = self.delivery_channel if self.delivery_channel else [\"API\"]\n\n        self.release_date = release_date\n        self.delivery_channel = delivery_channel\n\n        data = self.to_dict()\n\n        url = f\"{client.root_url}catalogs/{catalog}/products/{self.identifier}\"\n        resp: requests.Response = client.session.post(url, json=data)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def update(\n        self,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Update an existing product in a Fusion catalog.\n\n        Args:\n            client (Fusion): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog(catalog=\"my_catalog\")\n            &gt;&gt;&gt; product.title = \"My Updated Product Title\"\n            &gt;&gt;&gt; product.update(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        release_date = self.release_date if self.release_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n        delivery_channel = self.delivery_channel if self.delivery_channel else [\"API\"]\n\n        self.release_date = release_date\n        self.delivery_channel = delivery_channel\n\n        data = self.to_dict()\n\n        url = f\"{client.root_url}catalogs/{catalog}/products/{self.identifier}\"\n        resp: requests.Response = client.session.put(url, json=data)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def delete(\n        self,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Delete a product from a Fusion catalog.\n\n        Args:\n            client (Fusion): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n         Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.product(\"my_product\").delete(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        url = f\"{client.root_url}catalogs/{catalog}/products/{self.identifier}\"\n        resp: requests.Response = client.session.delete(url)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def copy(\n        self,\n        catalog_to: str,\n        catalog_from: str | None = None,\n        client: Fusion | None = None,\n        client_to: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Copy product from one Fusion catalog and/or environment to another by copy.\n\n        Args:\n            catalog_to (str): Catalog identifier to which to copy product.\n            catalog_from (str, optional): A catalog identifier from which to copy product. Defaults to \"common\".\n            client (Fusion): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            client_to (Fusion | None, optional): Fusion client object. Defaults to current instance.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.product(\"my_product\").copy(catalog_from=\"my_catalog\", catalog_to=\"my_new_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog_from = client._use_catalog(catalog_from)\n        if client_to is None:\n            client_to = client\n        product_obj = self.from_catalog(catalog=catalog_from, client=client)\n        product_obj.client = client_to\n        resp = product_obj.create(catalog=catalog_to, return_resp_obj=True)\n        return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.product.Product.client","title":"<code>client</code>  <code>property</code> <code>writable</code>","text":"<p>Return the client.</p>"},{"location":"api/#fusion.product.Product.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Format Product metadata fields after object instantiation.</p> Source code in <code>py_src/fusion/product.py</code> <pre><code>def __post_init__(self: Product) -&gt; None:\n    \"\"\"Format Product metadata fields after object instantiation.\"\"\"\n    self.identifier = tidy_string(self.identifier).upper().replace(\" \", \"_\")\n    self.title = tidy_string(self.title) if self.title != \"\" else self.identifier.replace(\"_\", \" \").title()\n    self.description = tidy_string(self.description) if self.description != \"\" else self.title\n    self.short_abstract = tidy_string(self.short_abstract) if self.short_abstract != \"\" else self.title\n    self.description = tidy_string(self.description)\n    self.category = (\n        self.category if isinstance(self.category, list) or self.category is None else make_list(self.category)\n    )\n    self.tag = self.tag if isinstance(self.tag, list) or self.tag is None else make_list(self.tag)\n    self.dataset = (\n        self.dataset if isinstance(self.dataset, list) or self.dataset is None else make_list(self.dataset)\n    )\n    self.sub_category = (\n        self.sub_category\n        if isinstance(self.sub_category, list) or self.sub_category is None\n        else make_list(self.sub_category)\n    )\n    self.is_active = self.is_active if isinstance(self.is_active, bool) else make_bool(self.is_active)\n    self.is_restricted = (\n        self.is_restricted\n        if isinstance(self.is_restricted, bool) or self.is_restricted is None\n        else make_bool(self.is_restricted)\n    )\n    self.maintainer = (\n        self.maintainer\n        if isinstance(self.maintainer, list) or self.maintainer is None\n        else make_list(self.maintainer)\n    )\n    self.region = self.region if isinstance(self.region, list) or self.region is None else make_list(self.region)\n    self.delivery_channel = (\n        self.delivery_channel if isinstance(self.delivery_channel, list) else make_list(self.delivery_channel)\n    )\n    self.release_date = convert_date_format(self.release_date) if self.release_date else None\n</code></pre>"},{"location":"api/#fusion.product.Product.__repr__","title":"<code>__repr__()</code>","text":"<p>Return an object representation of the Product object.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Object representaiton of the product.</p> Source code in <code>py_src/fusion/product.py</code> <pre><code>def __repr__(self: Product) -&gt; str:\n    \"\"\"Return an object representation of the Product object.\n\n    Returns:\n        str: Object representaiton of the product.\n\n    \"\"\"\n    attrs = {k: v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n    return f\"Product(\\n\" + \",\\n \".join(f\"{k}={v!r}\" for k, v in attrs.items()) + \"\\n)\"\n</code></pre>"},{"location":"api/#fusion.product.Product.copy","title":"<code>copy(catalog_to, catalog_from=None, client=None, client_to=None, return_resp_obj=False)</code>","text":"<p>Copy product from one Fusion catalog and/or environment to another by copy.</p> <p>Parameters:</p> Name Type Description Default <code>catalog_to</code> <code>str</code> <p>Catalog identifier to which to copy product.</p> required <code>catalog_from</code> <code>str</code> <p>A catalog identifier from which to copy product. Defaults to \"common\".</p> <code>None</code> <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>client_to</code> <code>Fusion | None</code> <p>Fusion client object. Defaults to current instance.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.product(\"my_product\").copy(catalog_from=\"my_catalog\", catalog_to=\"my_new_catalog\")\n</code></pre> Source code in <code>py_src/fusion/product.py</code> <pre><code>def copy(\n    self,\n    catalog_to: str,\n    catalog_from: str | None = None,\n    client: Fusion | None = None,\n    client_to: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Copy product from one Fusion catalog and/or environment to another by copy.\n\n    Args:\n        catalog_to (str): Catalog identifier to which to copy product.\n        catalog_from (str, optional): A catalog identifier from which to copy product. Defaults to \"common\".\n        client (Fusion): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        client_to (Fusion | None, optional): Fusion client object. Defaults to current instance.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.product(\"my_product\").copy(catalog_from=\"my_catalog\", catalog_to=\"my_new_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog_from = client._use_catalog(catalog_from)\n    if client_to is None:\n        client_to = client\n    product_obj = self.from_catalog(catalog=catalog_from, client=client)\n    product_obj.client = client_to\n    resp = product_obj.create(catalog=catalog_to, return_resp_obj=True)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.product.Product.create","title":"<code>create(catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Upload a new product to a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>From scratch:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product = fusion.product(\n...     identifer=\"my_product\"\n...     title=\"My Product\",\n...     category=\"Data\",\n...     short_abstract=\"My product is awesome\",\n...     description=\"My product is very awesome\",\n...     )\n&gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\nFrom a dictionary:\n\n&gt;&gt;&gt; product_dict = {\n...     \"identifier\": \"my_product\",\n...     \"title\": \"My Product\",\n...     \"category\": \"Data\"\n...     }\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_dict)\n&gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\nFrom a JSON string:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product_json = '{\n...     \"identifier\": \"my_product\",\n...     \"title\": \"My Product\",\n...     \"category\": \"Data\"\n...     }'\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_json)\n&gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\nFrom a CSV file:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(\"path/to/product.csv\")\n&gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\nFrom a pandas Series:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product_series = pd.Series({\n...     \"identifier\": \"my_product\",\n...     \"title\": \"My Product\",\n...     \"category\": \"Data\"\n...     })\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_series)\n&gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\nFrom existing product in a catalog:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog()\n&gt;&gt;&gt; product.identifier = \"my_new_product\"\n&gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/product.py</code> <pre><code>def create(\n    self,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Upload a new product to a Fusion catalog.\n\n    Args:\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        From scratch:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product = fusion.product(\n        ...     identifer=\"my_product\"\n        ...     title=\"My Product\",\n        ...     category=\"Data\",\n        ...     short_abstract=\"My product is awesome\",\n        ...     description=\"My product is very awesome\",\n        ...     )\n        &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n        From a dictionary:\n\n        &gt;&gt;&gt; product_dict = {\n        ...     \"identifier\": \"my_product\",\n        ...     \"title\": \"My Product\",\n        ...     \"category\": \"Data\"\n        ...     }\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_dict)\n        &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n        From a JSON string:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product_json = '{\n        ...     \"identifier\": \"my_product\",\n        ...     \"title\": \"My Product\",\n        ...     \"category\": \"Data\"\n        ...     }'\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_json)\n        &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n        From a CSV file:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(\"path/to/product.csv\")\n        &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n        From a pandas Series:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product_series = pd.Series({\n        ...     \"identifier\": \"my_product\",\n        ...     \"title\": \"My Product\",\n        ...     \"category\": \"Data\"\n        ...     })\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_series)\n        &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n        From existing product in a catalog:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog()\n        &gt;&gt;&gt; product.identifier = \"my_new_product\"\n        &gt;&gt;&gt; product.create(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    release_date = self.release_date if self.release_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n    delivery_channel = self.delivery_channel if self.delivery_channel else [\"API\"]\n\n    self.release_date = release_date\n    self.delivery_channel = delivery_channel\n\n    data = self.to_dict()\n\n    url = f\"{client.root_url}catalogs/{catalog}/products/{self.identifier}\"\n    resp: requests.Response = client.session.post(url, json=data)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.product.Product.delete","title":"<code>delete(catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Delete a product from a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.product(\"my_product\").delete(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/product.py</code> <pre><code>def delete(\n    self,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Delete a product from a Fusion catalog.\n\n    Args:\n        client (Fusion): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n     Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.product(\"my_product\").delete(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    url = f\"{client.root_url}catalogs/{catalog}/products/{self.identifier}\"\n    resp: requests.Response = client.session.delete(url)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.product.Product.from_catalog","title":"<code>from_catalog(catalog=None, client=None)</code>","text":"<p>Instantiate a Product object from a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str | None</code> <p>Catalog identifer. Defaults to None.</p> <code>None</code> <code>client</code> <code>Fusion | None</code> <p>Fusion session. Defaults to None. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Product</code> <code>Product</code> <p>Product object.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/product.py</code> <pre><code>def from_catalog(self, catalog: str | None = None, client: Fusion | None = None) -&gt; Product:\n    \"\"\"Instantiate a Product object from a Fusion catalog.\n\n    Args:\n        catalog (str | None, optional): Catalog identifer. Defaults to None.\n        client (Fusion | None, optional): Fusion session. Defaults to None.\n            If instantiated from a Fusion object, then the client is set automatically.\n\n    Returns:\n        Product: Product object.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    resp = client.session.get(f\"{client.root_url}catalogs/{catalog}/products\")\n    requests_raise_for_status(resp)\n    list_products = resp.json()[\"resources\"]\n    dict_ = [dict_ for dict_ in list_products if dict_[\"identifier\"] == self.identifier][0]\n    product_obj = Product._from_dict(dict_)\n    product_obj.client = client\n\n    return product_obj\n</code></pre>"},{"location":"api/#fusion.product.Product.from_object","title":"<code>from_object(product_source)</code>","text":"<p>Instantiate a Product object from a Product object, dictionary, path to CSV, JSON string, or pandas Series.</p> <p>Parameters:</p> Name Type Description Default <code>product_source</code> <code>Product | dict[str, Any] | str | Series[Any]</code> <p>Product metadata source.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object provided is not a Product, dictionary, path to CSV file, JSON string,</p> <p>Returns:</p> Name Type Description <code>Product</code> <code>Product</code> <p>Product object.</p> <p>Examples:</p> <p>Instantiating a Product object from a dictionary:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; from fusion.product import Product\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product_dict = {\n...     \"identifier\": \"my_product\",\n...     \"title\": \"My Product\",\n...     \"category\": \"Data\",\n...     \"short_abstract\": \"My product is awesome\",\n...     \"description\": \"My product is very awesome\",\n...     \"is_active\": True,\n...     \"is_restricted\": False,\n...     \"maintainer\": \"My Company\",\n...     \"region\": \"Global\",\n...     \"publisher\": \"My Company\",\n...     \"sub_category\": \"Data\",\n...     \"tag\": \"My Company\",\n...     \"delivery_channel\": \"API\",\n...     \"theme\": \"Data\",\n...     \"release_date\": \"2021-01-01\",\n...     \"language\": \"English\",\n...     \"status\": \"Available\"\n... }\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_dict)\n</code></pre> <p>Instantiating a Product object from a JSON string:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; from fusion.product import Product\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product_json = '{\n...     \"identifier\": \"my_product\",\n...     \"title\": \"My Product\",\n...     \"category\": \"Data\",\n...     \"short_abstract\": \"My product is awesome\",\n...     \"description\": \"My product is very awesome\",\n...     \"is_active\": True,\n...     \"is_restricted\": False,\n...     \"maintainer\": \"My Company\",\n...     \"region\": \"Global\",\n...     \"publisher\": \"My Company\",\n...     \"sub_category\": \"Data\",\n...     \"tag\": \"My Company\",\n...     \"delivery_channel\": \"API\",\n...     \"theme\": \"Data\",\n...     \"release_date\": \"2021-01-01\",\n...     \"language\": \"English\",\n...     \"status\": \"Available\",\n... }'\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_json)\n</code></pre> <p>Instantiating a Product object from a CSV file:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; from fusion.product import Product\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(\"path/to/product.csv\")\n</code></pre> <p>Instantiating a Product object from a pandas Series:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; from fusion.product import Product\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product_series = pd.Series({\n...     \"identifier\": \"my_product\",\n...     \"title\": \"My Product\",\n...     \"category\": \"Data\",\n...     \"short_abstract\": \"My product is awesome\",\n...     \"description\": \"My product is very awesome\",\n...     \"is_active\": True,\n...     \"is_restricted\": False,\n...     \"maintainer\": \"My Company\",\n...     \"region\": \"Global\",\n...     \"publisher\": \"My Company\",\n...     \"sub_category\": \"Data\",\n...     \"tag\": \"My Company\",\n...     \"delivery_channel\": \"API\",\n...     \"theme\": \"Data\",\n...     \"release_date\": \"2021-01-01\",\n...     \"language\": \"English\",\n...     \"status\": \"Available\",\n... })\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_series)\n</code></pre> Source code in <code>py_src/fusion/product.py</code> <pre><code>def from_object(\n    self,\n    product_source: Product | dict[str, Any] | str | pd.Series[Any],\n) -&gt; Product:\n    \"\"\"Instantiate a Product object from a Product object, dictionary, path to CSV, JSON string, or pandas Series.\n\n    Args:\n        product_source (Product | dict[str, Any] | str | pd.Series[Any]): Product metadata source.\n\n    Raises:\n        TypeError: If the object provided is not a Product, dictionary, path to CSV file, JSON string,\n        or pandas Series.\n\n    Returns:\n        Product: Product object.\n\n    Examples:\n        Instantiating a Product object from a dictionary:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; from fusion.product import Product\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product_dict = {\n        ...     \"identifier\": \"my_product\",\n        ...     \"title\": \"My Product\",\n        ...     \"category\": \"Data\",\n        ...     \"short_abstract\": \"My product is awesome\",\n        ...     \"description\": \"My product is very awesome\",\n        ...     \"is_active\": True,\n        ...     \"is_restricted\": False,\n        ...     \"maintainer\": \"My Company\",\n        ...     \"region\": \"Global\",\n        ...     \"publisher\": \"My Company\",\n        ...     \"sub_category\": \"Data\",\n        ...     \"tag\": \"My Company\",\n        ...     \"delivery_channel\": \"API\",\n        ...     \"theme\": \"Data\",\n        ...     \"release_date\": \"2021-01-01\",\n        ...     \"language\": \"English\",\n        ...     \"status\": \"Available\"\n        ... }\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_dict)\n\n        Instantiating a Product object from a JSON string:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; from fusion.product import Product\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product_json = '{\n        ...     \"identifier\": \"my_product\",\n        ...     \"title\": \"My Product\",\n        ...     \"category\": \"Data\",\n        ...     \"short_abstract\": \"My product is awesome\",\n        ...     \"description\": \"My product is very awesome\",\n        ...     \"is_active\": True,\n        ...     \"is_restricted\": False,\n        ...     \"maintainer\": \"My Company\",\n        ...     \"region\": \"Global\",\n        ...     \"publisher\": \"My Company\",\n        ...     \"sub_category\": \"Data\",\n        ...     \"tag\": \"My Company\",\n        ...     \"delivery_channel\": \"API\",\n        ...     \"theme\": \"Data\",\n        ...     \"release_date\": \"2021-01-01\",\n        ...     \"language\": \"English\",\n        ...     \"status\": \"Available\",\n        ... }'\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_json)\n\n        Instantiating a Product object from a CSV file:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; from fusion.product import Product\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(\"path/to/product.csv\")\n\n        Instantiating a Product object from a pandas Series:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; from fusion.product import Product\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product_series = pd.Series({\n        ...     \"identifier\": \"my_product\",\n        ...     \"title\": \"My Product\",\n        ...     \"category\": \"Data\",\n        ...     \"short_abstract\": \"My product is awesome\",\n        ...     \"description\": \"My product is very awesome\",\n        ...     \"is_active\": True,\n        ...     \"is_restricted\": False,\n        ...     \"maintainer\": \"My Company\",\n        ...     \"region\": \"Global\",\n        ...     \"publisher\": \"My Company\",\n        ...     \"sub_category\": \"Data\",\n        ...     \"tag\": \"My Company\",\n        ...     \"delivery_channel\": \"API\",\n        ...     \"theme\": \"Data\",\n        ...     \"release_date\": \"2021-01-01\",\n        ...     \"language\": \"English\",\n        ...     \"status\": \"Available\",\n        ... })\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_object(product_series)\n\n    \"\"\"\n    if isinstance(product_source, Product):\n        product = product_source\n    elif isinstance(product_source, dict):\n        product = Product._from_dict(product_source)\n    elif isinstance(product_source, str):\n        if _is_json(product_source):\n            product = Product._from_dict(js.loads(product_source))\n        else:\n            product = Product._from_csv(product_source)\n    elif isinstance(product_source, pd.Series):\n        product = Product._from_series(product_source)\n    else:\n        raise TypeError(f\"Could not resolve the object provided: {product_source}\")\n    product.client = self._client\n    return product\n</code></pre>"},{"location":"api/#fusion.product.Product.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the Product instance to a dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Product metadata as a dictionary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product = fusion.product(\"my_product\")\n&gt;&gt;&gt; product_dict = product.to_dict()\n</code></pre> Source code in <code>py_src/fusion/product.py</code> <pre><code>def to_dict(self: Product) -&gt; dict[str, Any]:\n    \"\"\"Convert the Product instance to a dictionary.\n\n    Returns:\n        dict[str, Any]: Product metadata as a dictionary.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product = fusion.product(\"my_product\")\n        &gt;&gt;&gt; product_dict = product.to_dict()\n\n    \"\"\"\n    product_dict = {snake_to_camel(k): v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n    return product_dict\n</code></pre>"},{"location":"api/#fusion.product.Product.update","title":"<code>update(catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Update an existing product in a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog(catalog=\"my_catalog\")\n&gt;&gt;&gt; product.title = \"My Updated Product Title\"\n&gt;&gt;&gt; product.update(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/product.py</code> <pre><code>def update(\n    self,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Update an existing product in a Fusion catalog.\n\n    Args:\n        client (Fusion): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; product = fusion.product(\"my_product\").from_catalog(catalog=\"my_catalog\")\n        &gt;&gt;&gt; product.title = \"My Updated Product Title\"\n        &gt;&gt;&gt; product.update(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    release_date = self.release_date if self.release_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n    delivery_channel = self.delivery_channel if self.delivery_channel else [\"API\"]\n\n    self.release_date = release_date\n    self.delivery_channel = delivery_channel\n\n    data = self.to_dict()\n\n    url = f\"{client.root_url}catalogs/{catalog}/products/{self.identifier}\"\n    resp: requests.Response = client.session.put(url, json=data)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset","title":"<code>Dataset</code>  <code>dataclass</code>","text":"<p>Fusion Dataset class for managing dataset metadata in a Fusion catalog.</p> <p>Attributes:</p> Name Type Description <code>identifier</code> <code>str</code> <p>A unique identifier for the dataset.</p> <code>title</code> <code>str</code> <p>A title for the dataset. If not provided, defaults to identifier.</p> <code>category</code> <code>str | list[str] | None</code> <p>A category or list of categories for the dataset. Defaults to None.</p> <code>description</code> <code>str</code> <p>A description of the dataset. If not provided, defaults to identifier.</p> <code>frequency</code> <code>str</code> <p>The frequency of the dataset. Defaults to \"Once\".</p> <code>is_internal_only_dataset</code> <code>bool</code> <p>Flag for internal datasets. Defaults to False.</p> <code>is_third_party_data</code> <code>bool</code> <p>Flag for third party data. Defaults to True.</p> <code>is_restricted</code> <code>bool | None</code> <p>Flag for restricted datasets. Defaults to None.</p> <code>is_raw_data</code> <code>bool</code> <p>Flag for raw datasets. Defaults to True.</p> <code>maintainer</code> <code>str | None</code> <p>Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".</p> <code>source</code> <code>str | list[str] | None</code> <p>Name of data vendor which provided the data. Defaults to None.</p> <code>region</code> <code>str | list[str] | None</code> <p>Region. Defaults to None.</p> <code>publisher</code> <code>str</code> <p>Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".</p> <code>product</code> <code>str | list[str] | None</code> <p>Product to associate dataset with. Defaults to None.</p> <code>sub_category</code> <code>str | list[str] | None</code> <p>Sub-category. Defaults to None.</p> <code>tags</code> <code>str | list[str] | None</code> <p>Tags used for search purposes. Defaults to None.</p> <code>created_date</code> <code>str | None</code> <p>Created date. Defaults to None.</p> <code>modified_date</code> <code>str | None</code> <p>Modified date. Defaults to None.</p> <code>delivery_channel</code> <code>str | list[str]</code> <p>Delivery channel. Defaults to \"API\".</p> <code>language</code> <code>str</code> <p>Language. Defaults to \"English\".</p> <code>status</code> <code>str</code> <p>Status. Defaults to \"Available\".</p> <code>type_</code> <code>str | None</code> <p>Dataset type. Defaults to \"Source\".</p> <code>container_type</code> <code>str | None</code> <p>Container type. Defaults to \"Snapshot-Full\".</p> <code>snowflake</code> <code>str | None</code> <p>Snowflake account connection. Defaults to None.</p> <code>complexity</code> <code>str | None</code> <p>Complexity. Defaults to None.</p> <code>is_immutable</code> <code>bool | None</code> <p>Flag for immutable datasets. Defaults to None.</p> <code>is_mnpi</code> <code>bool | None</code> <p>is_mnpi. Defaults to None.</p> <code>is_pci</code> <code>bool | None</code> <p>is_pci. Defaults to None.</p> <code>is_pii</code> <code>bool | None</code> <p>is_pii. Defaults to None.</p> <code>is_client</code> <code>bool | None</code> <p>is_client. Defaults to None.</p> <code>is_public</code> <code>bool | None</code> <p>is_public. Defaults to None.</p> <code>is_internal</code> <code>bool | None</code> <p>is_internal. Defaults to None.</p> <code>is_confidential</code> <code>bool | None</code> <p>is_confidential. Defaults to None.</p> <code>is_highly_confidential</code> <code>bool | None</code> <p>is_highly_confidential. Defaults to None.</p> <code>is_active</code> <code>bool | None</code> <p>is_active. Defaults to None.</p> <code>owners</code> <code>list[str] | None</code> <p>The owners of the dataset. Defaults to None.</p> <code>application_id</code> <code>str | dict[str, str] | None</code> <p>The application (most commonly seal ID) that the dataset/report/flow is owned by. Accepts string format for seal IDs, or a dictionary containing 'id' and 'type' as keys. Defaults to None.</p> <code>_client</code> <code>Any</code> <p>A Fusion client object. Defaults to None.</p> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>@dataclass\nclass Dataset(metaclass=CamelCaseMeta):\n    \"\"\"Fusion Dataset class for managing dataset metadata in a Fusion catalog.\n\n    Attributes:\n        identifier (str): A unique identifier for the dataset.\n        title (str, optional): A title for the dataset. If not provided, defaults to identifier.\n        category (str | list[str] | None, optional): A category or list of categories for the dataset. Defaults to None.\n        description (str, optional): A description of the dataset. If not provided, defaults to identifier.\n        frequency (str, optional): The frequency of the dataset. Defaults to \"Once\".\n        is_internal_only_dataset (bool, optional): Flag for internal datasets. Defaults to False.\n        is_third_party_data (bool, optional): Flag for third party data. Defaults to True.\n        is_restricted (bool | None, optional): Flag for restricted datasets. Defaults to None.\n        is_raw_data (bool, optional): Flag for raw datasets. Defaults to True.\n        maintainer (str | None, optional): Dataset maintainer. Defaults to \"J.P. Morgan Fusion\".\n        source (str | list[str] | None, optional): Name of data vendor which provided the data. Defaults to None.\n        region (str | list[str] | None, optional): Region. Defaults to None.\n        publisher (str, optional): Name of vendor that publishes the data. Defaults to \"J.P. Morgan\".\n        product (str | list[str] | None, optional): Product to associate dataset with. Defaults to None.\n        sub_category (str | list[str] | None, optional): Sub-category. Defaults to None.\n        tags (str | list[str] | None, optional): Tags used for search purposes. Defaults to None.\n        created_date (str | None, optional): Created date. Defaults to None.\n        modified_date (str | None, optional): Modified date. Defaults to None.\n        delivery_channel (str | list[str], optional): Delivery channel. Defaults to \"API\".\n        language (str, optional): Language. Defaults to \"English\".\n        status (str, optional): Status. Defaults to \"Available\".\n        type_ (str | None, optional): Dataset type. Defaults to \"Source\".\n        container_type (str | None, optional): Container type. Defaults to \"Snapshot-Full\".\n        snowflake (str | None, optional): Snowflake account connection. Defaults to None.\n        complexity (str | None, optional): Complexity. Defaults to None.\n        is_immutable (bool | None, optional): Flag for immutable datasets. Defaults to None.\n        is_mnpi (bool | None, optional): is_mnpi. Defaults to None.\n        is_pci (bool | None, optional): is_pci. Defaults to None.\n        is_pii (bool | None, optional): is_pii. Defaults to None.\n        is_client (bool | None, optional): is_client. Defaults to None.\n        is_public (bool | None, optional): is_public. Defaults to None.\n        is_internal (bool | None, optional): is_internal. Defaults to None.\n        is_confidential (bool | None, optional): is_confidential. Defaults to None.\n        is_highly_confidential (bool | None, optional): is_highly_confidential. Defaults to None.\n        is_active (bool | None, optional): is_active. Defaults to None.\n        owners (list[str] | None, optional): The owners of the dataset. Defaults to None.\n        application_id (str | dict[str, str] | None, optional): The application (most commonly seal ID) that the\n            dataset/report/flow is owned by. Accepts string format for seal IDs, or a dictionary containing 'id' and\n            'type' as keys. Defaults to None.\n        _client (Any, optional): A Fusion client object. Defaults to None.\n\n    \"\"\"\n\n    identifier: str\n    title: str = \"\"\n    category: str | list[str] | None = None\n    description: str = \"\"\n    frequency: str = \"Once\"\n    is_internal_only_dataset: bool = False\n    is_third_party_data: bool = True\n    is_restricted: bool | None = None\n    is_raw_data: bool = True\n    maintainer: str | None = \"J.P. Morgan Fusion\"\n    source: str | list[str] | None = None\n    region: str | list[str] | None = None\n    publisher: str = \"J.P. Morgan\"\n    product: str | list[str] | None = None\n    sub_category: str | list[str] | None = None\n    tags: str | list[str] | None = None\n    created_date: str | None = None\n    modified_date: str | None = None\n    delivery_channel: str | list[str] = field(default_factory=lambda: [\"API\"])\n    language: str = \"English\"\n    status: str = \"Available\"\n    type_: str | None = \"Source\"\n    container_type: str | None = \"Snapshot-Full\"\n    snowflake: str | None = None\n    complexity: str | None = None\n    is_immutable: bool | None = None\n    is_mnpi: bool | None = None\n    is_pci: bool | None = None\n    is_pii: bool | None = None\n    is_client: bool | None = None\n    is_public: bool | None = None\n    is_internal: bool | None = None\n    is_confidential: bool | None = None\n    is_highly_confidential: bool | None = None\n    is_active: bool | None = None\n    owners: list[str] | None = None\n    application_id: str | dict[str, str] | None = None\n\n    _client: Fusion | None = field(init=False, repr=False, compare=False, default=None)\n\n    def __repr__(self: Dataset) -&gt; str:\n        \"\"\"Return an object representation of the Dataset object.\n\n        Returns:\n            str: Object representation of the dataset.\n\n        \"\"\"\n        attrs = {k: v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n        return f\"Dataset(\\n\" + \",\\n \".join(f\"{k}={v!r}\" for k, v in attrs.items()) + \"\\n)\"\n\n    def __post_init__(self: Dataset) -&gt; None:\n        \"\"\"Format Dataset metadata fields after object initialization.\"\"\"\n        self.identifier = tidy_string(self.identifier).upper().replace(\" \", \"_\")\n        self.title = tidy_string(self.title) if self.title != \"\" else self.identifier.replace(\"_\", \" \").title()\n        self.description = tidy_string(self.description) if self.description != \"\" else self.title\n        self.category = (\n            self.category if isinstance(self.category, list) or self.category is None else make_list(self.category)\n        )\n        self.delivery_channel = (\n            self.delivery_channel if isinstance(self.delivery_channel, list) else make_list(self.delivery_channel)\n        )\n        self.source = self.source if isinstance(self.source, list) or self.source is None else make_list(self.source)\n        self.region = self.region if isinstance(self.region, list) or self.region is None else make_list(self.region)\n        self.product = (\n            self.product if isinstance(self.product, list) or self.product is None else make_list(self.product)\n        )\n        self.sub_category = (\n            self.sub_category\n            if isinstance(self.sub_category, list) or self.sub_category is None\n            else make_list(self.sub_category)\n        )\n        self.tags = self.tags if isinstance(self.tags, list) or self.tags is None else make_list(self.tags)\n        self.is_internal_only_dataset = (\n            self.is_internal_only_dataset\n            if isinstance(self.is_internal_only_dataset, bool)\n            else make_bool(self.is_internal_only_dataset)\n        )\n        self.created_date = convert_date_format(self.created_date) if self.created_date else None\n        self.modified_date = convert_date_format(self.modified_date) if self.modified_date else None\n        self.owners = self.owners if isinstance(self.owners, list) or self.owners is None else make_list(self.owners)\n        self.application_id = (\n            {\"id\": str(self.application_id), \"type\": \"Application (SEAL)\"}\n            if isinstance(self.application_id, str)\n            else self.application_id\n        )\n\n    def __getattr__(self, name: str) -&gt; Any:\n        # Redirect attribute access to the snake_case version\n        snake_name = camel_to_snake(name)\n        if snake_name in self.__dict__:\n            return self.__dict__[snake_name]\n        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        if name == \"client\":\n            # Use the property setter for client\n            object.__setattr__(self, name, value)\n        else:\n            snake_name = camel_to_snake(name)\n            self.__dict__[snake_name] = value\n\n    @property\n    def client(self) -&gt; Fusion | None:\n        \"\"\"Return the client.\"\"\"\n        return self._client\n\n    @client.setter\n    def client(self, client: Fusion | None) -&gt; None:\n        \"\"\"Set the client for the Dataset. Set automatically, if the Dataset is instantiated from a Fusion object.\n\n        Args:\n            client (Any): Fusion client object.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\")\n            &gt;&gt;&gt; dataset.client = fusion\n\n        \"\"\"\n        self._client = client\n\n    def _use_client(self, client: Fusion | None) -&gt; Fusion:\n        \"\"\"Determine client.\"\"\"\n\n        res = self._client if client is None else client\n        if res is None:\n            raise ValueError(\"A Fusion client object is required.\")\n        return res\n\n    @classmethod\n    def _from_series(cls: type[Dataset], series: pd.Series[Any]) -&gt; Dataset:\n        \"\"\"Instantiate a Dataset object from a pandas Series.\n\n        Args:\n            series (pd.Series[Any]): Dataset metadata as a pandas Series.\n\n        Returns:\n            Dataset: Dataset object.\n\n        \"\"\"\n        series = series.rename(lambda x: x.replace(\" \", \"\").replace(\"_\", \"\").lower())\n        series = series.rename({\"tag\": \"tags\"})\n        series = series.rename({\"type_\": \"type\"})\n        series = series.rename({\"productId\": \"product\"})\n\n        is_internal_only_dataset = series.get(\"isinternalonlydataset\", None)\n        is_internal_only_dataset = (\n            make_bool(is_internal_only_dataset) if is_internal_only_dataset is not None else is_internal_only_dataset\n        )\n        is_restricted = series.get(\"isrestricted\", None)\n        is_restricted = make_bool(is_restricted) if is_restricted is not None else is_restricted\n        is_immutable = series.get(\"isimmutable\", None)\n        is_immutable = make_bool(is_immutable) if is_immutable is not None else is_immutable\n        is_mnpi = series.get(\"ismnpi\", None)\n        is_mnpi = make_bool(is_mnpi) if is_mnpi is not None else is_mnpi\n        is_pci = series.get(\"ispci\", None)\n        is_pci = make_bool(is_pci) if is_pci is not None else is_pci\n        is_pii = series.get(\"ispii\", None)\n        is_pii = make_bool(is_pii) if is_pii is not None else is_pii\n        is_client = series.get(\"isclient\", None)\n        is_client = make_bool(is_client) if is_client is not None else is_client\n        is_public = series.get(\"ispublic\", None)\n        is_public = make_bool(is_public) if is_public is not None else is_public\n        is_internal = series.get(\"isinternal\", None)\n        is_internal = make_bool(is_internal) if is_internal is not None else is_internal\n        is_confidential = series.get(\"isconfidential\", None)\n        is_confidential = make_bool(is_confidential) if is_confidential is not None else is_confidential\n        is_highly_confidential = series.get(\"ishighlyconfidential\", None)\n        is_highly_confidential = (\n            make_bool(is_highly_confidential) if is_highly_confidential is not None else is_highly_confidential\n        )\n        is_active = series.get(\"isactive\", None)\n        is_active = make_bool(is_active) if is_active is not None else is_active\n\n        dataset = cls(\n            identifier=series.get(\"identifier\", \"\"),\n            category=series.get(\"category\", None),\n            delivery_channel=series.get(\"deliverychannel\", [\"API\"]),\n            title=series.get(\"title\", \"\"),\n            description=series.get(\"description\", \"\"),\n            frequency=series.get(\"frequency\", \"Once\"),\n            is_internal_only_dataset=is_internal_only_dataset,  # type: ignore\n            is_third_party_data=series.get(\"isthirdpartydata\", True),\n            is_restricted=is_restricted,\n            is_raw_data=series.get(\"israwdata\", True),\n            maintainer=series.get(\"maintainer\", \"J.P. Morgan Fusion\"),\n            source=series.get(\"source\", None),\n            region=series.get(\"region\", None),\n            publisher=series.get(\"publisher\", \"J.P. Morgan\"),\n            product=series.get(\"product\", None),\n            sub_category=series.get(\"subcategory\", None),\n            tags=series.get(\"tags\", None),\n            container_type=series.get(\"containertype\", \"Snapshot-Full\"),\n            language=series.get(\"language\", \"English\"),\n            status=series.get(\"status\", \"Available\"),\n            type_=series.get(\"type\", \"Source\"),\n            created_date=series.get(\"createddate\", None),\n            modified_date=series.get(\"modifieddate\", None),\n            snowflake=series.get(\"snowflake\", None),\n            complexity=series.get(\"complexity\", None),\n            owners=series.get(\"owners\", None),\n            application_id=series.get(\"applicationid\", None),\n            is_immutable=is_immutable,\n            is_mnpi=is_mnpi,\n            is_pci=is_pci,\n            is_pii=is_pii,\n            is_client=is_client,\n            is_public=is_public,\n            is_internal=is_internal,\n            is_confidential=is_confidential,\n            is_highly_confidential=is_highly_confidential,\n            is_active=is_active,\n        )\n        return dataset\n\n    @classmethod\n    def _from_dict(cls: type[Dataset], data: dict[str, Any]) -&gt; Dataset:\n        \"\"\"Instantiate a Dataset object from a dictionary.\n\n        Args:\n            data (dict[str, Any]): Dataset metadata as a dictionary.\n\n        Returns:\n            Dataset: Dataset object.\n\n        \"\"\"\n        keys = [f.name for f in fields(cls)]\n        keys = [\"type\" if key == \"type_\" else key for key in keys]\n        data = {camel_to_snake(k): v for k, v in data.items()}\n        data = {k: v for k, v in data.items() if k in keys}\n        if \"type\" in data:\n            data[\"type_\"] = data.pop(\"type\")\n        return cls(**data)\n\n    @classmethod\n    def _from_csv(cls: type[Dataset], file_path: str, identifier: str | None = None) -&gt; Dataset:\n        \"\"\"Instantiate a Dataset object from a CSV file.\n\n        Args:\n            file_path (str): Path to the CSV file.\n            identifier (str | None, optional): Dataset identifer for filtering if multipler datasets are defined in csv.\n                Defaults to None.\n\n        Returns:\n            Dataset: Dataset object.\n\n        \"\"\"\n        data = pd.read_csv(file_path)\n\n        return (\n            cls._from_series(data[data[\"identifier\"] == identifier].reset_index(drop=True).iloc[0])\n            if identifier\n            else cls._from_series(data.reset_index(drop=True).iloc[0])\n        )\n\n    def from_object(\n        self,\n        dataset_source: Dataset | dict[str, Any] | str | pd.Series[Any],\n    ) -&gt; Dataset:\n        \"\"\"Instantiate a Dataset object from a Dataset object, dictionary, JSON string, path to CSV, or pandas Series.\n\n        Args:\n            dataset_source (Dataset | dict[str, Any] | str | pd.Series[Any]): Dataset metadata source.\n\n        Raises:\n            TypeError: If the object provided is not a Dataset, dictionary, JSON string, path to CSV file,\n                or pandas Series.\n\n        Returns:\n            Dataset: Dataset object.\n\n        Examples:\n            Instantiate a Dataset object from a dictionary:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset_dict = {\n            ...     \"identifier\": \"my_dataset\",\n            ...     \"title\": \"My Dataset\",\n            ...     \"description\": \"My dataset description\",\n            ...     \"category\": \"Finance\",\n            ...     \"frequency\": \"Daily\",\n            ...     \"is_restricted\": False,\n            ...     \"is_raw_data\": True,\n            ...     \"maintainer\": \"J.P. Morgan Fusion\",\n            ...     \"source\": \"J.P. Morgan\",\n            ...     }\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_dict)\n\n            Instantiate a Dataset object from a JSON string:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset_json = '{\n            ...     \"identifier\": \"my_dataset\",\n            ...     \"title\": \"My Dataset\",\n            ...     \"description\": \"My dataset description\",\n            ...     \"category\": \"Finance\",\n            ...     \"frequency\": \"Daily\",\n            ...     \"is_restricted\": False,\n            ...     \"is_raw_data\": True,\n            ...     \"maintainer\": \"J.P. Morgan Fusion\",\n            ...     \"source\": \"J.P. Morgan\"\n            ...     }'\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_json)\n\n            Instantiate a Dataset object from a CSV file:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(\"path/to/dataset.csv\")\n\n            Instantiate a Dataset object from a pandas Series:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset_series = pd.Series({\n            ...     \"identifier\": \"my_dataset\",\n            ...     \"title\": \"My Dataset\",\n            ...     \"description\": \"My dataset description\",\n            ...     \"category\": \"Finance\",\n            ...     \"frequency\": \"Daily\",\n            ...     \"is_restricted\": False,\n            ...     \"is_raw_data\": True,\n            ...     \"maintainer\": \"J.P. Morgan Fusion\",\n            ...     \"source\": \"J.P. Morgan\"\n            ...     })\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_series)\n\n        \"\"\"\n        if isinstance(dataset_source, Dataset):\n            dataset = dataset_source\n        elif isinstance(dataset_source, dict):\n            dataset = self._from_dict(dataset_source)\n        elif isinstance(dataset_source, str):\n            if _is_json(dataset_source):\n                dataset = self._from_dict(js.loads(dataset_source))\n            else:\n                dataset = self._from_csv(dataset_source)\n        elif isinstance(dataset_source, pd.Series):\n            dataset = self._from_series(dataset_source)\n        else:\n            raise TypeError(f\"Could not resolve the object provided: {dataset_source}\")\n\n        dataset.client = self._client\n\n        return dataset\n\n    def from_catalog(self, catalog: str | None = None, client: Fusion | None = None) -&gt; Dataset:\n        \"\"\"Instantiate a Dataset object from a Fusion catalog.\n\n        Args:\n            catalog (str | None, optional): Catalog identifer. Defaults to None.\n            client (Fusion | None, optional): Fusion session. Defaults to None.\n                If instantiated from a Fusion object, then the client is set automatically.\n\n        Returns:\n            Dataset: Dataset object.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        dataset = self.identifier\n        resp = client.session.get(f\"{client.root_url}catalogs/{catalog}/datasets\")\n        requests_raise_for_status(resp)\n        list_datasets = resp.json()[\"resources\"]\n        dict_ = [dict_ for dict_ in list_datasets if dict_[\"identifier\"] == dataset][0]\n        dataset_obj = self._from_dict(dict_)\n        dataset_obj.client = client\n\n        prod_df = client.list_product_dataset_mapping(catalog=catalog)\n\n        if dataset.lower() in list(prod_df.dataset.str.lower()):\n            product = [prod_df[prod_df[\"dataset\"].str.lower() == dataset.lower()][\"product\"].iloc[0]]\n            dataset_obj.product = product\n\n        return dataset_obj\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert the Dataset instance to a dictionary.\n\n        Returns:\n            dict[str, Any]: Dataset metadata as a dictionary.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\")\n            &gt;&gt;&gt; dataset_dict = dataset.to_dict()\n\n        \"\"\"\n        dataset_dict = {snake_to_camel(k): v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n\n        return dataset_dict\n\n    def create(\n        self,\n        catalog: str | None = None,\n        product: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Upload a new dataset to a Fusion catalog.\n\n        Args:\n            catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n            product (str | None, optional): A product identifier to upload dataset to. If dataset object already has\n                product attribute populated, the attribute will be overwritten by this value. Defaults to None.\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            From scratch:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\n            ...     identifier= \"my_dataset\",\n            ...     title= \"My Dataset\",\n            ...     description= \"My dataset description\",\n            ...     category= \"Finance\",\n            ...     frequency= \"Daily\",\n            ...     is_restricted= False\n            ...     )\n            &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n            From a dictionary:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset_dict = {\n            ...     \"identifier\": \"my_dataset\",\n            ...     \"title\": \"My Dataset\",\n            ...     \"description\": \"My dataset description\",\n            ...     \"category\": \"Finance\",\n            ...     \"frequency\": \"Daily\",\n            ...     \"is_restricted\": False\n            ...     }\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_dict)\n            &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n            From a JSON string:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset_json = '{\n            ...     \"identifier\": \"my_dataset\",\n            ...     \"title\": \"My Dataset\",\n            ...     \"description\": \"My dataset description\",\n            ...     \"category\": \"Finance\",\n            ...     \"frequency\": \"Daily\",\n            ...     \"is_restricted\": False\n            ...     }'\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_json)\n            &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n            From a CSV file:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(\"path/to/dataset.csv\")\n            &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n            From a pandas Series:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset_series = pd.Series({\n            ...     \"identifier\": \"my_dataset\",\n            ...     \"title\": \"My Dataset\",\n            ...     \"description\": \"My dataset description\",\n            ...     \"category\": \"Finance\",\n            ...     \"frequency\": \"Daily\",\n            ...     \"is_restricted\": False\n            ...     })\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_series)\n\n            From existing dataset in a catalog:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n            &gt;&gt;&gt; dataset.identifier = \"my_new_dataset\"\n            &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        self.created_date = self.created_date if self.created_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n        self.modified_date = self.modified_date if self.modified_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n\n        self.product = [product] if product else self.product\n\n        data = self.to_dict()\n\n        if data.get(\"report\", None) and data[\"report\"][\"tier\"] == \"\":\n            raise ValueError(\"Tier cannot be blank for reports.\")\n\n        url = f\"{client.root_url}catalogs/{catalog}/datasets/{self.identifier}\"\n        resp: requests.Response = client.session.post(url, json=data)\n        requests_raise_for_status(resp)\n\n        return resp if return_resp_obj else None\n\n    def update(\n        self,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Updates a dataset via API from dataset object.\n\n        Args:\n            catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n            &gt;&gt;&gt; dataset.title = \"My Updated Dataset\"\n            &gt;&gt;&gt; dataset.update(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        self.created_date = self.created_date if self.created_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n        self.modified_date = self.modified_date if self.modified_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n\n        data = self.to_dict()\n\n        url = f\"{client.root_url}catalogs/{catalog}/datasets/{self.identifier}\"\n        resp: requests.Response = client.session.put(url, json=data)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def delete(\n        self,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Delete a dataset via API from its dataset identifier.\n\n        Args:\n            catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.dataset(\"my_dataset\").delete(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        url = f\"{client.root_url}catalogs/{catalog}/datasets/{self.identifier}\"\n        resp: requests.Response = client.session.delete(url)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def copy(\n        self,\n        catalog_to: str,\n        catalog_from: str | None = None,\n        client: Fusion | None = None,\n        client_to: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Copy dataset from one catalog and/or environment to another by copy.\n\n        Args:\n            catalog_to (str): A catalog identifier to which to copy dataset.\n            catalog_from (str, optional): A catalog identifier from which to copy dataset. Defaults to \"common\".\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            client_to (Fusion | None, optional): Fusion client object. Defaults to current instance.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").copy(catalog_from=\"my_catalog\", catalog_to=\"my_new_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog_from = client._use_catalog(catalog_from)\n\n        if client_to is None:\n            client_to = client\n        dataset_obj = self.from_catalog(catalog=catalog_from, client=client)\n        dataset_obj.client = client_to\n        resp = dataset_obj.create(client=client_to, catalog=catalog_to, return_resp_obj=True)\n        return resp if return_resp_obj else None\n\n    def activate(\n        self,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Activate a dataset by setting the isActive flag to True.\n\n        Args:\n            catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n            client (Fusion | None, optional):  A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.dataset(\"my_dataset\").activate(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        dataset_obj = self.from_catalog(catalog=catalog, client=client)\n        dataset_obj.is_active = True\n        resp = dataset_obj.update(catalog=catalog, client=client, return_resp_obj=return_resp_obj)\n\n        return resp if return_resp_obj else None\n\n    def add_to_product(\n        self,\n        product: str,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Map dataset to a product.\n\n        Args:\n            product (str): A product identifier.\n            catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n            client (Fusion | None, optional):  A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.dataset(\"my_dataset\").add_to_product(product=\"MY_PRODUCT\", catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        url = f\"{client.root_url}catalogs/{catalog}/productDatasets\"\n        data = {\"product\": product, \"datasets\": [self.identifier]}\n        resp = client.session.put(url=url, json=data)\n\n        requests_raise_for_status(resp)\n\n        return resp if return_resp_obj else None\n\n    def remove_from_product(\n        self,\n        product: str,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Delete dataset to product mapping.\n\n        Args:\n            product (str): A product identifier.\n            catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n            client (Fusion | None, optional):  A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.dataset(\"my_dataset\").remove_from_product(product=\"MY_PRODUCT\", catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        dataset = self.identifier\n        url = f\"{client.root_url}catalogs/{catalog}/productDatasets/{product}/{dataset}\"\n        resp = client.session.delete(url=url)\n\n        requests_raise_for_status(resp)\n\n        return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.client","title":"<code>client</code>  <code>property</code> <code>writable</code>","text":"<p>Return the client.</p>"},{"location":"api/#fusion.dataset.Dataset.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Format Dataset metadata fields after object initialization.</p> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def __post_init__(self: Dataset) -&gt; None:\n    \"\"\"Format Dataset metadata fields after object initialization.\"\"\"\n    self.identifier = tidy_string(self.identifier).upper().replace(\" \", \"_\")\n    self.title = tidy_string(self.title) if self.title != \"\" else self.identifier.replace(\"_\", \" \").title()\n    self.description = tidy_string(self.description) if self.description != \"\" else self.title\n    self.category = (\n        self.category if isinstance(self.category, list) or self.category is None else make_list(self.category)\n    )\n    self.delivery_channel = (\n        self.delivery_channel if isinstance(self.delivery_channel, list) else make_list(self.delivery_channel)\n    )\n    self.source = self.source if isinstance(self.source, list) or self.source is None else make_list(self.source)\n    self.region = self.region if isinstance(self.region, list) or self.region is None else make_list(self.region)\n    self.product = (\n        self.product if isinstance(self.product, list) or self.product is None else make_list(self.product)\n    )\n    self.sub_category = (\n        self.sub_category\n        if isinstance(self.sub_category, list) or self.sub_category is None\n        else make_list(self.sub_category)\n    )\n    self.tags = self.tags if isinstance(self.tags, list) or self.tags is None else make_list(self.tags)\n    self.is_internal_only_dataset = (\n        self.is_internal_only_dataset\n        if isinstance(self.is_internal_only_dataset, bool)\n        else make_bool(self.is_internal_only_dataset)\n    )\n    self.created_date = convert_date_format(self.created_date) if self.created_date else None\n    self.modified_date = convert_date_format(self.modified_date) if self.modified_date else None\n    self.owners = self.owners if isinstance(self.owners, list) or self.owners is None else make_list(self.owners)\n    self.application_id = (\n        {\"id\": str(self.application_id), \"type\": \"Application (SEAL)\"}\n        if isinstance(self.application_id, str)\n        else self.application_id\n    )\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.__repr__","title":"<code>__repr__()</code>","text":"<p>Return an object representation of the Dataset object.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Object representation of the dataset.</p> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def __repr__(self: Dataset) -&gt; str:\n    \"\"\"Return an object representation of the Dataset object.\n\n    Returns:\n        str: Object representation of the dataset.\n\n    \"\"\"\n    attrs = {k: v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n    return f\"Dataset(\\n\" + \",\\n \".join(f\"{k}={v!r}\" for k, v in attrs.items()) + \"\\n)\"\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.activate","title":"<code>activate(catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Activate a dataset by setting the isActive flag to True.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to \"common\".</p> <code>None</code> <code>client</code> <code>Fusion | None</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.dataset(\"my_dataset\").activate(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def activate(\n    self,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Activate a dataset by setting the isActive flag to True.\n\n    Args:\n        catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n        client (Fusion | None, optional):  A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.dataset(\"my_dataset\").activate(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    dataset_obj = self.from_catalog(catalog=catalog, client=client)\n    dataset_obj.is_active = True\n    resp = dataset_obj.update(catalog=catalog, client=client, return_resp_obj=return_resp_obj)\n\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.add_to_product","title":"<code>add_to_product(product, catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Map dataset to a product.</p> <p>Parameters:</p> Name Type Description Default <code>product</code> <code>str</code> <p>A product identifier.</p> required <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to \"common\".</p> <code>None</code> <code>client</code> <code>Fusion | None</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.dataset(\"my_dataset\").add_to_product(product=\"MY_PRODUCT\", catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def add_to_product(\n    self,\n    product: str,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Map dataset to a product.\n\n    Args:\n        product (str): A product identifier.\n        catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n        client (Fusion | None, optional):  A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.dataset(\"my_dataset\").add_to_product(product=\"MY_PRODUCT\", catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    url = f\"{client.root_url}catalogs/{catalog}/productDatasets\"\n    data = {\"product\": product, \"datasets\": [self.identifier]}\n    resp = client.session.put(url=url, json=data)\n\n    requests_raise_for_status(resp)\n\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.copy","title":"<code>copy(catalog_to, catalog_from=None, client=None, client_to=None, return_resp_obj=False)</code>","text":"<p>Copy dataset from one catalog and/or environment to another by copy.</p> <p>Parameters:</p> Name Type Description Default <code>catalog_to</code> <code>str</code> <p>A catalog identifier to which to copy dataset.</p> required <code>catalog_from</code> <code>str</code> <p>A catalog identifier from which to copy dataset. Defaults to \"common\".</p> <code>None</code> <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>client_to</code> <code>Fusion | None</code> <p>Fusion client object. Defaults to current instance.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").copy(catalog_from=\"my_catalog\", catalog_to=\"my_new_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def copy(\n    self,\n    catalog_to: str,\n    catalog_from: str | None = None,\n    client: Fusion | None = None,\n    client_to: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Copy dataset from one catalog and/or environment to another by copy.\n\n    Args:\n        catalog_to (str): A catalog identifier to which to copy dataset.\n        catalog_from (str, optional): A catalog identifier from which to copy dataset. Defaults to \"common\".\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        client_to (Fusion | None, optional): Fusion client object. Defaults to current instance.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").copy(catalog_from=\"my_catalog\", catalog_to=\"my_new_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog_from = client._use_catalog(catalog_from)\n\n    if client_to is None:\n        client_to = client\n    dataset_obj = self.from_catalog(catalog=catalog_from, client=client)\n    dataset_obj.client = client_to\n    resp = dataset_obj.create(client=client_to, catalog=catalog_to, return_resp_obj=True)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.create","title":"<code>create(catalog=None, product=None, client=None, return_resp_obj=False)</code>","text":"<p>Upload a new dataset to a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to \"common\".</p> <code>None</code> <code>product</code> <code>str | None</code> <p>A product identifier to upload dataset to. If dataset object already has product attribute populated, the attribute will be overwritten by this value. Defaults to None.</p> <code>None</code> <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>From scratch:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\n...     identifier= \"my_dataset\",\n...     title= \"My Dataset\",\n...     description= \"My dataset description\",\n...     category= \"Finance\",\n...     frequency= \"Daily\",\n...     is_restricted= False\n...     )\n&gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\nFrom a dictionary:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset_dict = {\n...     \"identifier\": \"my_dataset\",\n...     \"title\": \"My Dataset\",\n...     \"description\": \"My dataset description\",\n...     \"category\": \"Finance\",\n...     \"frequency\": \"Daily\",\n...     \"is_restricted\": False\n...     }\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_dict)\n&gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\nFrom a JSON string:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset_json = '{\n...     \"identifier\": \"my_dataset\",\n...     \"title\": \"My Dataset\",\n...     \"description\": \"My dataset description\",\n...     \"category\": \"Finance\",\n...     \"frequency\": \"Daily\",\n...     \"is_restricted\": False\n...     }'\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_json)\n&gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\nFrom a CSV file:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(\"path/to/dataset.csv\")\n&gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\nFrom a pandas Series:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset_series = pd.Series({\n...     \"identifier\": \"my_dataset\",\n...     \"title\": \"My Dataset\",\n...     \"description\": \"My dataset description\",\n...     \"category\": \"Finance\",\n...     \"frequency\": \"Daily\",\n...     \"is_restricted\": False\n...     })\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_series)\n\nFrom existing dataset in a catalog:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n&gt;&gt;&gt; dataset.identifier = \"my_new_dataset\"\n&gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def create(\n    self,\n    catalog: str | None = None,\n    product: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Upload a new dataset to a Fusion catalog.\n\n    Args:\n        catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n        product (str | None, optional): A product identifier to upload dataset to. If dataset object already has\n            product attribute populated, the attribute will be overwritten by this value. Defaults to None.\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        From scratch:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\n        ...     identifier= \"my_dataset\",\n        ...     title= \"My Dataset\",\n        ...     description= \"My dataset description\",\n        ...     category= \"Finance\",\n        ...     frequency= \"Daily\",\n        ...     is_restricted= False\n        ...     )\n        &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n        From a dictionary:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset_dict = {\n        ...     \"identifier\": \"my_dataset\",\n        ...     \"title\": \"My Dataset\",\n        ...     \"description\": \"My dataset description\",\n        ...     \"category\": \"Finance\",\n        ...     \"frequency\": \"Daily\",\n        ...     \"is_restricted\": False\n        ...     }\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_dict)\n        &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n        From a JSON string:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset_json = '{\n        ...     \"identifier\": \"my_dataset\",\n        ...     \"title\": \"My Dataset\",\n        ...     \"description\": \"My dataset description\",\n        ...     \"category\": \"Finance\",\n        ...     \"frequency\": \"Daily\",\n        ...     \"is_restricted\": False\n        ...     }'\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_json)\n        &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n        From a CSV file:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(\"path/to/dataset.csv\")\n        &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n        From a pandas Series:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset_series = pd.Series({\n        ...     \"identifier\": \"my_dataset\",\n        ...     \"title\": \"My Dataset\",\n        ...     \"description\": \"My dataset description\",\n        ...     \"category\": \"Finance\",\n        ...     \"frequency\": \"Daily\",\n        ...     \"is_restricted\": False\n        ...     })\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_series)\n\n        From existing dataset in a catalog:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n        &gt;&gt;&gt; dataset.identifier = \"my_new_dataset\"\n        &gt;&gt;&gt; dataset.create(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    self.created_date = self.created_date if self.created_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n    self.modified_date = self.modified_date if self.modified_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n\n    self.product = [product] if product else self.product\n\n    data = self.to_dict()\n\n    if data.get(\"report\", None) and data[\"report\"][\"tier\"] == \"\":\n        raise ValueError(\"Tier cannot be blank for reports.\")\n\n    url = f\"{client.root_url}catalogs/{catalog}/datasets/{self.identifier}\"\n    resp: requests.Response = client.session.post(url, json=data)\n    requests_raise_for_status(resp)\n\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.delete","title":"<code>delete(catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Delete a dataset via API from its dataset identifier.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to \"common\".</p> <code>None</code> <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.dataset(\"my_dataset\").delete(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def delete(\n    self,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Delete a dataset via API from its dataset identifier.\n\n    Args:\n        catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.dataset(\"my_dataset\").delete(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    url = f\"{client.root_url}catalogs/{catalog}/datasets/{self.identifier}\"\n    resp: requests.Response = client.session.delete(url)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.from_catalog","title":"<code>from_catalog(catalog=None, client=None)</code>","text":"<p>Instantiate a Dataset object from a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str | None</code> <p>Catalog identifer. Defaults to None.</p> <code>None</code> <code>client</code> <code>Fusion | None</code> <p>Fusion session. Defaults to None. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset object.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def from_catalog(self, catalog: str | None = None, client: Fusion | None = None) -&gt; Dataset:\n    \"\"\"Instantiate a Dataset object from a Fusion catalog.\n\n    Args:\n        catalog (str | None, optional): Catalog identifer. Defaults to None.\n        client (Fusion | None, optional): Fusion session. Defaults to None.\n            If instantiated from a Fusion object, then the client is set automatically.\n\n    Returns:\n        Dataset: Dataset object.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    dataset = self.identifier\n    resp = client.session.get(f\"{client.root_url}catalogs/{catalog}/datasets\")\n    requests_raise_for_status(resp)\n    list_datasets = resp.json()[\"resources\"]\n    dict_ = [dict_ for dict_ in list_datasets if dict_[\"identifier\"] == dataset][0]\n    dataset_obj = self._from_dict(dict_)\n    dataset_obj.client = client\n\n    prod_df = client.list_product_dataset_mapping(catalog=catalog)\n\n    if dataset.lower() in list(prod_df.dataset.str.lower()):\n        product = [prod_df[prod_df[\"dataset\"].str.lower() == dataset.lower()][\"product\"].iloc[0]]\n        dataset_obj.product = product\n\n    return dataset_obj\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.from_object","title":"<code>from_object(dataset_source)</code>","text":"<p>Instantiate a Dataset object from a Dataset object, dictionary, JSON string, path to CSV, or pandas Series.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_source</code> <code>Dataset | dict[str, Any] | str | Series[Any]</code> <p>Dataset metadata source.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object provided is not a Dataset, dictionary, JSON string, path to CSV file, or pandas Series.</p> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset object.</p> <p>Examples:</p> <p>Instantiate a Dataset object from a dictionary:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset_dict = {\n...     \"identifier\": \"my_dataset\",\n...     \"title\": \"My Dataset\",\n...     \"description\": \"My dataset description\",\n...     \"category\": \"Finance\",\n...     \"frequency\": \"Daily\",\n...     \"is_restricted\": False,\n...     \"is_raw_data\": True,\n...     \"maintainer\": \"J.P. Morgan Fusion\",\n...     \"source\": \"J.P. Morgan\",\n...     }\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_dict)\n</code></pre> <p>Instantiate a Dataset object from a JSON string:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset_json = '{\n...     \"identifier\": \"my_dataset\",\n...     \"title\": \"My Dataset\",\n...     \"description\": \"My dataset description\",\n...     \"category\": \"Finance\",\n...     \"frequency\": \"Daily\",\n...     \"is_restricted\": False,\n...     \"is_raw_data\": True,\n...     \"maintainer\": \"J.P. Morgan Fusion\",\n...     \"source\": \"J.P. Morgan\"\n...     }'\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_json)\n</code></pre> <p>Instantiate a Dataset object from a CSV file:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(\"path/to/dataset.csv\")\n</code></pre> <p>Instantiate a Dataset object from a pandas Series:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset_series = pd.Series({\n...     \"identifier\": \"my_dataset\",\n...     \"title\": \"My Dataset\",\n...     \"description\": \"My dataset description\",\n...     \"category\": \"Finance\",\n...     \"frequency\": \"Daily\",\n...     \"is_restricted\": False,\n...     \"is_raw_data\": True,\n...     \"maintainer\": \"J.P. Morgan Fusion\",\n...     \"source\": \"J.P. Morgan\"\n...     })\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_series)\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def from_object(\n    self,\n    dataset_source: Dataset | dict[str, Any] | str | pd.Series[Any],\n) -&gt; Dataset:\n    \"\"\"Instantiate a Dataset object from a Dataset object, dictionary, JSON string, path to CSV, or pandas Series.\n\n    Args:\n        dataset_source (Dataset | dict[str, Any] | str | pd.Series[Any]): Dataset metadata source.\n\n    Raises:\n        TypeError: If the object provided is not a Dataset, dictionary, JSON string, path to CSV file,\n            or pandas Series.\n\n    Returns:\n        Dataset: Dataset object.\n\n    Examples:\n        Instantiate a Dataset object from a dictionary:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset_dict = {\n        ...     \"identifier\": \"my_dataset\",\n        ...     \"title\": \"My Dataset\",\n        ...     \"description\": \"My dataset description\",\n        ...     \"category\": \"Finance\",\n        ...     \"frequency\": \"Daily\",\n        ...     \"is_restricted\": False,\n        ...     \"is_raw_data\": True,\n        ...     \"maintainer\": \"J.P. Morgan Fusion\",\n        ...     \"source\": \"J.P. Morgan\",\n        ...     }\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_dict)\n\n        Instantiate a Dataset object from a JSON string:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset_json = '{\n        ...     \"identifier\": \"my_dataset\",\n        ...     \"title\": \"My Dataset\",\n        ...     \"description\": \"My dataset description\",\n        ...     \"category\": \"Finance\",\n        ...     \"frequency\": \"Daily\",\n        ...     \"is_restricted\": False,\n        ...     \"is_raw_data\": True,\n        ...     \"maintainer\": \"J.P. Morgan Fusion\",\n        ...     \"source\": \"J.P. Morgan\"\n        ...     }'\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_json)\n\n        Instantiate a Dataset object from a CSV file:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(\"path/to/dataset.csv\")\n\n        Instantiate a Dataset object from a pandas Series:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset_series = pd.Series({\n        ...     \"identifier\": \"my_dataset\",\n        ...     \"title\": \"My Dataset\",\n        ...     \"description\": \"My dataset description\",\n        ...     \"category\": \"Finance\",\n        ...     \"frequency\": \"Daily\",\n        ...     \"is_restricted\": False,\n        ...     \"is_raw_data\": True,\n        ...     \"maintainer\": \"J.P. Morgan Fusion\",\n        ...     \"source\": \"J.P. Morgan\"\n        ...     })\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_object(dataset_series)\n\n    \"\"\"\n    if isinstance(dataset_source, Dataset):\n        dataset = dataset_source\n    elif isinstance(dataset_source, dict):\n        dataset = self._from_dict(dataset_source)\n    elif isinstance(dataset_source, str):\n        if _is_json(dataset_source):\n            dataset = self._from_dict(js.loads(dataset_source))\n        else:\n            dataset = self._from_csv(dataset_source)\n    elif isinstance(dataset_source, pd.Series):\n        dataset = self._from_series(dataset_source)\n    else:\n        raise TypeError(f\"Could not resolve the object provided: {dataset_source}\")\n\n    dataset.client = self._client\n\n    return dataset\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.remove_from_product","title":"<code>remove_from_product(product, catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Delete dataset to product mapping.</p> <p>Parameters:</p> Name Type Description Default <code>product</code> <code>str</code> <p>A product identifier.</p> required <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to \"common\".</p> <code>None</code> <code>client</code> <code>Fusion | None</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.dataset(\"my_dataset\").remove_from_product(product=\"MY_PRODUCT\", catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def remove_from_product(\n    self,\n    product: str,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Delete dataset to product mapping.\n\n    Args:\n        product (str): A product identifier.\n        catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n        client (Fusion | None, optional):  A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.dataset(\"my_dataset\").remove_from_product(product=\"MY_PRODUCT\", catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    dataset = self.identifier\n    url = f\"{client.root_url}catalogs/{catalog}/productDatasets/{product}/{dataset}\"\n    resp = client.session.delete(url=url)\n\n    requests_raise_for_status(resp)\n\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the Dataset instance to a dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dataset metadata as a dictionary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\")\n&gt;&gt;&gt; dataset_dict = dataset.to_dict()\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the Dataset instance to a dictionary.\n\n    Returns:\n        dict[str, Any]: Dataset metadata as a dictionary.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\")\n        &gt;&gt;&gt; dataset_dict = dataset.to_dict()\n\n    \"\"\"\n    dataset_dict = {snake_to_camel(k): v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n\n    return dataset_dict\n</code></pre>"},{"location":"api/#fusion.dataset.Dataset.update","title":"<code>update(catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Updates a dataset via API from dataset object.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>str | None</code> <p>A catalog identifier. Defaults to \"common\".</p> <code>None</code> <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n&gt;&gt;&gt; dataset.title = \"My Updated Dataset\"\n&gt;&gt;&gt; dataset.update(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/dataset.py</code> <pre><code>def update(\n    self,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Updates a dataset via API from dataset object.\n\n    Args:\n        catalog (str | None, optional): A catalog identifier. Defaults to \"common\".\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; dataset = fusion.dataset(\"my_dataset\").from_catalog(catalog=\"my_catalog\")\n        &gt;&gt;&gt; dataset.title = \"My Updated Dataset\"\n        &gt;&gt;&gt; dataset.update(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    self.created_date = self.created_date if self.created_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n    self.modified_date = self.modified_date if self.modified_date else pd.Timestamp(\"today\").strftime(\"%Y-%m-%d\")\n\n    data = self.to_dict()\n\n    url = f\"{client.root_url}catalogs/{catalog}/datasets/{self.identifier}\"\n    resp: requests.Response = client.session.put(url, json=data)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute","title":"<code>Attribute</code>  <code>dataclass</code>","text":"<p>Fusion Attribute class for managing attributes metadata in a Fusion catalog.</p> <p>Attributes:</p> Name Type Description <code>identifier</code> <code>str</code> <p>The unique identifier for the attribute.</p> <code>index</code> <code>int</code> <p>Attribute index.</p> <code>data_type</code> <code>str | Types</code> <p>Datatype of attribute. Defaults to \"String\".</p> <code>title</code> <code>str</code> <p>Attribute title. If not provided, defaults to identifier.</p> <code>description</code> <code>str</code> <p>Attribute description. If not provided, defaults to identifier.</p> <code>is_dataset_key</code> <code>bool</code> <p>Flag for primary keys. Defaults to False.</p> <code>source</code> <code>str | None</code> <p>Name of data vendor which provided the data. Defaults to None.</p> <code>source_field_id</code> <code>str | None</code> <p>Original identifier of attribute, if attribute has been renamed. If not provided, defaults to identifier.</p> <code>is_internal_dataset_key</code> <code>bool | None</code> <p>Flag for internal primary keys. Defaults to None.</p> <code>is_externally_visible</code> <code>bool | None</code> <p>Flag for externally visible attributes. Defaults to True.</p> <code>unit</code> <code>Any | None</code> <p>Unit of attribute. Defaults to None.</p> <code>multiplier</code> <code>float</code> <p>Multiplier for unit. Defaults to 1.0.</p> <code>is_propagation_eligible</code> <code>bool | None</code> <p>Flag for propagation eligibility. Defaults to None.</p> <code>is_metric</code> <code>bool | None</code> <p>Flag for attributes that are metrics. Defaults to None.</p> <code>available_from</code> <code>str | None</code> <p>Date from which the attribute is available. Defaults to None.</p> <code>deprecated_from</code> <code>str | None</code> <p>Date from which the attribute is deprecated. Defaults to None.</p> <code>term</code> <code>str</code> <p>Term. Defaults to \"bizterm1\".</p> <code>dataset</code> <code>int | None</code> <p>Dataset. Defaults to None.</p> <code>attribute_type</code> <code>str | None</code> <p>Attribute type. Defaults to None.</p> <code>application_id</code> <code>str | dict[str, str] | None</code> <p>The seal ID of the dataset in string format, or a dictionary containing 'id' and 'type'. Used for catalog attributes. Defaults to None.</p> <code>publisher</code> <code>str | None</code> <p>Publisher of the attribute. Used for catalog attributes. Defaults to None.</p> <code>is_key_data_element</code> <code>bool | None</code> <p>Flag for key data elements. Used for attributes registered to Reports. Defaults to None.</p> <code>_client</code> <code>Fusion | None</code> <p>Fusion client object. Defaults to None.</p> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>@dataclass\nclass Attribute(metaclass=CamelCaseMeta):\n    \"\"\"Fusion Attribute class for managing attributes metadata in a Fusion catalog.\n\n    Attributes:\n        identifier (str): The unique identifier for the attribute.\n        index (int): Attribute index.\n        data_type (str | Types, optional): Datatype of attribute. Defaults to \"String\".\n        title (str, optional): Attribute title. If not provided, defaults to identifier.\n        description (str, optional): Attribute description. If not provided, defaults to identifier.\n        is_dataset_key (bool, optional): Flag for primary keys. Defaults to False.\n        source (str | None, optional): Name of data vendor which provided the data. Defaults to None.\n        source_field_id (str | None, optional): Original identifier of attribute, if attribute has been renamed.\n            If not provided, defaults to identifier.\n        is_internal_dataset_key (bool | None, optional): Flag for internal primary keys. Defaults to None.\n        is_externally_visible (bool | None, optional): Flag for externally visible attributes. Defaults to True.\n        unit (Any | None, optional): Unit of attribute. Defaults to None.\n        multiplier (float, optional): Multiplier for unit. Defaults to 1.0.\n        is_propagation_eligible (bool | None, optional): Flag for propagation eligibility. Defaults to None.\n        is_metric (bool | None, optional): Flag for attributes that are metrics. Defaults to None.\n        available_from (str | None, optional): Date from which the attribute is available. Defaults to None.\n        deprecated_from (str | None, optional): Date from which the attribute is deprecated. Defaults to None.\n        term (str, optional): Term. Defaults to \"bizterm1\".\n        dataset (int | None, optional): Dataset. Defaults to None.\n        attribute_type (str | None, optional): Attribute type. Defaults to None.\n        application_id (str | dict[str, str] | None, optional): The seal ID of the dataset in string format,\n            or a dictionary containing 'id' and 'type'. Used for catalog attributes. Defaults to None.\n        publisher (str | None, optional): Publisher of the attribute. Used for catalog attributes. Defaults to None.\n        is_key_data_element (bool | None, optional): Flag for key data elements. Used for attributes registered to\n            Reports. Defaults to None.\n        _client (Fusion | None, optional): Fusion client object. Defaults to None.\n\n    \"\"\"\n\n    identifier: str\n    index: int\n    data_type: Types = cast(Types, Types.String)\n    title: str = \"\"\n    description: str = \"\"\n    is_dataset_key: bool = False\n    source: str | None = None\n    source_field_id: str | None = None\n    is_internal_dataset_key: bool | None = None\n    is_externally_visible: bool | None = True\n    unit: Any | None = None\n    multiplier: float = 1.0\n    is_propagation_eligible: bool | None = None\n    is_metric: bool | None = None\n    available_from: str | None = None\n    deprecated_from: str | None = None\n    term: str = \"bizterm1\"\n    dataset: int | None = None\n    attribute_type: str | None = None\n    application_id: str | dict[str, str] | None = None\n    publisher: str | None = None\n    is_key_data_element: bool | None = None\n\n    _client: Fusion | None = field(init=False, repr=False, compare=False, default=None)\n\n    def __str__(self: Attribute) -&gt; str:\n        \"\"\"Format string representation.\"\"\"\n        attrs = {k: v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n        return f\"Attribute(\\n\" + \",\\n \".join(f\"{k}={v!r}\" for k, v in attrs.items()) + \"\\n)\"\n\n    def __repr__(self: Attribute) -&gt; str:\n        \"\"\"Format object representation.\"\"\"\n        s = \", \".join(f\"{getattr(self, f.name)!r}\" for f in fields(self) if not f.name.startswith(\"_\"))\n        return \"(\" + s + \")\"\n\n    def __post_init__(self: Attribute) -&gt; None:\n        \"\"\"Format Attribute metadata fields after object initialization.\"\"\"\n        self.is_dataset_key = make_bool(self.is_dataset_key)\n        self.identifier = tidy_string(self.identifier).lower().replace(\" \", \"_\")\n        self.title = tidy_string(self.title) if self.title != \"\" else self.identifier.replace(\"_\", \" \").title()\n        self.description = tidy_string(self.description) if self.description and self.description != \"\" else self.title\n        self.source_field_id = (\n            tidy_string(self.source_field_id).lower().replace(\" \", \"_\") if self.source_field_id else self.identifier\n        )\n        self.available_from = convert_date_format(self.available_from) if self.available_from else None\n        self.deprecated_from = convert_date_format(self.deprecated_from) if self.deprecated_from else None\n        self.data_type = Types[str(self.data_type).strip().rsplit(\".\", maxsplit=1)[-1].title()]\n        self.application_id = (\n            {\"id\": str(self.application_id), \"type\": \"Application (SEAL)\"}\n            if isinstance(self.application_id, str)\n            else self.application_id\n        )\n\n    def __getattr__(self, name: str) -&gt; Any:\n        # Redirect attribute access to the snake_case version\n        snake_name = camel_to_snake(name)\n        if snake_name in self.__dict__:\n            return self.__dict__[snake_name]\n        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        if name == \"client\":\n            # Use the property setter for client\n            object.__setattr__(self, name, value)\n        else:\n            snake_name = camel_to_snake(name)\n            self.__dict__[snake_name] = value\n\n    @property\n    def client(self) -&gt; Fusion | None:\n        \"\"\"Return the client.\"\"\"\n        return self._client\n\n    @client.setter\n    def client(self, client: Fusion | None) -&gt; None:\n        \"\"\"Set the client for the Dataset. Set automatically, if the Dataset is instantiated from a Fusion object.\n\n        Args:\n            client (Any): Fusion client object.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attribute.client = fusion\n\n        \"\"\"\n        self._client = client\n\n    def _use_client(self, client: Fusion | None) -&gt; Fusion:\n        \"\"\"Determine client.\"\"\"\n\n        res = self._client if client is None else client\n        if res is None:\n            raise ValueError(\"A Fusion client object is required.\")\n        return res\n\n    @classmethod\n    def _from_series(\n        cls: type[Attribute],\n        series: pd.Series[Any],\n    ) -&gt; Attribute:\n        \"\"\"Instantiate an Attribute object from a pandas Series.\n\n        Args:\n            series (pd.Series[Any]): Attribute metadata as a pandas Series.\n\n        Returns:\n            Attribute: Attribute object.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; series = pd.Series({\n            ...     \"identifier\": \"my_attribute\",\n            ...     \"index\": 0,\n            ...     \"data_type\": \"String\",\n            ...     \"title\": \"My Attribute\",\n            ...     \"description\": \"My attribute description\"\n            ... })\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)._from_series(series)\n\n        \"\"\"\n        series = series.rename(lambda x: x.replace(\" \", \"\").replace(\"_\", \"\").lower()).replace(\n            to_replace=np.nan, value=None\n        )\n        data_type = series.get(\"datatype\", cast(Types, Types.String))\n        data_type = series.get(\"type\", cast(Types, Types.String)) if data_type is None else data_type\n        source = series.get(\"source\", None)\n        source = source.strip() if isinstance(source, str) else source\n\n        is_propagation_eligible = series.get(\"ispropagationeligible\", None)\n        is_propagation_eligible = (\n            make_bool(is_propagation_eligible) if is_propagation_eligible is not None else is_propagation_eligible\n        )\n        is_metric = series.get(\"ismetric\", None)\n        is_metric = make_bool(is_metric) if is_metric is not None else is_metric\n        is_internal_dataset_key = series.get(\"isinternaldatasetkey\", None)\n        is_internal_dataset_key = (\n            make_bool(is_internal_dataset_key) if is_internal_dataset_key is not None else is_internal_dataset_key\n        )\n        is_externally_visible = series.get(\"isexternallyvisible\", True)\n        is_externally_visible = (\n            make_bool(is_externally_visible) if is_externally_visible is not None else is_externally_visible\n        )\n\n        return cls(\n            identifier=series.get(\"identifier\", \"\").strip(),\n            index=series.get(\"index\", -1),\n            data_type=Types[data_type.strip().split(\".\")[-1].title()],\n            title=series.get(\"title\", \"\"),\n            description=series.get(\"description\", \"\"),\n            is_dataset_key=series.get(\"isdatasetkey\", False),\n            source=source,\n            source_field_id=series.get(\"sourcefieldid\", None),\n            is_internal_dataset_key=is_internal_dataset_key,\n            is_externally_visible=is_externally_visible,\n            unit=series.get(\"unit\", None),\n            multiplier=series.get(\"multiplier\", 1.0),\n            is_propagation_eligible=is_propagation_eligible,\n            is_metric=is_metric,\n            available_from=series.get(\"availablefrom\", None),\n            deprecated_from=series.get(\"deprecatedfrom\", None),\n            term=series.get(\"term\", \"bizterm1\"),\n            dataset=series.get(\"dataset\", None),\n            attribute_type=series.get(\"attributetype\", None),\n        )\n\n    @classmethod\n    def _from_dict(cls: type[Attribute], data: dict[str, Any]) -&gt; Attribute:\n        \"\"\"Instantiate an Attribute object from a dictionary.\n\n        Args:\n            data (dict[str, Any]): Attribute metadata as a dictionary.\n\n        Returns:\n            Attribute: Attribute object.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; data = {\n            ...     \"identifier\": \"my_attribute\",\n            ...     \"index\": 0,\n            ...     \"data_type\": \"String\",\n            ...     \"title\": \"My Attribute\",\n            ...     \"description\": \"My attribute description\"\n            ... }\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)._from_dict(data)\n\n        \"\"\"\n        keys = [f.name for f in fields(cls)]\n        data = {camel_to_snake(k): v for k, v in data.items()}\n        data = {k: (None if pd.isna(v) else v) for k, v in data.items() if k in keys}\n        if \"data_type\" in data:\n            data[\"data_type\"] = Types[data[\"data_type\"].strip().rsplit(\".\", maxsplit=1)[-1].title()]\n        return cls(**data)\n\n    def from_object(\n        self,\n        attribute_source: Attribute | dict[str, Any] | pd.Series[Any],\n    ) -&gt; Attribute:\n        \"\"\"Instatiate an Attribute from an Attribute object, dictionary or pandas Series.\n\n        Args:\n            attribute_source (Attribute | dict[str, Any] | pd.Series[Any]): Attribute metadata source.\n\n        Raises:\n            TypeError: If the object provided is not an Attribute object, dictionary or pandas Series.\n\n        Returns:\n            Attribute: Attribute object.\n\n        Examples:\n\n            Instatiating a Attribute from a dictionary:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; data = {\n            ...     \"identifier\": \"my_attribute\",\n            ...     \"index\": 0,\n            ...     \"data_type\": \"String\",\n            ...     \"title\": \"My Attribute\",\n            ...     \"description\": \"My attribute description\"\n            ... }\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(data)\n\n            Instatiating a Attribute from a pandas Series:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; series = pd.Series({\n            ...     \"identifier\": \"my_attribute\",\n            ...     \"index\": 0,\n            ...     \"data_type\": \"String\",\n            ...     \"title\": \"My Attribute\",\n            ...     \"description\": \"My attribute description\"\n            ... })\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(series)\n\n        \"\"\"\n        if isinstance(attribute_source, Attribute):\n            attribute = attribute_source\n        elif isinstance(attribute_source, dict):\n            attribute = self._from_dict(attribute_source)\n        elif isinstance(attribute_source, pd.Series):\n            attribute = self._from_series(attribute_source)\n        else:\n            raise ValueError(f\"Could not resolve the object provided: {attribute_source}\")\n        attribute.client = self._client\n        return attribute\n\n    def to_dict(self: Attribute) -&gt; dict[str, Any]:\n        \"\"\"Convert object to dictionary.\n\n        Returns:\n            dict[str, Any]: Attribute metadata as a dictionary.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attribute_dict = attribute.to_dict()\n\n        \"\"\"\n        result = {snake_to_camel(k): v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n        result[\"unit\"] = str(self.unit) if self.unit is not None else None\n        result[\"dataType\"] = self.data_type.name\n        if \"isKeyDataElement\" in result:\n            result[\"isCriticalDataElement\"] = result.pop(\"isKeyDataElement\")\n        return result\n\n    def create(\n        self,\n        dataset: str,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Upload a new attribute to a Fusion catalog.\n\n        Args:\n            dataset (str): Dataset identifier.\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            Individually, from scratch:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute0 = fusion.attribute(identifier=\"my_attribute_0\", index=0)\n            &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n            &gt;&gt;&gt; attribute1 = fusion.attribute(identifier=\"my_attribute_1\", index=1)\n            &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n            Individually, from a dictionary:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; data = {\n            ...     \"identifier\": \"my_attribute\",\n            ...     \"index\": 0,\n            ...     \"data_type\": \"String\",\n            ...     \"title\": \"My Attribute\",\n            ...     \"description\": \"My attribute description\"\n            ...    }\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(data)\n            &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n            Individually, from a pandas Series:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; series = pd.Series({\n            ...     \"identifier\": \"my_attribute\",\n            ...     \"index\": 0,\n            ...     \"data_type\": \"String\",\n            ...     \"title\": \"My Attribute\",\n            ...     \"description\": \"My attribute description\"\n            ... })\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(series)\n            &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        data = self.to_dict()\n        url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes/{self.identifier}\"\n        resp = client.session.put(url, json=data)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def delete(\n        self,\n        dataset: str,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Delete an Attribute from a Fusion catalog.\n\n        Args:\n            dataset (str): Dataset identifier.\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; fusion.attribute(identifier=\"my_attribute\", index=0).delete(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes/{self.identifier}\"\n        resp = client.session.delete(url)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n\n    def set_lineage(\n        self,\n        attributes: list[Attribute],\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Map an attribute to existing registered attributes in a Fusion catalog. Attributes from an output data flow\n            can be mapped to existing registered input data flow attributes. This supports the case in which the\n            generating application and receiving application store their attributes with different names.\n\n        Args:\n            attributes (str): List of Attribute objects to establish upstream lineage from.\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; my_attr1 = fusion.attribute(identifier=\"my_attribute1\", index=0, application_id=\"12345\")\n            &gt;&gt;&gt; my_attr2 = fusion.attribute(identifier=\"my_attribute2\", index=0, application_id=\"12345\")\n            &gt;&gt;&gt; my_attr3 = fusion.attribute(identifier=\"my_attribute3\", index=0, application_id=\"12345\")\n            &gt;&gt;&gt; attrs = [my_attr1, my_attr2]\n            &gt;&gt;&gt; my_attr3.set_lineage(attributes=attrs, catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n\n        if self.application_id is None:\n            raise ValueError(\"The 'application_id' attribute is required for setting lineage.\")\n        target_attributes = []\n        for attribute in attributes:\n            if attribute.application_id is None:\n                raise ValueError(f\"The 'application_id' attribute is required for setting lineage.\")\n            attr_dict = {\n                \"catalog\": catalog,\n                \"attribute\": attribute.identifier,\n                \"applicationId\": attribute.application_id,\n            }\n            target_attributes.append(attr_dict)\n\n        url = f\"{client.root_url}catalogs/{catalog}/attributes/lineage\"\n        data = [\n            {\n                \"source\": {\"catalog\": catalog, \"attribute\": self.identifier, \"applicationId\": self.application_id},\n                \"targets\": target_attributes,\n            }\n        ]\n        resp = client.session.post(url, json=data)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.client","title":"<code>client</code>  <code>property</code> <code>writable</code>","text":"<p>Return the client.</p>"},{"location":"api/#fusion.attributes.Attribute.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Format Attribute metadata fields after object initialization.</p> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def __post_init__(self: Attribute) -&gt; None:\n    \"\"\"Format Attribute metadata fields after object initialization.\"\"\"\n    self.is_dataset_key = make_bool(self.is_dataset_key)\n    self.identifier = tidy_string(self.identifier).lower().replace(\" \", \"_\")\n    self.title = tidy_string(self.title) if self.title != \"\" else self.identifier.replace(\"_\", \" \").title()\n    self.description = tidy_string(self.description) if self.description and self.description != \"\" else self.title\n    self.source_field_id = (\n        tidy_string(self.source_field_id).lower().replace(\" \", \"_\") if self.source_field_id else self.identifier\n    )\n    self.available_from = convert_date_format(self.available_from) if self.available_from else None\n    self.deprecated_from = convert_date_format(self.deprecated_from) if self.deprecated_from else None\n    self.data_type = Types[str(self.data_type).strip().rsplit(\".\", maxsplit=1)[-1].title()]\n    self.application_id = (\n        {\"id\": str(self.application_id), \"type\": \"Application (SEAL)\"}\n        if isinstance(self.application_id, str)\n        else self.application_id\n    )\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.__repr__","title":"<code>__repr__()</code>","text":"<p>Format object representation.</p> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def __repr__(self: Attribute) -&gt; str:\n    \"\"\"Format object representation.\"\"\"\n    s = \", \".join(f\"{getattr(self, f.name)!r}\" for f in fields(self) if not f.name.startswith(\"_\"))\n    return \"(\" + s + \")\"\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.__str__","title":"<code>__str__()</code>","text":"<p>Format string representation.</p> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def __str__(self: Attribute) -&gt; str:\n    \"\"\"Format string representation.\"\"\"\n    attrs = {k: v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n    return f\"Attribute(\\n\" + \",\\n \".join(f\"{k}={v!r}\" for k, v in attrs.items()) + \"\\n)\"\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.create","title":"<code>create(dataset, catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Upload a new attribute to a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>Dataset identifier.</p> required <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>Individually, from scratch:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute0 = fusion.attribute(identifier=\"my_attribute_0\", index=0)\n&gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n&gt;&gt;&gt; attribute1 = fusion.attribute(identifier=\"my_attribute_1\", index=1)\n&gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\nIndividually, from a dictionary:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; data = {\n...     \"identifier\": \"my_attribute\",\n...     \"index\": 0,\n...     \"data_type\": \"String\",\n...     \"title\": \"My Attribute\",\n...     \"description\": \"My attribute description\"\n...    }\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(data)\n&gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\nIndividually, from a pandas Series:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; series = pd.Series({\n...     \"identifier\": \"my_attribute\",\n...     \"index\": 0,\n...     \"data_type\": \"String\",\n...     \"title\": \"My Attribute\",\n...     \"description\": \"My attribute description\"\n... })\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(series)\n&gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def create(\n    self,\n    dataset: str,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Upload a new attribute to a Fusion catalog.\n\n    Args:\n        dataset (str): Dataset identifier.\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        Individually, from scratch:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute0 = fusion.attribute(identifier=\"my_attribute_0\", index=0)\n        &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n        &gt;&gt;&gt; attribute1 = fusion.attribute(identifier=\"my_attribute_1\", index=1)\n        &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        Individually, from a dictionary:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; data = {\n        ...     \"identifier\": \"my_attribute\",\n        ...     \"index\": 0,\n        ...     \"data_type\": \"String\",\n        ...     \"title\": \"My Attribute\",\n        ...     \"description\": \"My attribute description\"\n        ...    }\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(data)\n        &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        Individually, from a pandas Series:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; series = pd.Series({\n        ...     \"identifier\": \"my_attribute\",\n        ...     \"index\": 0,\n        ...     \"data_type\": \"String\",\n        ...     \"title\": \"My Attribute\",\n        ...     \"description\": \"My attribute description\"\n        ... })\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(series)\n        &gt;&gt;&gt; attribute.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    data = self.to_dict()\n    url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes/{self.identifier}\"\n    resp = client.session.put(url, json=data)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.delete","title":"<code>delete(dataset, catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Delete an Attribute from a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>Dataset identifier.</p> required <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; fusion.attribute(identifier=\"my_attribute\", index=0).delete(dataset=\"my_dataset\", catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def delete(\n    self,\n    dataset: str,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Delete an Attribute from a Fusion catalog.\n\n    Args:\n        dataset (str): Dataset identifier.\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; fusion.attribute(identifier=\"my_attribute\", index=0).delete(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes/{self.identifier}\"\n    resp = client.session.delete(url)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.from_object","title":"<code>from_object(attribute_source)</code>","text":"<p>Instatiate an Attribute from an Attribute object, dictionary or pandas Series.</p> <p>Parameters:</p> Name Type Description Default <code>attribute_source</code> <code>Attribute | dict[str, Any] | Series[Any]</code> <p>Attribute metadata source.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object provided is not an Attribute object, dictionary or pandas Series.</p> <p>Returns:</p> Name Type Description <code>Attribute</code> <code>Attribute</code> <p>Attribute object.</p> <pre><code>Instatiating a Attribute from a dictionary:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; data = {\n...     \"identifier\": \"my_attribute\",\n...     \"index\": 0,\n...     \"data_type\": \"String\",\n...     \"title\": \"My Attribute\",\n...     \"description\": \"My attribute description\"\n... }\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(data)\n\nInstatiating a Attribute from a pandas Series:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; series = pd.Series({\n...     \"identifier\": \"my_attribute\",\n...     \"index\": 0,\n...     \"data_type\": \"String\",\n...     \"title\": \"My Attribute\",\n...     \"description\": \"My attribute description\"\n... })\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(series)\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def from_object(\n    self,\n    attribute_source: Attribute | dict[str, Any] | pd.Series[Any],\n) -&gt; Attribute:\n    \"\"\"Instatiate an Attribute from an Attribute object, dictionary or pandas Series.\n\n    Args:\n        attribute_source (Attribute | dict[str, Any] | pd.Series[Any]): Attribute metadata source.\n\n    Raises:\n        TypeError: If the object provided is not an Attribute object, dictionary or pandas Series.\n\n    Returns:\n        Attribute: Attribute object.\n\n    Examples:\n\n        Instatiating a Attribute from a dictionary:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; data = {\n        ...     \"identifier\": \"my_attribute\",\n        ...     \"index\": 0,\n        ...     \"data_type\": \"String\",\n        ...     \"title\": \"My Attribute\",\n        ...     \"description\": \"My attribute description\"\n        ... }\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(data)\n\n        Instatiating a Attribute from a pandas Series:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; series = pd.Series({\n        ...     \"identifier\": \"my_attribute\",\n        ...     \"index\": 0,\n        ...     \"data_type\": \"String\",\n        ...     \"title\": \"My Attribute\",\n        ...     \"description\": \"My attribute description\"\n        ... })\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0).from_object(series)\n\n    \"\"\"\n    if isinstance(attribute_source, Attribute):\n        attribute = attribute_source\n    elif isinstance(attribute_source, dict):\n        attribute = self._from_dict(attribute_source)\n    elif isinstance(attribute_source, pd.Series):\n        attribute = self._from_series(attribute_source)\n    else:\n        raise ValueError(f\"Could not resolve the object provided: {attribute_source}\")\n    attribute.client = self._client\n    return attribute\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.set_lineage","title":"<code>set_lineage(attributes, catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Map an attribute to existing registered attributes in a Fusion catalog. Attributes from an output data flow     can be mapped to existing registered input data flow attributes. This supports the case in which the     generating application and receiving application store their attributes with different names.</p> <p>Parameters:</p> Name Type Description Default <code>attributes</code> <code>str</code> <p>List of Attribute objects to establish upstream lineage from.</p> required <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; my_attr1 = fusion.attribute(identifier=\"my_attribute1\", index=0, application_id=\"12345\")\n&gt;&gt;&gt; my_attr2 = fusion.attribute(identifier=\"my_attribute2\", index=0, application_id=\"12345\")\n&gt;&gt;&gt; my_attr3 = fusion.attribute(identifier=\"my_attribute3\", index=0, application_id=\"12345\")\n&gt;&gt;&gt; attrs = [my_attr1, my_attr2]\n&gt;&gt;&gt; my_attr3.set_lineage(attributes=attrs, catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def set_lineage(\n    self,\n    attributes: list[Attribute],\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Map an attribute to existing registered attributes in a Fusion catalog. Attributes from an output data flow\n        can be mapped to existing registered input data flow attributes. This supports the case in which the\n        generating application and receiving application store their attributes with different names.\n\n    Args:\n        attributes (str): List of Attribute objects to establish upstream lineage from.\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; my_attr1 = fusion.attribute(identifier=\"my_attribute1\", index=0, application_id=\"12345\")\n        &gt;&gt;&gt; my_attr2 = fusion.attribute(identifier=\"my_attribute2\", index=0, application_id=\"12345\")\n        &gt;&gt;&gt; my_attr3 = fusion.attribute(identifier=\"my_attribute3\", index=0, application_id=\"12345\")\n        &gt;&gt;&gt; attrs = [my_attr1, my_attr2]\n        &gt;&gt;&gt; my_attr3.set_lineage(attributes=attrs, catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n\n    if self.application_id is None:\n        raise ValueError(\"The 'application_id' attribute is required for setting lineage.\")\n    target_attributes = []\n    for attribute in attributes:\n        if attribute.application_id is None:\n            raise ValueError(f\"The 'application_id' attribute is required for setting lineage.\")\n        attr_dict = {\n            \"catalog\": catalog,\n            \"attribute\": attribute.identifier,\n            \"applicationId\": attribute.application_id,\n        }\n        target_attributes.append(attr_dict)\n\n    url = f\"{client.root_url}catalogs/{catalog}/attributes/lineage\"\n    data = [\n        {\n            \"source\": {\"catalog\": catalog, \"attribute\": self.identifier, \"applicationId\": self.application_id},\n            \"targets\": target_attributes,\n        }\n    ]\n    resp = client.session.post(url, json=data)\n    requests_raise_for_status(resp)\n    return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attribute.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert object to dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Attribute metadata as a dictionary.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n&gt;&gt;&gt; attribute_dict = attribute.to_dict()\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def to_dict(self: Attribute) -&gt; dict[str, Any]:\n    \"\"\"Convert object to dictionary.\n\n    Returns:\n        dict[str, Any]: Attribute metadata as a dictionary.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n        &gt;&gt;&gt; attribute_dict = attribute.to_dict()\n\n    \"\"\"\n    result = {snake_to_camel(k): v for k, v in self.__dict__.items() if not k.startswith(\"_\")}\n    result[\"unit\"] = str(self.unit) if self.unit is not None else None\n    result[\"dataType\"] = self.data_type.name\n    if \"isKeyDataElement\" in result:\n        result[\"isCriticalDataElement\"] = result.pop(\"isKeyDataElement\")\n    return result\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes","title":"<code>Attributes</code>  <code>dataclass</code>","text":"<p>Class representing a collection of Attribute instances for managing atrribute metadata in a Fusion catalog.</p> <p>Attributes:</p> Name Type Description <code>attributes</code> <code>list[Attribute]</code> <p>List of Attribute instances.</p> <code>_client</code> <code>Fusion | None</code> <p>Fusion client object.</p> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>@dataclass\nclass Attributes:\n    \"\"\"Class representing a collection of Attribute instances for managing atrribute metadata in a Fusion catalog.\n\n    Attributes:\n        attributes (list[Attribute]): List of Attribute instances.\n        _client (Fusion | None): Fusion client object.\n\n    \"\"\"\n\n    attributes: list[Attribute] = field(default_factory=list)\n\n    _client: Fusion | None = None\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the Attributes collection.\"\"\"\n        return (\n            f\"[\\n\" + \",\\n \".join(f\"{attr.__repr__()}\" for attr in self.attributes) + \"\\n]\" if self.attributes else \"[]\"\n        )\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Object representation of the Attributes collection.\"\"\"\n        return self.__str__()\n\n    @property\n    def client(self) -&gt; Fusion | None:\n        \"\"\"Return the client.\"\"\"\n        return self._client\n\n    @client.setter\n    def client(self, client: Fusion | None) -&gt; None:\n        \"\"\"Set the client for the Dataset. Set automatically, if the Dataset is instantiated from a Fusion object.\n\n        Args:\n            client (Any): Fusion client object.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attributes = fusion.attributes()\n            &gt;&gt;&gt; attributes.client = fusion\n\n        \"\"\"\n        self._client = client\n\n    def _use_client(self, client: Fusion | None) -&gt; Fusion:\n        \"\"\"Determine client.\"\"\"\n\n        res = self._client if client is None else client\n        if res is None:\n            raise ValueError(\"A Fusion client object is required.\")\n        return res\n\n    def add_attribute(self, attribute: Attribute) -&gt; None:\n        \"\"\"Add an Attribute instance to the collection.\n\n        Args:\n            attribute (Attribute): Attribute instance to add.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attributes = fusion.attributes()\n            &gt;&gt;&gt; attributes.add_attribute(attribute)\n\n        \"\"\"\n        self.attributes.append(attribute)\n\n    def remove_attribute(self, identifier: str) -&gt; bool:\n        \"\"\"Remove an Attribute instance from the collection by identifier.\n\n        Args:\n            identifier (str): Identifier of the Attribute to remove.\n\n        Returns:\n            bool: True if the Attribute was removed, False otherwise.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n            &gt;&gt;&gt; attributes.remove_attribute(\"my_attribute\")\n\n        \"\"\"\n        for attr in self.attributes:\n            if attr.identifier == identifier:\n                self.attributes.remove(attr)\n                return True\n        return False\n\n    def get_attribute(self, identifier: str) -&gt; Attribute | None:\n        \"\"\"Get an Attribute instance from the collection by identifier.\n\n        Args:\n            identifier (str): Identifier of the Attribute to retrieve.\n\n        Returns:\n            Attribute | None: The Attribute instance if found, None otherwise.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attributes =fusion.attributes(attributes=[attribute])\n            &gt;&gt;&gt; retrieved_attribute = attributes.get_attribute(\"my_attribute\")\n\n        \"\"\"\n        for attr in self.attributes:\n            if attr.identifier == identifier:\n                return attr\n        return None\n\n    def to_dict(self) -&gt; dict[str, list[dict[str, Any]]]:\n        \"\"\"Convert the collection of Attribute instances to a list of dictionaries.\n\n        Returns:\n            dict[str, list[dict[str, Any]]]: Collection of Attribute instances as a dictionary.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n            &gt;&gt;&gt; attributes_dict = attributes.to_dict()\n\n        \"\"\"\n        dict_out = {\"attributes\": [attr.to_dict() for attr in self.attributes]}\n        return dict_out\n\n    @classmethod\n    def _from_dict_list(cls: type[Attributes], data: list[dict[str, Any]]) -&gt; Attributes:\n        \"\"\"Create an Attributes instance from a list of dictionaries.\n\n        Args:\n            data (list[dict[str, Any]]): List of dictionaries representing Attribute instances.\n\n        Returns:\n            Attributes: Attributes instance.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; data = [\n            ...     {\n            ...         \"identifier\": \"my_attribute\",\n            ...         \"index\": 0,\n            ...         \"data_type\": \"String\",\n            ...         \"title\": \"My Attribute\",\n            ...         \"description\": \"My attribute description\"\n            ...     }\n            ... ]\n            &gt;&gt;&gt; attributes = fusion.attributes()._from_dict_list(data)\n\n        \"\"\"\n        attributes = [Attribute._from_dict(attr_data) for attr_data in data]\n        return Attributes(attributes=attributes)\n\n    @classmethod\n    def _from_dataframe(cls: type[Attributes], data: pd.DataFrame) -&gt; Attributes:\n        \"\"\"Create an Attributes instance from a pandas DataFrame.\n\n        Args:\n            data (pd.DataFrame): DataFrame representing Attribute instances.\n\n        Returns:\n            Attributes: Attributes instance.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; data = pd.DataFrame([\n            ...     {\n            ...         \"identifier\": \"my_attribute\",\n            ...         \"index\": 0,\n            ...         \"data_type\": \"String\",\n            ...         \"title\": \"My Attribute\",\n            ...         \"description\": \"My attribute description\"\n            ...     }\n            ... ])\n            &gt;&gt;&gt; attributes = fusion.attributes()._from_dataframe(data)\n\n        \"\"\"\n        data = data.replace(to_replace=np.nan, value=None)\n        data = data.reset_index() if \"index\" not in data.columns else data\n        attributes = [Attribute._from_series(series) for _, series in data.iterrows()]\n        return Attributes(attributes=attributes)\n\n    def from_object(\n        self,\n        attributes_source: list[Attribute] | list[dict[str, Any]] | pd.DataFrame,\n    ) -&gt; Attributes:\n        \"\"\"Instantiate an Attributes object from a list of Attribute objects, dictionaries or pandas DataFrame.\n\n        Args:\n            attributes_source (list[Attribute] | list[dict[str, Any]] | pd.DataFrame): Attributes metadata source.\n\n        Raises:\n            TypeError: If the object provided is not a list of Attribute objects, dictionaries or pandas DataFrame.\n\n        Returns:\n            Attributes: Attributes object.\n\n        Examples:\n\n            Instatiating Attributes from a list of dictionaries:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; data = [\n            ...     {\n            ...         \"identifier\": \"my_attribute\",\n            ...         \"index\": 0,\n            ...         \"data_type\": \"String\",\n            ...         \"title\": \"My Attribute\",\n            ...         \"description\": \"My attribute description\"\n            ...     }\n            ... ]\n            &gt;&gt;&gt; attributes = fusion.attributes().from_object(data)\n\n            Instatiating Attributes from a pandas DataFrame:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; data = pd.DataFrame([\n            ...     {\n            ...         \"identifier\": \"my_attribute\",\n            ...         \"index\": 0,\n            ...         \"data_type\": \"String\",\n            ...         \"title\": \"My Attribute\",\n            ...         \"description\": \"My attribute description\"\n            ...     }\n            ... ])\n            &gt;&gt;&gt; attributes = fusion.attributes().from_object(data)\n\n        \"\"\"\n        if isinstance(attributes_source, list):\n            if all(isinstance(attr, Attribute) for attr in attributes_source):\n                attributes = Attributes(cast(list[Attribute], attributes_source))\n            elif all(isinstance(attr, dict) for attr in attributes_source):\n                attributes = Attributes._from_dict_list(cast(list[dict[str, Any]], attributes_source))\n        elif isinstance(attributes_source, pd.DataFrame):\n            attributes = Attributes._from_dataframe(attributes_source)\n        else:\n            raise ValueError(f\"Could not resolve the object provided: {attributes_source}\")\n        attributes.client = self._client\n        return attributes\n\n    def to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Convert the collection of Attribute instances to a pandas DataFrame.\n\n        Returns:\n            pd.DataFrame: DataFrame representing the collection of Attribute instances.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n            &gt;&gt;&gt; attributes_df = attributes.to_dataframe()\n\n        \"\"\"\n        if len(self.attributes) == 0:\n            self.attributes = [Attribute(identifier=\"example_attribute\", index=0)]\n        data = [attr.to_dict() for attr in self.attributes]\n        return pd.DataFrame(data)\n\n    def from_catalog(self, dataset: str, catalog: str | None = None, client: Fusion | None = None) -&gt; Attributes:\n        \"\"\"Instatiate an Attributes object from a dataset's attributes in a Fusion catalog.\n\n        Args:\n            dataset (str): The dataset identifier.\n            catalog (str | None, optional): The catalog identifier. Defaults to None.\n            client (Fusion | None, optional): Fusion session. Defaults to None.\n                If instantiated from a Fusion object, then the client is set automatically.\n\n        Returns:\n            Attributes: An instance of the Attributes class with the attributes from the catalog.\n\n        Examples:\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes\"\n        response = client.session.get(url)\n        requests_raise_for_status(response)\n        list_attributes = response.json()[\"resources\"]\n        list_attributes = sorted(list_attributes, key=lambda x: x[\"index\"])\n\n        self.attributes = [Attribute._from_dict(attr_data) for attr_data in list_attributes]\n        return self\n\n    def create(\n        self,\n        dataset: str | None = None,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; requests.Response | None:\n        \"\"\"Upload the Attributes to a dataset in a Fusion catalog. If no dataset is provided,\n            attributes are registered to the catalog.\n\n        Args:\n            dataset (str): Dataset identifier.\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n                If instantiated from a Fusion object, then the client is set automatically.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n        Examples:\n\n            From scratch:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n            &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n            &gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n            From a list of dictionaries:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; data = [\n            ...     {\n            ...         \"identifier\": \"my_attribute\",\n            ...         \"index\": 0,\n            ...         \"data_type\": \"String\",\n            ...         \"title\": \"My Attribute\",\n            ...         \"description\": \"My attribute description\"\n            ...     }\n            ... ]\n            &gt;&gt;&gt; attributes = fusion.attributes().from_dict_list(data)\n            &gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n            From a pandas DataFrame:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; data = pd.DataFrame([\n            ...     {\n            ...         \"identifier\": \"my_attribute\",\n            ...         \"index\": 0,\n            ...         \"data_type\": \"String\",\n            ...         \"title\": \"My Attribute\",\n            ...         \"description\": \"My attribute description\"\n            ...     }\n            ... ])\n            &gt;&gt;&gt; attributes = fusion.attributes().from_dataframe(data)\n            &gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n            From existing dataset's attributes in a Fusion catalog:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n            &gt;&gt;&gt; attributes.create(dataset=\"my_new_dataset\", catalog=\"my_catalog\")\n\n            Register attributes to a catalog:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0, application_id=\"123\", publisher=\"JPM\")\n            &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n            &gt;&gt;&gt; attributes.create(catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        data = self.to_dict()\n        if dataset:\n            url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes\"\n            resp = client.session.put(url, json=data)\n            requests_raise_for_status(resp)\n            return resp if return_resp_obj else None\n        else:\n            for attr in self.attributes:\n                if attr.publisher is None:\n                    raise ValueError(\"The 'publisher' attribute is required for catalog attributes.\")\n                if attr.application_id is None:\n                    raise ValueError(\"The 'application_id' attribute is required for catalog attributes.\")\n            url = f\"{client.root_url}catalogs/{catalog}/attributes\"\n            data_ = data.get(\"attributes\", None)\n            resp = client.session.post(url, json=data_)\n            requests_raise_for_status(resp)\n            return resp if return_resp_obj else None\n\n    def delete(\n        self,\n        dataset: str,\n        catalog: str | None = None,\n        client: Fusion | None = None,\n        return_resp_obj: bool = False,\n    ) -&gt; list[requests.Response] | None:\n        \"\"\"Delete the Attributes from a Fusion catalog.\n\n        Args:\n            dataset (str): Dataset identifier.\n            client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            catalog (str, optional): A catalog identifier. Defaults to None.\n            return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n        Returns:\n            list[requests.Response] | None: List of response objects from the API calls if return_resp_obj is True,\n                otherwise None.\n\n        Examples:\n\n            &gt;&gt;&gt; from fusion import Fusion\n            &gt;&gt;&gt; fusion = Fusion()\n            &gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n            &gt;&gt;&gt; attributes.delete(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        \"\"\"\n        client = self._use_client(client)\n        catalog = client._use_catalog(catalog)\n        responses = []\n        for attr in self.attributes:\n            resp = client.session.delete(\n                f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes/{attr.identifier}\"\n            )\n            requests_raise_for_status(resp)\n            responses.append(resp)\n\n        return responses if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.client","title":"<code>client</code>  <code>property</code> <code>writable</code>","text":"<p>Return the client.</p>"},{"location":"api/#fusion.attributes.Attributes.__repr__","title":"<code>__repr__()</code>","text":"<p>Object representation of the Attributes collection.</p> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Object representation of the Attributes collection.\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the Attributes collection.</p> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the Attributes collection.\"\"\"\n    return (\n        f\"[\\n\" + \",\\n \".join(f\"{attr.__repr__()}\" for attr in self.attributes) + \"\\n]\" if self.attributes else \"[]\"\n    )\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.add_attribute","title":"<code>add_attribute(attribute)</code>","text":"<p>Add an Attribute instance to the collection.</p> <p>Parameters:</p> Name Type Description Default <code>attribute</code> <code>Attribute</code> <p>Attribute instance to add.</p> required <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n&gt;&gt;&gt; attributes = fusion.attributes()\n&gt;&gt;&gt; attributes.add_attribute(attribute)\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def add_attribute(self, attribute: Attribute) -&gt; None:\n    \"\"\"Add an Attribute instance to the collection.\n\n    Args:\n        attribute (Attribute): Attribute instance to add.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n        &gt;&gt;&gt; attributes = fusion.attributes()\n        &gt;&gt;&gt; attributes.add_attribute(attribute)\n\n    \"\"\"\n    self.attributes.append(attribute)\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.create","title":"<code>create(dataset=None, catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Upload the Attributes to a dataset in a Fusion catalog. If no dataset is provided,     attributes are registered to the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>Dataset identifier.</p> <code>None</code> <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Response | None</code> <p>requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.</p> <pre><code>From scratch:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n&gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n&gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\nFrom a list of dictionaries:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; data = [\n...     {\n...         \"identifier\": \"my_attribute\",\n...         \"index\": 0,\n...         \"data_type\": \"String\",\n...         \"title\": \"My Attribute\",\n...         \"description\": \"My attribute description\"\n...     }\n... ]\n&gt;&gt;&gt; attributes = fusion.attributes().from_dict_list(data)\n&gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\nFrom a pandas DataFrame:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; data = pd.DataFrame([\n...     {\n...         \"identifier\": \"my_attribute\",\n...         \"index\": 0,\n...         \"data_type\": \"String\",\n...         \"title\": \"My Attribute\",\n...         \"description\": \"My attribute description\"\n...     }\n... ])\n&gt;&gt;&gt; attributes = fusion.attributes().from_dataframe(data)\n&gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\nFrom existing dataset's attributes in a Fusion catalog:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n&gt;&gt;&gt; attributes.create(dataset=\"my_new_dataset\", catalog=\"my_catalog\")\n\nRegister attributes to a catalog:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0, application_id=\"123\", publisher=\"JPM\")\n&gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n&gt;&gt;&gt; attributes.create(catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def create(\n    self,\n    dataset: str | None = None,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; requests.Response | None:\n    \"\"\"Upload the Attributes to a dataset in a Fusion catalog. If no dataset is provided,\n        attributes are registered to the catalog.\n\n    Args:\n        dataset (str): Dataset identifier.\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n            If instantiated from a Fusion object, then the client is set automatically.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        requests.Response | None: The response object from the API call if return_resp_obj is True, otherwise None.\n\n    Examples:\n\n        From scratch:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n        &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n        &gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        From a list of dictionaries:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; data = [\n        ...     {\n        ...         \"identifier\": \"my_attribute\",\n        ...         \"index\": 0,\n        ...         \"data_type\": \"String\",\n        ...         \"title\": \"My Attribute\",\n        ...         \"description\": \"My attribute description\"\n        ...     }\n        ... ]\n        &gt;&gt;&gt; attributes = fusion.attributes().from_dict_list(data)\n        &gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        From a pandas DataFrame:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     {\n        ...         \"identifier\": \"my_attribute\",\n        ...         \"index\": 0,\n        ...         \"data_type\": \"String\",\n        ...         \"title\": \"My Attribute\",\n        ...         \"description\": \"My attribute description\"\n        ...     }\n        ... ])\n        &gt;&gt;&gt; attributes = fusion.attributes().from_dataframe(data)\n        &gt;&gt;&gt; attributes.create(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n        From existing dataset's attributes in a Fusion catalog:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n        &gt;&gt;&gt; attributes.create(dataset=\"my_new_dataset\", catalog=\"my_catalog\")\n\n        Register attributes to a catalog:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0, application_id=\"123\", publisher=\"JPM\")\n        &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n        &gt;&gt;&gt; attributes.create(catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    data = self.to_dict()\n    if dataset:\n        url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes\"\n        resp = client.session.put(url, json=data)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n    else:\n        for attr in self.attributes:\n            if attr.publisher is None:\n                raise ValueError(\"The 'publisher' attribute is required for catalog attributes.\")\n            if attr.application_id is None:\n                raise ValueError(\"The 'application_id' attribute is required for catalog attributes.\")\n        url = f\"{client.root_url}catalogs/{catalog}/attributes\"\n        data_ = data.get(\"attributes\", None)\n        resp = client.session.post(url, json=data_)\n        requests_raise_for_status(resp)\n        return resp if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.delete","title":"<code>delete(dataset, catalog=None, client=None, return_resp_obj=False)</code>","text":"<p>Delete the Attributes from a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>Dataset identifier.</p> required <code>client</code> <code>Fusion</code> <p>A Fusion client object. Defaults to the instance's _client.</p> <code>None</code> <code>catalog</code> <code>str</code> <p>A catalog identifier. Defaults to None.</p> <code>None</code> <code>return_resp_obj</code> <code>bool</code> <p>If True then return the response object. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[Response] | None</code> <p>list[requests.Response] | None: List of response objects from the API calls if return_resp_obj is True, otherwise None.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n&gt;&gt;&gt; attributes.delete(dataset=\"my_dataset\", catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def delete(\n    self,\n    dataset: str,\n    catalog: str | None = None,\n    client: Fusion | None = None,\n    return_resp_obj: bool = False,\n) -&gt; list[requests.Response] | None:\n    \"\"\"Delete the Attributes from a Fusion catalog.\n\n    Args:\n        dataset (str): Dataset identifier.\n        client (Fusion, optional): A Fusion client object. Defaults to the instance's _client.\n        catalog (str, optional): A catalog identifier. Defaults to None.\n        return_resp_obj (bool, optional): If True then return the response object. Defaults to False.\n\n    Returns:\n        list[requests.Response] | None: List of response objects from the API calls if return_resp_obj is True,\n            otherwise None.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n        &gt;&gt;&gt; attributes.delete(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    responses = []\n    for attr in self.attributes:\n        resp = client.session.delete(\n            f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes/{attr.identifier}\"\n        )\n        requests_raise_for_status(resp)\n        responses.append(resp)\n\n    return responses if return_resp_obj else None\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.from_catalog","title":"<code>from_catalog(dataset, catalog=None, client=None)</code>","text":"<p>Instatiate an Attributes object from a dataset's attributes in a Fusion catalog.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>The dataset identifier.</p> required <code>catalog</code> <code>str | None</code> <p>The catalog identifier. Defaults to None.</p> <code>None</code> <code>client</code> <code>Fusion | None</code> <p>Fusion session. Defaults to None. If instantiated from a Fusion object, then the client is set automatically.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Attributes</code> <code>Attributes</code> <p>An instance of the Attributes class with the attributes from the catalog.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def from_catalog(self, dataset: str, catalog: str | None = None, client: Fusion | None = None) -&gt; Attributes:\n    \"\"\"Instatiate an Attributes object from a dataset's attributes in a Fusion catalog.\n\n    Args:\n        dataset (str): The dataset identifier.\n        catalog (str | None, optional): The catalog identifier. Defaults to None.\n        client (Fusion | None, optional): Fusion session. Defaults to None.\n            If instantiated from a Fusion object, then the client is set automatically.\n\n    Returns:\n        Attributes: An instance of the Attributes class with the attributes from the catalog.\n\n    Examples:\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attributes = fusion.attributes().from_catalog(dataset=\"my_dataset\", catalog=\"my_catalog\")\n\n    \"\"\"\n    client = self._use_client(client)\n    catalog = client._use_catalog(catalog)\n    url = f\"{client.root_url}catalogs/{catalog}/datasets/{dataset}/attributes\"\n    response = client.session.get(url)\n    requests_raise_for_status(response)\n    list_attributes = response.json()[\"resources\"]\n    list_attributes = sorted(list_attributes, key=lambda x: x[\"index\"])\n\n    self.attributes = [Attribute._from_dict(attr_data) for attr_data in list_attributes]\n    return self\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.from_object","title":"<code>from_object(attributes_source)</code>","text":"<p>Instantiate an Attributes object from a list of Attribute objects, dictionaries or pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>attributes_source</code> <code>list[Attribute] | list[dict[str, Any]] | DataFrame</code> <p>Attributes metadata source.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object provided is not a list of Attribute objects, dictionaries or pandas DataFrame.</p> <p>Returns:</p> Name Type Description <code>Attributes</code> <code>Attributes</code> <p>Attributes object.</p> <pre><code>Instatiating Attributes from a list of dictionaries:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; data = [\n...     {\n...         \"identifier\": \"my_attribute\",\n...         \"index\": 0,\n...         \"data_type\": \"String\",\n...         \"title\": \"My Attribute\",\n...         \"description\": \"My attribute description\"\n...     }\n... ]\n&gt;&gt;&gt; attributes = fusion.attributes().from_object(data)\n\nInstatiating Attributes from a pandas DataFrame:\n\n&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; data = pd.DataFrame([\n...     {\n...         \"identifier\": \"my_attribute\",\n...         \"index\": 0,\n...         \"data_type\": \"String\",\n...         \"title\": \"My Attribute\",\n...         \"description\": \"My attribute description\"\n...     }\n... ])\n&gt;&gt;&gt; attributes = fusion.attributes().from_object(data)\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def from_object(\n    self,\n    attributes_source: list[Attribute] | list[dict[str, Any]] | pd.DataFrame,\n) -&gt; Attributes:\n    \"\"\"Instantiate an Attributes object from a list of Attribute objects, dictionaries or pandas DataFrame.\n\n    Args:\n        attributes_source (list[Attribute] | list[dict[str, Any]] | pd.DataFrame): Attributes metadata source.\n\n    Raises:\n        TypeError: If the object provided is not a list of Attribute objects, dictionaries or pandas DataFrame.\n\n    Returns:\n        Attributes: Attributes object.\n\n    Examples:\n\n        Instatiating Attributes from a list of dictionaries:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; data = [\n        ...     {\n        ...         \"identifier\": \"my_attribute\",\n        ...         \"index\": 0,\n        ...         \"data_type\": \"String\",\n        ...         \"title\": \"My Attribute\",\n        ...         \"description\": \"My attribute description\"\n        ...     }\n        ... ]\n        &gt;&gt;&gt; attributes = fusion.attributes().from_object(data)\n\n        Instatiating Attributes from a pandas DataFrame:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; data = pd.DataFrame([\n        ...     {\n        ...         \"identifier\": \"my_attribute\",\n        ...         \"index\": 0,\n        ...         \"data_type\": \"String\",\n        ...         \"title\": \"My Attribute\",\n        ...         \"description\": \"My attribute description\"\n        ...     }\n        ... ])\n        &gt;&gt;&gt; attributes = fusion.attributes().from_object(data)\n\n    \"\"\"\n    if isinstance(attributes_source, list):\n        if all(isinstance(attr, Attribute) for attr in attributes_source):\n            attributes = Attributes(cast(list[Attribute], attributes_source))\n        elif all(isinstance(attr, dict) for attr in attributes_source):\n            attributes = Attributes._from_dict_list(cast(list[dict[str, Any]], attributes_source))\n    elif isinstance(attributes_source, pd.DataFrame):\n        attributes = Attributes._from_dataframe(attributes_source)\n    else:\n        raise ValueError(f\"Could not resolve the object provided: {attributes_source}\")\n    attributes.client = self._client\n    return attributes\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.get_attribute","title":"<code>get_attribute(identifier)</code>","text":"<p>Get an Attribute instance from the collection by identifier.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Identifier of the Attribute to retrieve.</p> required <p>Returns:</p> Type Description <code>Attribute | None</code> <p>Attribute | None: The Attribute instance if found, None otherwise.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n&gt;&gt;&gt; attributes =fusion.attributes(attributes=[attribute])\n&gt;&gt;&gt; retrieved_attribute = attributes.get_attribute(\"my_attribute\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def get_attribute(self, identifier: str) -&gt; Attribute | None:\n    \"\"\"Get an Attribute instance from the collection by identifier.\n\n    Args:\n        identifier (str): Identifier of the Attribute to retrieve.\n\n    Returns:\n        Attribute | None: The Attribute instance if found, None otherwise.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n        &gt;&gt;&gt; attributes =fusion.attributes(attributes=[attribute])\n        &gt;&gt;&gt; retrieved_attribute = attributes.get_attribute(\"my_attribute\")\n\n    \"\"\"\n    for attr in self.attributes:\n        if attr.identifier == identifier:\n            return attr\n    return None\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.remove_attribute","title":"<code>remove_attribute(identifier)</code>","text":"<p>Remove an Attribute instance from the collection by identifier.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Identifier of the Attribute to remove.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the Attribute was removed, False otherwise.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n&gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n&gt;&gt;&gt; attributes.remove_attribute(\"my_attribute\")\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def remove_attribute(self, identifier: str) -&gt; bool:\n    \"\"\"Remove an Attribute instance from the collection by identifier.\n\n    Args:\n        identifier (str): Identifier of the Attribute to remove.\n\n    Returns:\n        bool: True if the Attribute was removed, False otherwise.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n        &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n        &gt;&gt;&gt; attributes.remove_attribute(\"my_attribute\")\n\n    \"\"\"\n    for attr in self.attributes:\n        if attr.identifier == identifier:\n            self.attributes.remove(attr)\n            return True\n    return False\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert the collection of Attribute instances to a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame representing the collection of Attribute instances.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n&gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n&gt;&gt;&gt; attributes_df = attributes.to_dataframe()\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the collection of Attribute instances to a pandas DataFrame.\n\n    Returns:\n        pd.DataFrame: DataFrame representing the collection of Attribute instances.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n        &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n        &gt;&gt;&gt; attributes_df = attributes.to_dataframe()\n\n    \"\"\"\n    if len(self.attributes) == 0:\n        self.attributes = [Attribute(identifier=\"example_attribute\", index=0)]\n    data = [attr.to_dict() for attr in self.attributes]\n    return pd.DataFrame(data)\n</code></pre>"},{"location":"api/#fusion.attributes.Attributes.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the collection of Attribute instances to a list of dictionaries.</p> <p>Returns:</p> Type Description <code>dict[str, list[dict[str, Any]]]</code> <p>dict[str, list[dict[str, Any]]]: Collection of Attribute instances as a dictionary.</p> <pre><code>&gt;&gt;&gt; from fusion import Fusion\n&gt;&gt;&gt; fusion = Fusion()\n&gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n&gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n&gt;&gt;&gt; attributes_dict = attributes.to_dict()\n</code></pre> Source code in <code>py_src/fusion/attributes.py</code> <pre><code>def to_dict(self) -&gt; dict[str, list[dict[str, Any]]]:\n    \"\"\"Convert the collection of Attribute instances to a list of dictionaries.\n\n    Returns:\n        dict[str, list[dict[str, Any]]]: Collection of Attribute instances as a dictionary.\n\n    Examples:\n\n        &gt;&gt;&gt; from fusion import Fusion\n        &gt;&gt;&gt; fusion = Fusion()\n        &gt;&gt;&gt; attribute = fusion.attribute(identifier=\"my_attribute\", index=0)\n        &gt;&gt;&gt; attributes = fusion.attributes(attributes=[attribute])\n        &gt;&gt;&gt; attributes_dict = attributes.to_dict()\n\n    \"\"\"\n    dict_out = {\"attributes\": [attr.to_dict() for attr in self.attributes]}\n    return dict_out\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#2015-2025-07-25","title":"[2.0.15] - 2025-07-25","text":"<ul> <li>Added various BCBS related functions for Reports, Report Attributes and Linkage of terms to Report Attrributes</li> <li>Includes fix for date format in bulk upload of file</li> <li>Added fusions logging to the existing loggers if present; which will remove forced use of fusions loggers.</li> </ul>"},{"location":"changelog/#2014-2025-07-14","title":"[2.0.14] - 2025-07-14","text":"<ul> <li>Removed the need for list datasets and list catalog calls during file uploads</li> <li>Bulk upload of files functionality enhanced to support file uploads from a folder path that contains subfolders</li> <li>Resolved the issue where downloading files would fail if the download folder already existed</li> </ul>"},{"location":"changelog/#2013-2025-05-06","title":"[2.0.13] - 2025-05-06","text":"<ul> <li>Exception handling improvement</li> <li>Limit Licensing service calls</li> <li>Limit list datasets calls internally</li> <li>Support xml format for distribution type</li> <li>Option to disable disc logging </li> <li>Remove the job-lib dependency to fix the credentials generating for each download and upload</li> <li>Enable exact search for list datasets</li> </ul>"},{"location":"changelog/#2012-2025-04-04","title":"[2.0.12] - 2025-04-04","text":"<ul> <li>Raise error immediately when attempting to download dataset you are not subscribed to</li> <li>Download available format when only one is available and format is set to None</li> <li>Reduce overhead of to_df when files are already downloaded</li> <li>Persist root url in events methods</li> <li>Provide metadata in columns for events notifications for usability</li> <li>Remove event duplication in events notification output</li> </ul>"},{"location":"changelog/#2011-2025-03-21","title":"[2.0.11] - 2025-03-21","text":"<ul> <li>Bug fix for _info, no longer submitting keep_protocol param to aiohttp client session</li> <li>Adding asynchronous streaming and asynchronous download as bytes to file system and Fusion</li> </ul>"},{"location":"changelog/#2010-2025-03-20","title":"[2.0.10] - 2025-03-20","text":"<ul> <li>Asynchronous embeddings API connection class</li> <li>Support multi knowledge base search in sync and async embeddings connection classes</li> <li>Consolidate embeddings connector class utilities</li> </ul>"},{"location":"changelog/#209-2025-03-11","title":"[2.0.9] - 2025-03-11","text":"<ul> <li>Adding async functionality to FusionHTTPFileSystem</li> </ul>"},{"location":"changelog/#208-2025-03-04","title":"[2.0.8] - 2025-03-04","text":"<ul> <li>GZ supported distribution type</li> <li>from bytes to handle multipart upload for large files</li> </ul>"},{"location":"changelog/#207-2025-02-03","title":"[2.0.7] - 2025-02-03","text":"<ul> <li>Embeddings API functionality</li> </ul>"},{"location":"changelog/#206-2025-01-16","title":"[2.0.6] - 2025-01-16","text":"<ul> <li>BCBS functionality</li> </ul>"},{"location":"changelog/#205-2024-12-12","title":"[2.0.5] - 2024-12-12","text":"<ul> <li>Application ID handling in dataset creation</li> <li>Activate dataset method</li> <li>Add dataset to product method</li> <li>Filter for dataset_type in list_datasets()</li> <li>bug fix for get_events()</li> </ul>"},{"location":"changelog/#204-2024-11-22","title":"[2.0.4] - 2024-11-22","text":"<ul> <li>download bug fix for credentials with proxies</li> </ul>"},{"location":"changelog/#203-2024-11-22","title":"[2.0.3] - 2024-11-22","text":"<ul> <li>x509 certificate auth support for FID</li> </ul>"},{"location":"changelog/#202-2024-11-14","title":"[2.0.2] - 2024-11-14","text":"<ul> <li>Metadata interface updated to use snake case style and handle camel case under hood</li> </ul>"},{"location":"changelog/#201-2024-11-04","title":"[2.0.1] - 2024-11-04","text":"<ul> <li>minor fix to to_dict methods of product, dataset, and attribute(s) classes</li> </ul>"},{"location":"changelog/#200-2024-10-28","title":"[2.0.0] - 2024-10-28","text":"<ul> <li>Metadata creation for products, datasets, and attributes</li> <li>dataset series member deletion functionality</li> </ul>"},{"location":"changelog/#141-2024-10-24","title":"[1.4.1] - 2024-10-24","text":"<ul> <li>s3 download bug fix</li> <li>Download latest dataset enhancement to handle non-ISO-formatted dates</li> </ul>"},{"location":"changelog/#140-2024-10-11","title":"[1.4.0] - 2024-10-11","text":"<ul> <li>dataset lineage exploration and creation</li> </ul>"},{"location":"changelog/#134-2024-09-14","title":"[1.3.4] - 2024-09-14","text":"<ul> <li>rustls support native certificates</li> </ul>"},{"location":"changelog/#133-2024-09-13","title":"[1.3.3] - 2024-09-13","text":"<ul> <li>support custom headers in credentials</li> <li>support additional headers in upload</li> <li>fix list datasets filter by product</li> </ul>"},{"location":"changelog/#132-2024-08-23","title":"[1.3.2] - 2024-08-23","text":"<ul> <li>add bespoke ssl certificated to aiohttp session</li> <li>robustify sample download</li> <li>do not strictly require headers for file download</li> </ul>"},{"location":"changelog/#131-2024-08-22","title":"[1.3.1] - 2024-08-22","text":"<ul> <li>fix preserve name download/upload feature</li> </ul>"},{"location":"changelog/#130-2024-08-16","title":"[1.3.0] - 2024-08-16","text":"<ul> <li>migrate from raw threading to async functions</li> <li>add support for more file formats</li> <li>add preservation of original file name</li> </ul>"},{"location":"changelog/#122-2024-08-01","title":"[1.2.2] - 2024-08-01","text":"<ul> <li>fix password based auth</li> </ul>"},{"location":"changelog/#121-2024-07-30","title":"[1.2.1] - 2024-07-30","text":"<ul> <li>fix password based auth</li> </ul>"},{"location":"changelog/#120-2024-07-27","title":"[1.2.0] - 2024-07-27","text":"<ul> <li>move authentication to rust layer</li> </ul>"},{"location":"changelog/#114-2024-06-28","title":"[1.1.4] - 2024-06-28","text":"<ul> <li>relax naming convention for single file upload</li> </ul>"},{"location":"changelog/#113-2024-06-20","title":"[1.1.3] - 2024-06-20","text":"<ul> <li>fix fsync upload</li> </ul>"},{"location":"changelog/#112-2024-06-16","title":"[1.1.2] - 2024-06-16","text":"<ul> <li>default root_url change</li> </ul>"},{"location":"changelog/#111-2024-06-07","title":"[1.1.1] - 2024-06-07","text":"<ul> <li>project folder rename</li> <li>minor fix in the upload internals</li> </ul>"},{"location":"changelog/#110-2024-06-06","title":"[1.1.0] - 2024-06-06","text":"<ul> <li>Fusion e2e monitoring</li> </ul>"},{"location":"changelog/#110-dev3-2024-05-22","title":"[1.1.0-dev3] - 2024-05-22","text":"<ul> <li>Internal build updates</li> </ul>"},{"location":"changelog/#110-dev1-2024-05-14","title":"[1.1.0-dev1] - 2024-05-14","text":"<ul> <li>Internal build updates</li> </ul>"},{"location":"changelog/#1023-2024-04-12","title":"[1.0.23] - 2024-04-12","text":"<ul> <li>bug fix to unlock the upload functionality</li> </ul>"},{"location":"changelog/#1022-2024-04-06","title":"[1.0.22] - 2024-04-06","text":"<ul> <li>limit number of threads for download to default to 10</li> </ul>"},{"location":"changelog/#1021-2024-03-27","title":"[1.0.21] - 2024-03-27","text":"<ul> <li>fix to_df for parquet files</li> </ul>"},{"location":"changelog/#1020-2024-03-27","title":"[1.0.20] - 2024-03-27","text":"<ul> <li>multipart download for a single file download</li> </ul>"},{"location":"changelog/#1019-2024-03-12","title":"[1.0.19] - 2024-03-12","text":"<ul> <li>eliminate dependency on async-retrying</li> </ul>"},{"location":"changelog/#1018-2024-03-11","title":"[1.0.18] - 2024-03-11","text":"<ul> <li>upload from s3 to API fix</li> </ul>"},{"location":"changelog/#1017-2024-02-26","title":"[1.0.17] - 2024-02-26","text":"<ul> <li>allow datetime dataseries members</li> <li>to_bytes method</li> <li>encode dataset name in the changes endpoint</li> </ul>"},{"location":"changelog/#1016-2024-02-19","title":"[1.0.16] - 2024-02-19","text":"<ul> <li>fix multi-dataset fsync</li> </ul>"},{"location":"changelog/#1015-2024-02-08","title":"[1.0.15] - 2024-02-08","text":"<ul> <li>fix get_events</li> <li>support for bytes-range requests in fusion filesystem</li> <li>support for per column downloads via pyarrow parquet dataset</li> </ul>"},{"location":"changelog/#1014-2023-12-13","title":"[1.0.14] - 2023-12-13","text":"<ul> <li>progress bar fix</li> <li>upload error propagation</li> </ul>"},{"location":"changelog/#1013-2023-12-13","title":"[1.0.13] - 2023-12-13","text":"<ul> <li>polars integration</li> <li>file size in fs.info function</li> <li>progress bar improvement to capture exceptions</li> <li>sample dataset download</li> <li>server events functionality</li> </ul>"},{"location":"changelog/#1012-2023-06-12","title":"[1.0.12] - 2023-06-12","text":"<ul> <li>minor bug fixes</li> </ul>"},{"location":"changelog/#1011-2023-05-10","title":"[1.0.11] - 2023-05-10","text":"<ul> <li>support bearer token authentication</li> <li>fix proxy support to aiohttp</li> <li>fix filtering support for csv and json</li> </ul>"},{"location":"changelog/#1010-2023-03-23","title":"[1.0.10] - 2023-03-23","text":"<ul> <li>md5 to sha256 convention change</li> <li>fsync continuous updates bug fix</li> <li>to_table function addition</li> <li>saving files in a hive friendly folder structure</li> <li>new bearer token add for download/upload operations</li> <li>raw data upload functionality fix</li> </ul>"},{"location":"changelog/#109-2023-01-23","title":"[1.0.9] - 2023-01-23","text":"<ul> <li>operational enhancements</li> </ul>"},{"location":"changelog/#108-2023-01-19","title":"[1.0.8] - 2023-01-19","text":"<ul> <li>cloud storage compatibility</li> </ul>"},{"location":"changelog/#107-2023-01-12","title":"[1.0.7] - 2023-01-12","text":"<ul> <li>Multi-part upload</li> <li>fsync</li> </ul>"},{"location":"changelog/#106-2022-11-21","title":"[1.0.6] - 2022-11-21","text":"<ul> <li>Support setting of the default catalog</li> <li>Fusion filesystem module</li> <li>Upload functionality</li> <li>Folder traversing for credentials</li> <li>Filters for parquet and csv file opening</li> </ul>"},{"location":"changelog/#105-2022-06-22","title":"[1.0.5] - 2022-06-22","text":"<ul> <li>Add support for internal auth methods</li> </ul>"},{"location":"changelog/#104-2022-05-19","title":"[1.0.4] - 2022-05-19","text":"<ul> <li>Support proxy servers in auth post requests</li> <li>Add back support for '2020-01-01' and '20200101' date formats</li> <li>Various bug fixes</li> <li>Streamline credentials creation</li> </ul>"},{"location":"changelog/#103-2022-05-12","title":"[1.0.3] - 2022-05-12","text":"<ul> <li>Add support for 'latest' datasets</li> </ul>"},{"location":"changelog/#102-2022-05-12","title":"[1.0.2] - 2022-05-12","text":"<ul> <li>Integrate build with docs</li> </ul>"},{"location":"changelog/#101-2022-05-12","title":"[1.0.1] - 2022-05-12","text":"<ul> <li>First live release on JPMC gitub</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>{{ cookiecutter.project_name }} could always use more documentation, whether as part of the official {{ cookiecutter.project_name }} docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up <code>{{ cookiecutter.project_slug }}</code> for local development.</p> <ol> <li>Fork the <code>{{ cookiecutter.project_slug }}</code> repo on GitHub.</li> <li> <p>Clone your fork locally</p> <pre><code>$ git clone git@github.com:your_name_here/{{ cookiecutter.project_slug }}.git\n</code></pre> </li> <li> <p>Ensure poetry is installed.</p> </li> <li> <p>Install dependencies and start your virtualenv:</p> <pre><code>$ poetry install -E test -E doc -E dev\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass the    tests, including testing other Python versions, with tox:</p> <pre><code>$ poetry run tox\n</code></pre> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.md.</li> <li>The pull request should work for Python 3.7, 3.8 and 3.9. Check    https://github.com/{{ cookiecutter.github_username }}/{{ cookiecutter.project_slug }}/actions    and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"contributing/#tips","title":"Tips","text":"<pre><code>$ poetry run pytest tests/test_{{ cookiecutter.pkg_name }}.py\n</code></pre> <p>To run a subset of tests.</p>"},{"location":"contributing/#deploying","title":"Deploying","text":"<p>A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run:</p> <pre><code>$ poetry run bump2version patch # possible: major / minor / patch\n$ git push\n$ git push --tags\n</code></pre> <p>GitHub Actions will then deploy to PyPI if tests pass.</p>"},{"location":"fusion_filesystem/","title":"Fusion - Working w/ Fusion File System (FFS)","text":"In\u00a0[2]: Copied! <pre>from fusion import Fusion\nimport asyncio\nimport ast\n\n# Package only for running async in notebook\nimport nest_asyncio\nnest_asyncio.apply()\n</pre> from fusion import Fusion import asyncio import ast  # Package only for running async in notebook import nest_asyncio nest_asyncio.apply() In\u00a0[3]: Copied! <pre>test_path = \"common/datasets/ISS_ESG_CNTRY_RTNG_SSF/datasetseries/20250101/distributions\"\n</pre> test_path = \"common/datasets/ISS_ESG_CNTRY_RTNG_SSF/datasetseries/20250101/distributions\" <p>Simplest way to create a synchronous FFS instance is to call the below Fusion method:</p> In\u00a0[4]: Copied! <pre># Fusion instance setup (synchronous)\nf_inst1 = Fusion()\nsync_ffs = f_inst1.get_fusion_filesystem()\n</pre> # Fusion instance setup (synchronous) f_inst1 = Fusion() sync_ffs = f_inst1.get_fusion_filesystem()  In\u00a0[5]: Copied! <pre># To create an async fusion file system, will require instantiating the FusionHTTPFileSystem class itself\nfrom fusion.fusion_filesystem import FusionHTTPFileSystem\n\nf_inst2 = Fusion()\nas_async = True\n\nasync_ffs = FusionHTTPFileSystem(\n    client_kwargs={\n        \"root_url\": f_inst2.root_url,\n        \"credentials\": f_inst2.credentials,\n    },\n    asynchronous=as_async\n)\n</pre> # To create an async fusion file system, will require instantiating the FusionHTTPFileSystem class itself from fusion.fusion_filesystem import FusionHTTPFileSystem  f_inst2 = Fusion() as_async = True  async_ffs = FusionHTTPFileSystem(     client_kwargs={         \"root_url\": f_inst2.root_url,         \"credentials\": f_inst2.credentials,     },     asynchronous=as_async ) <p>File system operations like \"cat\", \"ls\", \"info\", and \"find\" can easily be executed by calling their associated methods on your file system instance.</p> <p>Output for many operations will be a JSON. Byte-type outputs can be converted to string via methods like byte.decode(), and a string can be parsed to a dictionary using ast.literal_eval.</p> In\u00a0[9]: Copied! <pre>cat_output_bytes = sync_ffs.cat(test_path)\ncat_output_str = cat_output_bytes.decode(\"UTF-8\")\ncat_output_parsed = ast.literal_eval(cat_output_str)\n\nprint(f\"Raw .cat output {type(cat_output_bytes)}: {cat_output_bytes}\")\nprint(f\"Cast .cat output {type(cat_output_str)}: {cat_output_str}\")\nprint(f\"Parsed .cat output {type(cat_output_parsed)}: {cat_output_parsed}\")\n</pre> cat_output_bytes = sync_ffs.cat(test_path) cat_output_str = cat_output_bytes.decode(\"UTF-8\") cat_output_parsed = ast.literal_eval(cat_output_str)  print(f\"Raw .cat output {type(cat_output_bytes)}: {cat_output_bytes}\") print(f\"Cast .cat output {type(cat_output_str)}: {cat_output_str}\") print(f\"Parsed .cat output {type(cat_output_parsed)}: {cat_output_parsed}\") <pre>Raw .cat output &lt;class 'bytes'&gt;: b'{\"resources\":[{\"title\":\"CSV\",\"fileExtension\":\".csv\",\"description\":\"Snapshot data will be in a tabular, comma separated format.\",\"mediaType\":\"text/csv; header=present; charset=utf-8\",\"identifier\":\"csv\",\"@id\":\"csv/\"},{\"title\":\"Parquet\",\"fileExtension\":\".parquet\",\"description\":\"Snapshot data will be in a parquet format.\",\"mediaType\":\"application/parquet; header=present\",\"identifier\":\"parquet\",\"@id\":\"parquet/\"}],\"@context\":{\"@base\":\"https://fusion.jpmorgan.com/api/v1/\",\"@vocab\":\"https://www.w3.org/ns/dcat3.jsonld\"},\"description\":\"A list of available distributions\",\"@id\":\"distributions/\",\"identifier\":\"distributions\",\"title\":\"Distributions\"}'\nCast .cat output &lt;class 'str'&gt;: {\"resources\":[{\"title\":\"CSV\",\"fileExtension\":\".csv\",\"description\":\"Snapshot data will be in a tabular, comma separated format.\",\"mediaType\":\"text/csv; header=present; charset=utf-8\",\"identifier\":\"csv\",\"@id\":\"csv/\"},{\"title\":\"Parquet\",\"fileExtension\":\".parquet\",\"description\":\"Snapshot data will be in a parquet format.\",\"mediaType\":\"application/parquet; header=present\",\"identifier\":\"parquet\",\"@id\":\"parquet/\"}],\"@context\":{\"@base\":\"https://fusion.jpmorgan.com/api/v1/\",\"@vocab\":\"https://www.w3.org/ns/dcat3.jsonld\"},\"description\":\"A list of available distributions\",\"@id\":\"distributions/\",\"identifier\":\"distributions\",\"title\":\"Distributions\"}\nParsed .cat output &lt;class 'dict'&gt;: {'resources': [{'title': 'CSV', 'fileExtension': '.csv', 'description': 'Snapshot data will be in a tabular, comma separated format.', 'mediaType': 'text/csv; header=present; charset=utf-8', 'identifier': 'csv', '@id': 'csv/'}, {'title': 'Parquet', 'fileExtension': '.parquet', 'description': 'Snapshot data will be in a parquet format.', 'mediaType': 'application/parquet; header=present', 'identifier': 'parquet', '@id': 'parquet/'}], '@context': {'@base': 'https://fusion.jpmorgan.com/api/v1/', '@vocab': 'https://www.w3.org/ns/dcat3.jsonld'}, 'description': 'A list of available distributions', '@id': 'distributions/', 'identifier': 'distributions', 'title': 'Distributions'}\n</pre> <p>Using the async versions of our ffs functions will require more active management to properly execute. An aiohttp.ClientSession must be opened prior to method execution and all execution must occur in an async context.</p> In\u00a0[4]: Copied! <pre>target = \"catalogs/common/datasets/FXO_SP/datasetseries/20230726/distributions/csv\"\n</pre> target = \"catalogs/common/datasets/FXO_SP/datasetseries/20230726/distributions/csv\" In\u00a0[\u00a0]: Copied! <pre># Function to run async functions in a synchronous context\ndef execute_coroutine(coroute):\n    \"\"\"Execute coroutine from an un-awaited async function.\n    \n    Args:\n        coroute (coroutine): An async function's returned coroutine.\n    \n    Returns:\n        Result of coroutine execution.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    result = loop.run_until_complete(coroute)\n    return result\n\n# Example async function wrapping a basic fs operations we might use, here file downloading.\nasync def async_read(ffs: FusionHTTPFileSystem, client: Fusion, path: str):\n    \"\"\"Read a file asynchronously using provided ffs file system.\n    \n    Args:\n        ffs (FusionHTTPFileSystem): FFS file system configured to read from path.\n        client (Fusion): Fusion instance to extract root_url from.\n        path (str): Path without root_url to access desired file.\n    \n    Returns:\n        File returned as bytes.\n    \"\"\"\n    f = await ffs.open_async(client.root_url + path, \"rb\")\n    async with f:\n        result = await f.read()\n    return result\n</pre> # Function to run async functions in a synchronous context def execute_coroutine(coroute):     \"\"\"Execute coroutine from an un-awaited async function.          Args:         coroute (coroutine): An async function's returned coroutine.          Returns:         Result of coroutine execution.     \"\"\"     loop = asyncio.get_event_loop()     result = loop.run_until_complete(coroute)     return result  # Example async function wrapping a basic fs operations we might use, here file downloading. async def async_read(ffs: FusionHTTPFileSystem, client: Fusion, path: str):     \"\"\"Read a file asynchronously using provided ffs file system.          Args:         ffs (FusionHTTPFileSystem): FFS file system configured to read from path.         client (Fusion): Fusion instance to extract root_url from.         path (str): Path without root_url to access desired file.          Returns:         File returned as bytes.     \"\"\"     f = await ffs.open_async(client.root_url + path, \"rb\")     async with f:         result = await f.read()     return result In\u00a0[12]: Copied! <pre># Before deploying any ffs async methods, must first call the async method .set_session()\nsess = execute_coroutine(async_ffs.set_session())\n\n# Execute cat asynchronously\n# _cat, like other _methods, is asynchronous. Running it by itself returns a coroutine.\n# To actually execute the code, you either can \"await\" the coroutine in an asynchronous context\n# or if you're in a synchronous context (like this notebook), use a function like execute_coroutine.\ncat_coroutine = async_ffs._cat(test_path) # Returns a coroutine but does not yet execute code\ncat_async_bytes = execute_coroutine(cat_coroutine)\ncat_async_str = cat_async_bytes.decode(\"UTF-8\")\ncat_async_parsed = ast.literal_eval(cat_async_str)\n\nprint(f\"Raw .cat output {type(cat_async_bytes)}: {cat_async_bytes}\")\nprint(f\"Cast .cat output {type(cat_async_str)}: {cat_async_str}\")\nprint(f\"Parsed .cat output {type(cat_async_parsed)}: {cat_async_parsed}\")\n</pre> # Before deploying any ffs async methods, must first call the async method .set_session() sess = execute_coroutine(async_ffs.set_session())  # Execute cat asynchronously # _cat, like other _methods, is asynchronous. Running it by itself returns a coroutine. # To actually execute the code, you either can \"await\" the coroutine in an asynchronous context # or if you're in a synchronous context (like this notebook), use a function like execute_coroutine. cat_coroutine = async_ffs._cat(test_path) # Returns a coroutine but does not yet execute code cat_async_bytes = execute_coroutine(cat_coroutine) cat_async_str = cat_async_bytes.decode(\"UTF-8\") cat_async_parsed = ast.literal_eval(cat_async_str)  print(f\"Raw .cat output {type(cat_async_bytes)}: {cat_async_bytes}\") print(f\"Cast .cat output {type(cat_async_str)}: {cat_async_str}\") print(f\"Parsed .cat output {type(cat_async_parsed)}: {cat_async_parsed}\") <pre>Raw .cat output &lt;class 'bytes'&gt;: b'{\"@id\":\"distributions/\",\"title\":\"Distributions\",\"identifier\":\"distributions\",\"resources\":[{\"fileExtension\":\".csv\",\"mediaType\":\"text/csv; header=present; charset=utf-8\",\"identifier\":\"csv\",\"@id\":\"csv/\",\"description\":\"Snapshot data will be in a tabular, comma separated format.\",\"title\":\"CSV\"},{\"fileExtension\":\".parquet\",\"mediaType\":\"application/parquet; header=present\",\"identifier\":\"parquet\",\"@id\":\"parquet/\",\"description\":\"Snapshot data will be in a parquet format.\",\"title\":\"Parquet\"}],\"description\":\"A list of available distributions\",\"@context\":{\"@base\":\"https://fusion.jpmorgan.com/api/v1/\",\"@vocab\":\"https://www.w3.org/ns/dcat3.jsonld\"}}'\nCast .cat output &lt;class 'str'&gt;: {\"@id\":\"distributions/\",\"title\":\"Distributions\",\"identifier\":\"distributions\",\"resources\":[{\"fileExtension\":\".csv\",\"mediaType\":\"text/csv; header=present; charset=utf-8\",\"identifier\":\"csv\",\"@id\":\"csv/\",\"description\":\"Snapshot data will be in a tabular, comma separated format.\",\"title\":\"CSV\"},{\"fileExtension\":\".parquet\",\"mediaType\":\"application/parquet; header=present\",\"identifier\":\"parquet\",\"@id\":\"parquet/\",\"description\":\"Snapshot data will be in a parquet format.\",\"title\":\"Parquet\"}],\"description\":\"A list of available distributions\",\"@context\":{\"@base\":\"https://fusion.jpmorgan.com/api/v1/\",\"@vocab\":\"https://www.w3.org/ns/dcat3.jsonld\"}}\nParsed .cat output &lt;class 'dict'&gt;: {'@id': 'distributions/', 'title': 'Distributions', 'identifier': 'distributions', 'resources': [{'fileExtension': '.csv', 'mediaType': 'text/csv; header=present; charset=utf-8', 'identifier': 'csv', '@id': 'csv/', 'description': 'Snapshot data will be in a tabular, comma separated format.', 'title': 'CSV'}, {'fileExtension': '.parquet', 'mediaType': 'application/parquet; header=present', 'identifier': 'parquet', '@id': 'parquet/', 'description': 'Snapshot data will be in a parquet format.', 'title': 'Parquet'}], 'description': 'A list of available distributions', '@context': {'@base': 'https://fusion.jpmorgan.com/api/v1/', '@vocab': 'https://www.w3.org/ns/dcat3.jsonld'}}\n</pre> In\u00a0[\u00a0]: Copied! <pre># Creating a coroutine for reading a file asynchronously\ntask_perform_async_read = async_read(async_ffs, f_inst2, target)\nresult = execute_coroutine(task_perform_async_read)\nresult\n</pre> # Creating a coroutine for reading a file asynchronously task_perform_async_read = async_read(async_ffs, f_inst2, target) result = execute_coroutine(task_perform_async_read) result Out[\u00a0]: <pre>b'instrument_name,currency_pair,term,product,date,fx_rate\\nUSDAED | Spot,USDAED,Spot,FXSpot,20230726,3.673025\\nUSDARS | Spot,USDARS,Spot,FXSpot,20230726,272.5\\nUSDCHF | Spot,USDCHF,Spot,FXSpot,20230726,0.8632\\nUSDCNY | Spot,USDCNY,Spot,FXSpot,20230726,7.1504\\nUSDDKK | Spot,USDDKK,Spot,FXSpot,20230726,6.7345\\nUSDHUF | Spot,USDHUF,Spot,FXSpot,20230726,347.17\\nUSDIDO | Spot,USDIDO,Spot,FXSpot,20230726,15032.0\\nUSDIDR | Spot,USDIDR,Spot,FXSpot,20230726,15032.0\\nUSDILS | Spot,USDILS,Spot,FXSpot,20230726,3.6945\\nUSDMXN | Spot,USDMXN,Spot,FXSpot,20230726,16.835\\nUSDPAB | Spot,USDPAB,Spot,FXSpot,20230726,1.0\\nUSDPHF | Spot,USDPHF,Spot,FXSpot,20230726,54.62\\nUSDPHP | Spot,USDPHP,Spot,FXSpot,20230726,54.62\\nUSDSAR | Spot,USDSAR,Spot,FXSpot,20230726,3.7511\\nUSDTHB | Spot,USDTHB,Spot,FXSpot,20230726,34.309\\nUSDTRY | Spot,USDTRY,Spot,FXSpot,20230726,26.9495\\nUSDUAH | Spot,USDUAH,Spot,FXSpot,20230726,36.75145\\nXAUUSD | Spot,XAUUSD,Spot,FXSpot,20230726,1969.0\\nAUDUSD | Spot,AUDUSD,Spot,FXSpot,20230726,0.67525\\nEURUSD | Spot,EURUSD,Spot,FXSpot,20230726,1.1064\\nNZDUSD | Spot,NZDUSD,Spot,FXSpot,20230726,0.621\\nUSDCAD | Spot,USDCAD,Spot,FXSpot,20230726,1.3219\\nUSDCLF | Spot,USDCLF,Spot,FXSpot,20230726,0.0228602539\\nUSDCOP | Spot,USDCOP,Spot,FXSpot,20230726,3952.5\\nUSDIDF | Spot,USDIDF,Spot,FXSpot,20230726,15032.0\\nUSDINR | Spot,USDINR,Spot,FXSpot,20230726,82.01\\nUSDISK | Spot,USDISK,Spot,FXSpot,20230726,131.51\\nUSDJPY | Spot,USDJPY,Spot,FXSpot,20230726,140.365\\nUSDKRF | Spot,USDKRF,Spot,FXSpot,20230726,1276.5\\nUSDKRW | Spot,USDKRW,Spot,FXSpot,20230726,1276.5\\nUSDKWD | Spot,USDKWD,Spot,FXSpot,20230726,0.30694\\nUSDLBP | Spot,USDLBP,Spot,FXSpot,20230726,15010.0\\nUSDNOK | Spot,USDNOK,Spot,FXSpot,20230726,10.1345\\nUSDPKR | Spot,USDPKR,Spot,FXSpot,20230726,286.8\\nUSDRUB | Spot,USDRUB,Spot,FXSpot,20230726,89.95\\nUSDSEK | Spot,USDSEK,Spot,FXSpot,20230726,10.4541\\nUSDSGD | Spot,USDSGD,Spot,FXSpot,20230726,1.32675\\nUSDTWF | Spot,USDTWF,Spot,FXSpot,20230726,31.253\\nXPTUSD | Spot,XPTUSD,Spot,FXSpot,20230726,965.5\\nGBPUSD | Spot,GBPUSD,Spot,FXSpot,20230726,1.2922\\nUSDBMD | Spot,USDBMD,Spot,FXSpot,20230726,1.0\\nUSDBRL | Spot,USDBRL,Spot,FXSpot,20230726,4.7276\\nUSDCLP | Spot,USDCLP,Spot,FXSpot,20230726,824.25\\nUSDCNH | Spot,USDCNH,Spot,FXSpot,20230726,7.15025\\nUSDCZK | Spot,USDCZK,Spot,FXSpot,20230726,21.734\\nUSDEGP | Spot,USDEGP,Spot,FXSpot,20230726,30.9\\nUSDHKD | Spot,USDHKD,Spot,FXSpot,20230726,7.80045\\nUSDINO | Spot,USDINO,Spot,FXSpot,20230726,82.01\\nUSDJOD | Spot,USDJOD,Spot,FXSpot,20230726,0.70855\\nUSDKES | Spot,USDKES,Spot,FXSpot,20230726,143.275\\nUSDLKR | Spot,USDLKR,Spot,FXSpot,20230726,329.0\\nUSDMYR | Spot,USDMYR,Spot,FXSpot,20230726,4.545\\nUSDPEN | Spot,USDPEN,Spot,FXSpot,20230726,3.599\\nUSDPLN | Spot,USDPLN,Spot,FXSpot,20230726,4.0036\\nUSDSKK | Spot,USDSKK,Spot,FXSpot,20230726,27.2288503254\\nUSDTHO | Spot,USDTHO,Spot,FXSpot,20230726,34.309\\nUSDTWD | Spot,USDTWD,Spot,FXSpot,20230726,31.253\\nUSDVEB | Spot,USDVEB,Spot,FXSpot,20230726,2144.6\\nUSDZAR | Spot,USDZAR,Spot,FXSpot,20230726,17.6716\\nXAGUSD | Spot,XAGUSD,Spot,FXSpot,20230726,24.8\\nXPDUSD | Spot,XPDUSD,Spot,FXSpot,20230726,1262.4\\n'</pre> In\u00a0[37]: Copied! <pre>print(result.decode(\"UTF-8\"))\n</pre> print(result.decode(\"UTF-8\")) <pre>instrument_name,currency_pair,term,product,date,fx_rate\nUSDAED | Spot,USDAED,Spot,FXSpot,20230726,3.673025\nUSDARS | Spot,USDARS,Spot,FXSpot,20230726,272.5\nUSDCHF | Spot,USDCHF,Spot,FXSpot,20230726,0.8632\nUSDCNY | Spot,USDCNY,Spot,FXSpot,20230726,7.1504\nUSDDKK | Spot,USDDKK,Spot,FXSpot,20230726,6.7345\nUSDHUF | Spot,USDHUF,Spot,FXSpot,20230726,347.17\nUSDIDO | Spot,USDIDO,Spot,FXSpot,20230726,15032.0\nUSDIDR | Spot,USDIDR,Spot,FXSpot,20230726,15032.0\nUSDILS | Spot,USDILS,Spot,FXSpot,20230726,3.6945\nUSDMXN | Spot,USDMXN,Spot,FXSpot,20230726,16.835\nUSDPAB | Spot,USDPAB,Spot,FXSpot,20230726,1.0\nUSDPHF | Spot,USDPHF,Spot,FXSpot,20230726,54.62\nUSDPHP | Spot,USDPHP,Spot,FXSpot,20230726,54.62\nUSDSAR | Spot,USDSAR,Spot,FXSpot,20230726,3.7511\nUSDTHB | Spot,USDTHB,Spot,FXSpot,20230726,34.309\nUSDTRY | Spot,USDTRY,Spot,FXSpot,20230726,26.9495\nUSDUAH | Spot,USDUAH,Spot,FXSpot,20230726,36.75145\nXAUUSD | Spot,XAUUSD,Spot,FXSpot,20230726,1969.0\nAUDUSD | Spot,AUDUSD,Spot,FXSpot,20230726,0.67525\nEURUSD | Spot,EURUSD,Spot,FXSpot,20230726,1.1064\nNZDUSD | Spot,NZDUSD,Spot,FXSpot,20230726,0.621\nUSDCAD | Spot,USDCAD,Spot,FXSpot,20230726,1.3219\nUSDCLF | Spot,USDCLF,Spot,FXSpot,20230726,0.0228602539\nUSDCOP | Spot,USDCOP,Spot,FXSpot,20230726,3952.5\nUSDIDF | Spot,USDIDF,Spot,FXSpot,20230726,15032.0\nUSDINR | Spot,USDINR,Spot,FXSpot,20230726,82.01\nUSDISK | Spot,USDISK,Spot,FXSpot,20230726,131.51\nUSDJPY | Spot,USDJPY,Spot,FXSpot,20230726,140.365\nUSDKRF | Spot,USDKRF,Spot,FXSpot,20230726,1276.5\nUSDKRW | Spot,USDKRW,Spot,FXSpot,20230726,1276.5\nUSDKWD | Spot,USDKWD,Spot,FXSpot,20230726,0.30694\nUSDLBP | Spot,USDLBP,Spot,FXSpot,20230726,15010.0\nUSDNOK | Spot,USDNOK,Spot,FXSpot,20230726,10.1345\nUSDPKR | Spot,USDPKR,Spot,FXSpot,20230726,286.8\nUSDRUB | Spot,USDRUB,Spot,FXSpot,20230726,89.95\nUSDSEK | Spot,USDSEK,Spot,FXSpot,20230726,10.4541\nUSDSGD | Spot,USDSGD,Spot,FXSpot,20230726,1.32675\nUSDTWF | Spot,USDTWF,Spot,FXSpot,20230726,31.253\nXPTUSD | Spot,XPTUSD,Spot,FXSpot,20230726,965.5\nGBPUSD | Spot,GBPUSD,Spot,FXSpot,20230726,1.2922\nUSDBMD | Spot,USDBMD,Spot,FXSpot,20230726,1.0\nUSDBRL | Spot,USDBRL,Spot,FXSpot,20230726,4.7276\nUSDCLP | Spot,USDCLP,Spot,FXSpot,20230726,824.25\nUSDCNH | Spot,USDCNH,Spot,FXSpot,20230726,7.15025\nUSDCZK | Spot,USDCZK,Spot,FXSpot,20230726,21.734\nUSDEGP | Spot,USDEGP,Spot,FXSpot,20230726,30.9\nUSDHKD | Spot,USDHKD,Spot,FXSpot,20230726,7.80045\nUSDINO | Spot,USDINO,Spot,FXSpot,20230726,82.01\nUSDJOD | Spot,USDJOD,Spot,FXSpot,20230726,0.70855\nUSDKES | Spot,USDKES,Spot,FXSpot,20230726,143.275\nUSDLKR | Spot,USDLKR,Spot,FXSpot,20230726,329.0\nUSDMYR | Spot,USDMYR,Spot,FXSpot,20230726,4.545\nUSDPEN | Spot,USDPEN,Spot,FXSpot,20230726,3.599\nUSDPLN | Spot,USDPLN,Spot,FXSpot,20230726,4.0036\nUSDSKK | Spot,USDSKK,Spot,FXSpot,20230726,27.2288503254\nUSDTHO | Spot,USDTHO,Spot,FXSpot,20230726,34.309\nUSDTWD | Spot,USDTWD,Spot,FXSpot,20230726,31.253\nUSDVEB | Spot,USDVEB,Spot,FXSpot,20230726,2144.6\nUSDZAR | Spot,USDZAR,Spot,FXSpot,20230726,17.6716\nXAGUSD | Spot,XAGUSD,Spot,FXSpot,20230726,24.8\nXPDUSD | Spot,XPDUSD,Spot,FXSpot,20230726,1262.4\n\n</pre> In\u00a0[6]: Copied! <pre>### To stream a file using an async generator:\n\n# In an async context:\ntarget = \"common/datasets/ISS_ESG_CNTRY_RTNG_SSF/datasetseries/20250101/distributions/csv\"\nasync_generator = f_inst1._async_stream_file(target, chunk_size=100) # returns AsyncGenerator[bytes, None]\n\n# Working with output as async generator\n# Printing the first 5 chunks\ncounter = 0\nasync for chunk in async_generator:\n    print(chunk)\n    counter += 1\n    if counter &gt;= 5:\n        break\n</pre> ### To stream a file using an async generator:  # In an async context: target = \"common/datasets/ISS_ESG_CNTRY_RTNG_SSF/datasetseries/20250101/distributions/csv\" async_generator = f_inst1._async_stream_file(target, chunk_size=100) # returns AsyncGenerator[bytes, None]  # Working with output as async generator # Printing the first 5 chunks counter = 0 async for chunk in async_generator:     print(chunk)     counter += 1     if counter &gt;= 5:         break <pre>b'as_at_date,as_of_date,entity_id,entity_name,parent_entity_id,parent_entity_name,final_parent_entity_'\nb'id,final_parent_entity_name,iss_issr_id,iss_issr_name,lei,gics_sctr,gics_sctr_code,gics_industry_grp'\nb',gics_industry_grp_code,gics_industry,gics_industry_code,gics_sub_industry,gics_sub_industry_code,cm'\nb'pny_ticker,cmpny_isin,cmpny_cusip,cmpny_sedol,cmpny_cins,inst_class,cmpny_exchg_lvl_figi,metrics_by_'\nb'proxy_ind,proxy_entity_id,proxy_entity_name,agrcltre_prdctn_num,agrcltre_prdctn_wt,agrcltrl_prdctn,b'\n</pre> In\u00a0[7]: Copied! <pre>### To asynchronously get entire file instead of streaming\nfile_as_bytes = await f_inst1._async_get_file(target, chunk_size=1000)\nchar_limit = 700 # Set a display limit just so notebook doesn't have to render entire file\nprint(f\"First {char_limit} chars of file: {file_as_bytes[:char_limit]}\")\n</pre> ### To asynchronously get entire file instead of streaming file_as_bytes = await f_inst1._async_get_file(target, chunk_size=1000) char_limit = 700 # Set a display limit just so notebook doesn't have to render entire file print(f\"First {char_limit} chars of file: {file_as_bytes[:char_limit]}\") <pre>First 700 chars of file: b'as_at_date,as_of_date,entity_id,entity_name,parent_entity_id,parent_entity_name,final_parent_entity_id,final_parent_entity_name,iss_issr_id,iss_issr_name,lei,gics_sctr,gics_sctr_code,gics_industry_grp,gics_industry_grp_code,gics_industry,gics_industry_code,gics_sub_industry,gics_sub_industry_code,cmpny_ticker,cmpny_isin,cmpny_cusip,cmpny_sedol,cmpny_cins,inst_class,cmpny_exchg_lvl_figi,metrics_by_proxy_ind,proxy_entity_id,proxy_entity_name,agrcltre_prdctn_num,agrcltre_prdctn_wt,agrcltrl_prdctn,biodvrsty,biodvrsty_num,biodvrsty_wt,clmte_chg,clmte_chg_and_energy,clmte_chg_and_energy_num,clmte_chg_and_energy_wt,clmte_chg_num,clmte_chg_wt,cntry_env_rtng,cntry_env_rtng_num,cntry_env_rtng_wt,cntry'\n</pre> <p>The above async examples are modified to run in a notebook.</p> <p>See below for a pattern more applicable to execution in a .py file.</p> In\u00a0[\u00a0]: Copied! <pre>from fusion import Fusion\nfrom fusion.fusion_filesystem import FusionHTTPFileSystem\n\n# Basic Fusion/ffs setup\nf_inst3 = Fusion()\nas_async = True\nasync_ffs = FusionHTTPFileSystem(\n    client_kwargs={\n        \"root_url\": f_inst3.root_url,\n        \"credentials\": f_inst3.credentials,\n    },\n    asynchronous=as_async\n)\n\ntest_path = \"common/datasets/ISS_ESG_CNTRY_RTNG_SSF/datasetseries/20250101/distributions\"\n\n# An HTTP Client session must be opened before executing any async methods on FFS\nsess = await async_ffs.set_session()\n\n# To avoid resource leaks, session should be opened in \"async with\" block.\n# This ensures resources are cleaned up including when errors arise. Manually opening and then closing with .close() is available at user's own peril.\nasync with sess:\n    cat_output = await async_ffs._cat(test_path)\n    exists_output = await async_ffs._exists(test_path)\n    target = \"catalogs/common/datasets/FXO_SP/datasetseries/20230726/distributions/csv\"\n    async_download = await async_read(async_ffs, f_inst3, target)\n</pre> from fusion import Fusion from fusion.fusion_filesystem import FusionHTTPFileSystem  # Basic Fusion/ffs setup f_inst3 = Fusion() as_async = True async_ffs = FusionHTTPFileSystem(     client_kwargs={         \"root_url\": f_inst3.root_url,         \"credentials\": f_inst3.credentials,     },     asynchronous=as_async )  test_path = \"common/datasets/ISS_ESG_CNTRY_RTNG_SSF/datasetseries/20250101/distributions\"  # An HTTP Client session must be opened before executing any async methods on FFS sess = await async_ffs.set_session()  # To avoid resource leaks, session should be opened in \"async with\" block. # This ensures resources are cleaned up including when errors arise. Manually opening and then closing with .close() is available at user's own peril. async with sess:     cat_output = await async_ffs._cat(test_path)     exists_output = await async_ffs._exists(test_path)     target = \"catalogs/common/datasets/FXO_SP/datasetseries/20230726/distributions/csv\"     async_download = await async_read(async_ffs, f_inst3, target)"},{"location":"fusion_filesystem/#fusion-working-w-fusion-file-system-ffs","title":"Fusion - Working w/ Fusion File System (FFS)\u00b6","text":""},{"location":"fusion_filesystem/#creating-ffs-instances","title":"Creating FFS Instances\u00b6","text":""},{"location":"fusion_filesystem/#executing-basic-file-system-operations","title":"Executing Basic File System Operations\u00b6","text":""},{"location":"fusion_filesystem/#sync","title":"Sync\u00b6","text":""},{"location":"fusion_filesystem/#async","title":"Async\u00b6","text":""},{"location":"fusion_filesystem/#more-async-reading-with-fusion-module","title":"More Async Reading with Fusion Module\u00b6","text":""},{"location":"get_started/","title":"Fusion - get started","text":"In\u00a0[3]: Copied! <pre>import pandas as pd\nfrom fusion import Fusion\nimport matplotlib.pyplot as plt\nplt.style.use(\"bmh\")\n</pre> import pandas as pd from fusion import Fusion import matplotlib.pyplot as plt plt.style.use(\"bmh\") In\u00a0[4]: Copied! <pre>fusion = Fusion()\n</pre> fusion = Fusion() In\u00a0[5]: Copied! <pre>fusion\n</pre> fusion Out[5]: <pre>Fusion object \nAvailable methods:\n+------------------------------+--------------------------------------------------------------------------------------------------+\n| attribute                    | Instantiate an Attribute object with this client for metadata creation.                          |\n| attributes                   | Instantiate an Attributes object with this client for metadata creation.                         |\n| catalog_resources            | List the resources contained within the catalog, for example products and datasets.              |\n| create_dataset_lineage       | Upload lineage to a dataset.                                                                     |\n| dataset                      | Instantiate a Dataset object with this client for metadata creation.                             |\n| dataset_resources            | List the resources available for a dataset, currently this will always be a datasetseries.       |\n| datasetmember_resources      | List the available resources for a datasetseries member.                                         |\n| delete_all_datasetmembers    | Delete all dataset members within a dataset.                                                     |\n| delete_datasetmembers        | Delete dataset members.                                                                          |\n| download                     | Downloads the requested distributions of a dataset to disk.                                      |\n| from_bytes                   | Uploads data from an object in memory.                                                           |\n| get_events                   | Run server sent event listener and print out the new events. Keyboard terminate to stop.         |\n| get_fusion_filesystem        | Creates Fusion Filesystem.                                                                       |\n| list_catalogs                | Lists the catalogs available to the API account.                                                 |\n| list_dataset_attributes      | Returns the list of attributes that are in the dataset.                                          |\n| list_dataset_lineage         | List the upstream and downstream lineage of the dataset.                                         |\n| list_datasetmembers          | List the available members in the dataset series.                                                |\n| list_datasets                | Get the datasets contained in a catalog.                                                         |\n| list_distributions           | List the available distributions (downloadable instances of the dataset with a format type).     |\n| list_product_dataset_mapping | get the product to dataset linking contained in  a catalog. A product is a grouping of datasets. |\n| list_products                | Get the products contained in a catalog. A product is a grouping of datasets.                    |\n| listen_to_events             | Run server sent event listener in the background. Retrieve results by running get_events.        |\n| product                      | Instantiate a Product object with this client for metadata creation.                             |\n| to_bytes                     | Returns an instance of dataset (the distribution) as a bytes object.                             |\n| to_df                        | Gets distributions for a specified date or date range and returns the data as a dataframe.       |\n| to_table                     | Gets distributions for a specified date or date range and returns the data as an arrow table.    |\n| upload                       | Uploads the requested files/files to Fusion.                                                     |\n| default_catalog              | Returns the default catalog.                                                                     |\n+------------------------------+--------------------------------------------------------------------------------------------------+</pre> In\u00a0[6]: Copied! <pre>fusion.to_df?\n</pre> fusion.to_df? <pre>Signature:\nfusion.to_df(\n    dataset: 'str',\n    dt_str: 'str' = 'latest',\n    dataset_format: 'str' = 'parquet',\n    catalog: 'str | None' = None,\n    n_par: 'int | None' = None,\n    show_progress: 'bool' = True,\n    columns: 'list[str] | None' = None,\n    filters: 'PyArrowFilterT | None' = None,\n    force_download: 'bool' = False,\n    download_folder: 'str | None' = None,\n    dataframe_type: 'str' = 'pandas',\n    **kwargs: 'Any',\n) -&gt; 'pd.DataFrame'\nDocstring:\nGets distributions for a specified date or date range and returns the data as a dataframe.\n\nArgs:\n    dataset (str): A dataset identifier\n    dt_str (str, optional): Either a single date or a range identified by a start or end date,\n        or both separated with a \":\". Defaults to 'latest' which will return the most recent\n        instance of the dataset.\n    dataset_format (str, optional): The file format, e.g. CSV or Parquet. Defaults to 'parquet'.\n    catalog (str, optional): A catalog identifier. Defaults to 'common'.\n    n_par (int, optional): Specify how many distributions to download in parallel.\n        Defaults to all cpus available.\n    show_progress (bool, optional): Display a progress bar during data download Defaults to True.\n    columns (List, optional): A list of columns to return from a parquet file. Defaults to None\n    filters (List, optional): List[Tuple] or List[List[Tuple]] or None (default)\n        Rows which do not match the filter predicate will be removed from scanned data.\n        Partition keys embedded in a nested directory structure will be exploited to avoid\n        loading files at all if they contain no matching rows. If use_legacy_dataset is True,\n        filters can only reference partition keys and only a hive-style directory structure\n        is supported. When setting use_legacy_dataset to False, also within-file level filtering\n        and different partitioning schemes are supported.\n        More on https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html\n    force_download (bool, optional): If True then will always download a file even\n        if it is already on disk. Defaults to False.\n    download_folder (str, optional): The path, absolute or relative, where downloaded files are saved.\n        Defaults to download_folder as set in __init__\n    dataframe_type (str, optional): Type\nReturns:\n    class:`pandas.DataFrame`: a dataframe containing the requested data.\n        If multiple dataset instances are retrieved then these are concatenated first.\nFile:      ~/fusion/py_src/fusion/fusion.py\nType:      method</pre> In\u00a0[7]: Copied! <pre>fusion.list_catalogs()\n</pre> fusion.list_catalogs() Out[7]: identifier description @id isInternal title 0 common A catalog of common data common/ False Common 1 fusiondemo A catalog of fusion demo data fusiondemo/ False Fusion Demo In\u00a0[8]: Copied! <pre>fusion.list_datasets(\"FX\")\n</pre> fusion.list_datasets(\"FX\") Out[8]: identifier title containerType region category description status 0 FXO_SP FX Cash Rate Snapshot-Full EMEA, North America, Emerging Markets, APAC, G... FX This dataset includes FX spot rates for major ... Subscribed 3 FXO_ST FX Option Structure | Strangles Snapshot-Full EMEA, North America, APAC, Emerging Markets, G... FX Implied volatility for 10 and 25 delta FX opti... Subscribed 17 FX_INTRADAY_FWD_G10 FX INTRADAY FORWARDS - G10 Time-Series-Snapshot-Full Global FX FX Forwards Intraday Dataset\\n\\n Available 33 JPM_FX_Forwards_EOD JPM FX Forwards End of Day Time-Series-Delta Americas, Emerging Markets, Global FX JPM End of Day marks for Forwards Available 60 FXO_VOL_INTRA_EM FXO Intraday Implied Volatility Snaps - EM Snapshot-Full Emerging Markets, Global FX J.P. Morgan\u2019s FXO Intraday Implied Volatility ... Subscribed 94 STANDARD_MARKET_VALUATION_DETAIL_CCY_CONTRACTS Sample: Market Valuation Detail Currency Contr... Snapshot-Full Global Fund Accounting This dataset exclusively shows all pending spo... Available 98 FXO_RR FX Option Structure | Risk Reversal Snapshot-Full EMEA, North America, APAC, Emerging Markets, G... FX Implied volatility for 10 and 25 delta FX opti... Subscribed 114 MO_Standard_Closed_Tax_Lot MO Standard Closed Tax Lot Snapshot-Full Global Middle Office This dataset provides details at the Tax Lot l... Available 115 FX_ECONOMIC FX Specialized | Momentum Strategies (Economics) Snapshot-Full EMEA, North America, APAC, Emerging Markets, G... FX Momentum signals in a trend following strategy... Subscribed 121 FXO_VOL_EOD_EM FXO End of Day Implied Volatility - EM Snapshot-Full Emerging Markets, Global FX J.P. Morgan\u2019s FXO End of Day Implied Volatilit... Subscribed 123 STANDARD_FUTURE_VALUED_FX_CONTRACTS Sample: Future Valued FX Contracts Snapshot-Full Global Custody Standard Future Valued FX Contracts dataset di... Available 165 STANDARD_CLIENT_STANDING_INSTRUCTIONS Sample: Client Standing Instructions Snapshot-Full Global Custody Standard dataset detailing client standing ins... Available 183 FXO_VOL_INTRA_G10 FXO Intraday Implied Volatility Snaps - G10 Snapshot-Full Global FX J.P. Morgan\u2019s FXO Intraday Implied Volatility ... Available 239 FX_JPM_TCI FX Passive Index Snapshot-Full EMEA, North America, APAC, Global FX FX passive index level and currency sub-indices. Subscribed 240 FX_EASIDX Economic Activity Surprise Index (EASI) FX Snapshot-Full EMEA, North America, Emerging Markets, APAC, G... Economic The Economic Activity Surprise Index is publis... Subscribed 258 FXO_VOL_EOD_G10 FXO End of Day Implied Volatility - G10 Snapshot-Full Global FX J.P. Morgan\u2019s FXO End of Day Implied Volatilit... Subscribed 259 MO_Standard_Position_Summary MO Standard Position Summary Snapshot-Full Global Middle Office This dataset provides Portfolio level valuatio... Available 276 STANDARD_CLS_FX_TRANSACTIONS Sample: CLS FX Transactions Snapshot-Full Global Custody Standard dataset detailing all CLS FX trade ac... Available 278 JPM_FX_Spot_EOD JPM FX Spot End of Day Time-Series-Full Americas, EMEA, APAC FX JPM FX Spot rates sourced from trading desks Available 287 JPM_FX_Vols_EOD JPM FX Vols End Of Day Time-Series-Full Americas, Emerging Markets, Global FX FX EOD Vols across G10 and EM Available 296 STANDARD_VALUED_HOLDINGS Sample: Valued Holdings Snapshot-Full Global Middle Office Provides market value in local currency of the... Available 348 STANDARD_VALUED_HOLDINGS_SUMMARY Sample: Valued Holdings Summary Snapshot-Full Global Middle Office Provides portfolio level valuation in a specif... Available 366 FX_MEAN_HFFV FX Mean Reversion Strategies Hi Freq Fair Value Snapshot-Full EMEA, North America, APAC, Global FX The FX High Frequency Fair Value dataset from ... Subscribed 409 FX_MEAN_IMM FX Mean Reversion Strategies IMM Snapshot-Full EMEA, North America, APAC, Emerging Markets, G... FX The FX Mean Reversion, IMM dataset from J.P. M... Subscribed In\u00a0[9]: Copied! <pre>fusion.list_dataset_attributes(\"FXO_SP\")\n</pre> fusion.list_dataset_attributes(\"FXO_SP\") Out[9]: isDatasetKey identifier description title dataType 0 True instrument_name The instrument name Instrument Name String 1 False currency_pair The currency pair Currency Pair String 2 False term The time period of an investment, agreement or... Term String 3 False product The product identifier Product String 4 False date The snapshot date Date String 5 False fx_rate The spot and forward fx rate FX Rate Double In\u00a0[10]: Copied! <pre>fusion.list_datasetmembers(\"FXO_SP\")\n</pre> fusion.list_datasetmembers(\"FXO_SP\") Out[10]: identifier createdDate fromDate @id toDate 0 20190101 2019-01-01 2019-01-01 20190101/ 2019-01-01 1 20190102 2019-01-02 2019-01-02 20190102/ 2019-01-02 2 20190103 2019-01-03 2019-01-03 20190103/ 2019-01-03 3 20190104 2019-01-04 2019-01-04 20190104/ 2019-01-04 4 20190107 2019-01-07 2019-01-07 20190107/ 2019-01-07 ... ... ... ... ... ... 1498 20241018 2024-10-21 2024-10-18 20241018/ 2024-10-18 1499 20241021 2024-10-22 2024-10-21 20241021/ 2024-10-21 1500 20241022 2024-10-23 2024-10-22 20241022/ 2024-10-22 1501 20241023 2024-10-24 2024-10-23 20241023/ 2024-10-23 1502 20241024 2024-10-25 2024-10-24 20241024/ 2024-10-24 <p>1503 rows \u00d7 5 columns</p> In\u00a0[11]: Copied! <pre>fusion.list_distributions(\"FXO_SP\", \"20241024\")\n</pre> fusion.list_distributions(\"FXO_SP\", \"20241024\") Out[11]: identifier fileExtension mediaType @id title description 0 csv .csv text/csv; header=present; charset=utf-8 csv/ CSV Snapshot data will be in a tabular, comma sepa... 1 parquet .parquet application/parquet; header=present parquet/ Parquet Snapshot data will be in a parquet format. In\u00a0[12]: Copied! <pre>df = fusion.to_df(\"FXO_SP\", \"20241001:20241024\", dataset_format=\"csv\", columns=[\"currency_pair\", \"date\", \"fx_rate\"], filters=[(\"currency_pair\", \"=\", \"GBPUSD\")])\n</pre> df = fusion.to_df(\"FXO_SP\", \"20241001:20241024\", dataset_format=\"csv\", columns=[\"currency_pair\", \"date\", \"fx_rate\"], filters=[(\"currency_pair\", \"=\", \"GBPUSD\")]) <pre>Output()</pre> <pre></pre> <pre>\n</pre> In\u00a0[13]: Copied! <pre>df.head()\n</pre> df.head() Out[13]: currency_pair date fx_rate 0 GBPUSD 20241001 1.32885 1 GBPUSD 20241002 1.32505 2 GBPUSD 20241003 1.31075 3 GBPUSD 20241004 1.31185 4 GBPUSD 20241007 1.30785 In\u00a0[14]: Copied! <pre>df[\"date\"] = pd.to_datetime(df[\"date\"].astype(\"str\"))\ndf.sort_values(\"date\").set_index(\"date\").plot(grid=True);\n</pre> df[\"date\"] = pd.to_datetime(df[\"date\"].astype(\"str\")) df.sort_values(\"date\").set_index(\"date\").plot(grid=True);"},{"location":"get_started/#fusion-get-started","title":"Fusion - get started\u00b6","text":""},{"location":"get_started/#establish-the-connection","title":"Establish the connection\u00b6","text":""},{"location":"get_started/#show-the-available-functionality","title":"Show the available functionality\u00b6","text":""},{"location":"get_started/#access-function-documentation","title":"Access function documentation\u00b6","text":""},{"location":"get_started/#view-catalogs","title":"View Catalogs\u00b6","text":""},{"location":"get_started/#explore-the-datasets","title":"Explore the datasets\u00b6","text":""},{"location":"get_started/#display-the-attributes","title":"Display the attributes\u00b6","text":""},{"location":"get_started/#display-the-dataset-members","title":"Display the dataset members\u00b6","text":""},{"location":"get_started/#display-the-available-distributions-for-a-file","title":"Display the available distributions for a file\u00b6","text":""},{"location":"get_started/#download-and-load","title":"Download and load\u00b6","text":""},{"location":"get_started/#analyze","title":"Analyze\u00b6","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install PyFusion, run this command in your terminal:</p> <pre><code>$ pip install pyfusion\n</code></pre> <p>This is the preferred method to install PyFusion, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for PyFusion can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>$ git clone git://github.com/jpmorganchase/fusion\n</code></pre> <p>Or download the tarball:</p> <pre><code>$ curl -OJL https://github.com/jpmorganchase/fusion/tarball/master\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>$ pip install .\n</code></pre>"},{"location":"metadata_creation/","title":"Fusion - Metadata Creation","text":"In\u00a0[1]: Copied! <pre>from fusion import Fusion\nimport pandas as pd\n</pre> from fusion import Fusion import pandas as pd In\u00a0[2]: Copied! <pre>fusion = Fusion()\n</pre> fusion = Fusion() In\u00a0[3]: Copied! <pre>fusion\n</pre> fusion Out[3]: <pre>Fusion object \nAvailable methods:\n+------------------------------+--------------------------------------------------------------------------------------------------+\n| attribute                    | Instantiate an Attribute object with this client for metadata creation.                          |\n| attributes                   | Instantiate an Attributes object with this client for metadata creation.                         |\n| catalog_resources            | List the resources contained within the catalog, for example products and datasets.              |\n| create_dataset_lineage       | Upload lineage to a dataset.                                                                     |\n| dataset                      | Instantiate a Dataset object with this client for metadata creation.                             |\n| dataset_resources            | List the resources available for a dataset, currently this will always be a datasetseries.       |\n| datasetmember_resources      | List the available resources for a datasetseries member.                                         |\n| delete_all_datasetmembers    | Delete all dataset members within a dataset.                                                     |\n| delete_datasetmembers        | Delete dataset members.                                                                          |\n| download                     | Downloads the requested distributions of a dataset to disk.                                      |\n| from_bytes                   | Uploads data from an object in memory.                                                           |\n| get_events                   | Run server sent event listener and print out the new events. Keyboard terminate to stop.         |\n| get_fusion_filesystem        | Creates Fusion Filesystem.                                                                       |\n| list_catalogs                | Lists the catalogs available to the API account.                                                 |\n| list_dataset_attributes      | Returns the list of attributes that are in the dataset.                                          |\n| list_dataset_lineage         | List the upstream and downstream lineage of the dataset.                                         |\n| list_datasetmembers          | List the available members in the dataset series.                                                |\n| list_datasets                | Get the datasets contained in a catalog.                                                         |\n| list_distributions           | List the available distributions (downloadable instances of the dataset with a format type).     |\n| list_product_dataset_mapping | get the product to dataset linking contained in  a catalog. A product is a grouping of datasets. |\n| list_products                | Get the products contained in a catalog. A product is a grouping of datasets.                    |\n| listen_to_events             | Run server sent event listener in the background. Retrieve results by running get_events.        |\n| product                      | Instantiate a Product object with this client for metadata creation.                             |\n| to_bytes                     | Returns an instance of dataset (the distribution) as a bytes object.                             |\n| to_df                        | Gets distributions for a specified date or date range and returns the data as a dataframe.       |\n| to_table                     | Gets distributions for a specified date or date range and returns the data as an arrow table.    |\n| upload                       | Uploads the requested files/files to Fusion.                                                     |\n| default_catalog              | Returns the default catalog.                                                                     |\n+------------------------------+--------------------------------------------------------------------------------------------------+</pre> In\u00a0[4]: Copied! <pre>my_product = fusion.product(\n    identifier=\"PYFUSION_PRODUCT\",\n    title=\"PyFusion Product\",\n    description=\"A product created using the PyFusion SDK.\",\n    short_abstract=\"A product created using the PyFusion SDK.\",\n    is_restricted=True,\n    maintainer=\"J.P. Morgan Fusion\",\n    region=\"Global\",\n    publisher=\"J.P. Morgan\",\n    theme=\"Research\"\n)\nmy_product\n</pre> my_product = fusion.product(     identifier=\"PYFUSION_PRODUCT\",     title=\"PyFusion Product\",     description=\"A product created using the PyFusion SDK.\",     short_abstract=\"A product created using the PyFusion SDK.\",     is_restricted=True,     maintainer=\"J.P. Morgan Fusion\",     region=\"Global\",     publisher=\"J.P. Morgan\",     theme=\"Research\" ) my_product Out[4]: <pre>Product(\nidentifier='PYFUSION_PRODUCT',\n title='PyFusion Product',\n category=None,\n short_abstract='A product created using the PyFusion SDK.',\n description='A product created using the PyFusion SDK.',\n is_active=True,\n is_restricted=True,\n maintainer=['J.P. Morgan Fusion'],\n region=['Global'],\n publisher='J.P. Morgan',\n sub_category=None,\n tag=None,\n delivery_channel=['API'],\n theme='Research',\n release_date=None,\n language='English',\n status='Available',\n image='',\n logo='',\n dataset=None\n)</pre> In\u00a0[\u00a0]: Copied! <pre>my_product.create()\n</pre> my_product.create() In\u00a0[5]: Copied! <pre>my_dataset = fusion.dataset(\n    identifier=\"PYFUSION_DATASET\",\n    title=\"PyFusion Dataset\",\n    description=\"A dataset created using the PyFusion SDK.\",\n    is_restricted=True,\n    maintainer=\"J.P. Morgan Fusion\",\n    region=\"Global\",\n    publisher=\"J.P. Morgan\",\n    product=\"PYFUSION_PRODUCT\",\n    is_raw_data=False,\n)\nmy_dataset\n</pre> my_dataset = fusion.dataset(     identifier=\"PYFUSION_DATASET\",     title=\"PyFusion Dataset\",     description=\"A dataset created using the PyFusion SDK.\",     is_restricted=True,     maintainer=\"J.P. Morgan Fusion\",     region=\"Global\",     publisher=\"J.P. Morgan\",     product=\"PYFUSION_PRODUCT\",     is_raw_data=False, ) my_dataset Out[5]: <pre>Dataset(\nidentifier='PYFUSION_DATASET',\n title='PyFusion Dataset',\n category=None,\n description='A dataset created using the PyFusion SDK.',\n frequency='Once',\n is_internal_only_dataset=False,\n is_third_party_data=True,\n is_restricted=True,\n is_raw_data=False,\n maintainer='J.P. Morgan Fusion',\n source=None,\n region=['Global'],\n publisher='J.P. Morgan',\n product=['PYFUSION_PRODUCT'],\n sub_category=None,\n tags=None,\n created_date=None,\n modified_date=None,\n delivery_channel=['API'],\n language='English',\n status='Available',\n type_='Source',\n container_type='Snapshot-Full',\n snowflake=None,\n complexity=None,\n is_immutable=None,\n is_mnpi=None,\n is_pci=None,\n is_pii=None,\n is_client=None,\n is_public=None,\n is_internal=None,\n is_confidential=None,\n is_highly_confidential=None,\n is_active=None,\n owners=None,\n application_id=None\n)</pre> In\u00a0[\u00a0]: Copied! <pre>my_dataset.create()\n</pre> my_dataset.create() In\u00a0[6]: Copied! <pre>attributes_df = fusion.attributes().to_dataframe()\nattributes_df\n</pre> attributes_df = fusion.attributes().to_dataframe() attributes_df Out[6]: identifier index dataType title description isDatasetKey source sourceFieldId isInternalDatasetKey isExternallyVisible unit multiplier isPropagationEligible isMetric availableFrom deprecatedFrom term dataset attributeType 0 example_attribute 0 String Example Attribute Example Attribute False None example_attribute None True None 1.0 None None None None bizterm1 None None In\u00a0[7]: Copied! <pre>attributes_df.to_csv('attributes.csv', index=False)\n</pre> attributes_df.to_csv('attributes.csv', index=False) In\u00a0[8]: Copied! <pre>attributes = pd.read_csv('attributes.csv')\nattributes\n</pre> attributes = pd.read_csv('attributes.csv') attributes Out[8]: identifier index dataType title description isDatasetKey source sourceFieldId isInternalDatasetKey isExternallyVisible unit multiplier isPropogationEligible isMetric availableFrom deprecatedFrom term dataset attributeType 0 example_attribute0 0 String Example Attribute 0 Example Attribute 0 False NaN example_attribute 0 NaN True NaN 1.0 NaN NaN NaN NaN bizterm1 NaN NaN 1 example_attribute1 1 String Example Attribute 1 Example Attribute 1 False NaN example_attribute 1 NaN True NaN 1.0 NaN NaN NaN NaN bizterm1 NaN NaN 2 example_attribute2 2 String Example Attribute 2 Example Attribute 2 False NaN example_attribute 2 NaN True NaN 1.0 NaN NaN NaN NaN bizterm1 NaN NaN In\u00a0[9]: Copied! <pre>attributes_list = fusion.attributes().from_object(attributes)\nattributes_list\n</pre> attributes_list = fusion.attributes().from_object(attributes) attributes_list Out[9]: <pre>[\n('example_attribute0', 0, &lt;Types.String: 1&gt;, 'Example Attribute 0', 'Example Attribute 0', False, None, 'example_attribute_0', None, True, None, 1.0, None, None, None, None, 'bizterm1', None, None),\n ('example_attribute1', 1, &lt;Types.String: 1&gt;, 'Example Attribute 1', 'Example Attribute 1', False, None, 'example_attribute_1', None, True, None, 1.0, None, None, None, None, 'bizterm1', None, None),\n ('example_attribute2', 2, &lt;Types.String: 1&gt;, 'Example Attribute 2', 'Example Attribute 2', False, None, 'example_attribute_2', None, True, None, 1.0, None, None, None, None, 'bizterm1', None, None)\n]</pre> In\u00a0[\u00a0]: Copied! <pre>attributes_list.create(dataset=\"PYFUSION_DATASET\")\n</pre> attributes_list.create(dataset=\"PYFUSION_DATASET\") In\u00a0[11]: Copied! <pre>file_df = pd.read_csv('sample.csv')\nfile_df\n</pre> file_df = pd.read_csv('sample.csv') file_df Out[11]: example_attribute0 example_attribute1 example_attribute2 0 A A A 1 B B B 2 C C C In\u00a0[\u00a0]: Copied! <pre>fusion.upload(\n    path='sample.csv',\n    dataset=\"PYFUSION_DATASET\",\n    dt_str=\"20241025\",\n)\n</pre> fusion.upload(     path='sample.csv',     dataset=\"PYFUSION_DATASET\",     dt_str=\"20241025\", ) In\u00a0[7]: Copied! <pre>my_raw_dataset = fusion.dataset(\n    identifier=\"PYFUSION_RAW_DATASET\",\n    title=\"PyFusion Raw Dataset\",\n    description=\"A dataset created using the PyFusion SDK.\",\n    is_restricted=True,\n    maintainer=\"J.P. Morgan Fusion\",\n    region=\"Global\",\n    publisher=\"J.P. Morgan\",\n    product=\"PYFUSION_PRODUCT\",\n    is_raw_data=True,\n)\nmy_raw_dataset\n</pre> my_raw_dataset = fusion.dataset(     identifier=\"PYFUSION_RAW_DATASET\",     title=\"PyFusion Raw Dataset\",     description=\"A dataset created using the PyFusion SDK.\",     is_restricted=True,     maintainer=\"J.P. Morgan Fusion\",     region=\"Global\",     publisher=\"J.P. Morgan\",     product=\"PYFUSION_PRODUCT\",     is_raw_data=True, ) my_raw_dataset Out[7]: <pre>Dataset(\nidentifier='PYFUSION_RAW_DATASET',\n title='PyFusion Raw Dataset',\n category=None,\n description='A dataset created using the PyFusion SDK.',\n frequency='Once',\n is_internal_only_dataset=False,\n is_third_party_data=True,\n is_restricted=True,\n is_raw_data=True,\n maintainer='J.P. Morgan Fusion',\n source=None,\n region=['Global'],\n publisher='J.P. Morgan',\n product=['PYFUSION_PRODUCT'],\n sub_category=None,\n tags=None,\n created_date=None,\n modified_date=None,\n delivery_channel=['API'],\n language='English',\n status='Available',\n type_='Source',\n container_type='Snapshot-Full',\n snowflake=None,\n complexity=None,\n is_immutable=None,\n is_mnpi=None,\n is_pci=None,\n is_pii=None,\n is_client=None,\n is_public=None,\n is_internal=None,\n is_confidential=None,\n is_highly_confidential=None,\n is_active=None,\n owners=None,\n application_id=None\n)</pre> In\u00a0[\u00a0]: Copied! <pre>my_raw_dataset.create()\n</pre> my_raw_dataset.create() In\u00a0[\u00a0]: Copied! <pre>fusion.upload(\n    path='sample.csv',\n    dataset=\"PYFUSION_RAW_DATASET\",\n    dt_str=\"20241025\",\n)\n</pre> fusion.upload(     path='sample.csv',     dataset=\"PYFUSION_RAW_DATASET\",     dt_str=\"20241025\", )"},{"location":"metadata_creation/#fusion-metadata-creation","title":"Fusion - Metadata Creation\u00b6","text":""},{"location":"metadata_creation/#establish-the-connection","title":"Establish the connection\u00b6","text":""},{"location":"metadata_creation/#show-the-available-functionality","title":"Show the available functionality\u00b6","text":""},{"location":"metadata_creation/#create-product","title":"Create Product\u00b6","text":""},{"location":"metadata_creation/#create-product-object","title":"Create Product Object\u00b6","text":""},{"location":"metadata_creation/#upload-to-catalog","title":"Upload to catalog\u00b6","text":""},{"location":"metadata_creation/#create-dataset","title":"Create Dataset\u00b6","text":""},{"location":"metadata_creation/#create-a-dataset-object","title":"Create a dataset object\u00b6","text":""},{"location":"metadata_creation/#create-attributes","title":"Create Attributes\u00b6","text":""},{"location":"metadata_creation/#retrieve-template-for-attributes","title":"Retrieve template for attributes\u00b6","text":""},{"location":"metadata_creation/#download-and-edit","title":"Download and edit\u00b6","text":""},{"location":"metadata_creation/#convert-to-attributes-list","title":"Convert to attributes list\u00b6","text":""},{"location":"metadata_creation/#upload-attributes-to-dataset-on-catalog","title":"Upload attributes to dataset on catalog\u00b6","text":""},{"location":"metadata_creation/#upload-a-file","title":"Upload a file\u00b6","text":""},{"location":"metadata_creation/#create-raw-dataset","title":"Create Raw Dataset\u00b6","text":""},{"location":"metadata_creation/#upload-data-without-schema","title":"Upload data without schema\u00b6","text":""},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#usage","title":"Usage","text":""},{"location":"usage/#import-fusion","title":"Import Fusion","text":"<pre><code>from fusion import Fusion\n</code></pre>"},{"location":"usage/#fusion-object","title":"Fusion Object","text":"<pre><code>fusion = Fusion()\n</code></pre>"}]}